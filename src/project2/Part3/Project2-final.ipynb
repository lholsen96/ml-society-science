{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Project\n",
    "\n",
    "### Lars Olsen and Oda Kristensen\n",
    "\n",
    "## Part One - Historical Data\n",
    "In this project we are given a dataset of 10 000 patients. Each patient $\\textit{t}$ has attributes $x_t = \\{x_{t,1},x_{t,2},\\dots, x_{t,130}\\}$, where $x_{t,1}$ represents the gender, $x_{t,2}$ represents whether or not the patient smoke, $\\{x_{t,3},\\dots,x_{t,128}\\}$ represents the patient's genes and $\\{x_{t,129},x_{t,130}\\}$ represents the symptoms the patient displays. Note that all the variables are binary, that is $x_{t, \\cdot } \\in \\{ 0,1\\}$. We are also given the historical action $a_t \\in \\{ 0,1\\}$ which represents whether the patient was given a placebo or an active treatment, respectively. Finally, we are given the historical outcome $y_t\\in \\{ 0,1\\}$, whether the patient displayed measurable effects after the treatment. Note that later in the project, part 3, we will expand the action variable to take on values between 0 and 129, that is, $a_t \\in \\{ 0,1,2,\\dots,129\\}$. Where action 2 represents a new general treatment while the remaining treatments are gene specific treatments. I.e. they are more effective if the patient has certain genes.\n",
    "\n",
    "Throughout this project we want to find a policy that maximizes the utility, given by the mean of the rewards. \n",
    "$$\\text{Utility} = \\frac{1}{T}\\sum_t^T r_t = \\frac{1}{T}\\sum_t^T (-0.1a_t + y_t).$$\n",
    "\n",
    "The reward function implies that there is a small penalty associated with the use of an active treatment. Thus, the policy should be somewhat certain that an active treatment will yield a positive result before recommending it. If we omit this term, all our models recommend the active treatment 100% of the time, since the estimated reward of the treatment is higher than the placebo, as we will come back to soon. This penalty can reflect the cost of a treatment. Say that treatment 1 is cheaper than treatment 2, but the second treatment is more effective. Then we should use the cheaper treatment when that treatment will give as good a result (or better) as the more expensive treatment. Otherwise we will use the more expensive treatment. The penalty term may also reflect that there are side effects of the treatment. \n",
    "\n",
    "Later, when we introduce the new actions we let the penalty be the same for all active treatments. That is, we do not use the value of $a_t$, but apply the penalty of $-0.1$ if we use an active treatment. It is not realistic that all the treatments have the same cost, but if we use the reward function above, we get that $a_t = 100$ will yield a reward of $-10$ or $-9$ depending on the outcome. Since we want to maximize the utility we will never end up using the actions corrensponding to a high $a_t$. We did not want to make up random cost for each treatment, hence we choose a fixed cost for all the active treatments. We will still let the placebo treatment have a penalty of 0. \n",
    "\n",
    "First, we need to do some data exploration. We try clustering the data with the k-means algorithm. We also check if we can find the most important features for disease epidimology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing some packages and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('historical_X.dat', header=None, sep=\" \").values\n",
    "actions = pd.read_csv('historical_A.dat', header=None, sep=\" \").values\n",
    "outcome = pd.read_csv('historical_Y.dat', header=None, sep=\" \").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the project we are only interested in the features. The first 128 features are sex, smoker and 126 genes. The two last attributes are the symptoms and these can be taken to be akin to labels in supervised learning. First, we try to categorize the patients by what symptoms they display. There are four possible combinations of symptoms. If a patient displays no symptoms, we put him in category 0. If he displays only the first symptom, we put him in category 1. If he displays only the second symptom, we put him in category 2, and if he displays both symptoms, we put him in category 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = features[:, :128]\n",
    "labels = features[:,128] + features[:,129]*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the observations of the 1st pacient, sex = 0, and non smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide our data set into a traing set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_train, obs_test, lab_train, lab_test = train_test_split(observations, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of symptoms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lab_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take a look at the histogram of observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(obs_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explorative discussion (may be skipped)\n",
    "We talked to Summaya Mumtaz in the lab and she said that from this plot we could se that there are two clusters. We are not sure how she did that. From the definition of the data, the features only take values 0 or 1. If we look at only one attribute at the time we agreee that there are two clusters. Take $x_2$, either the patient smokes ($x_2=1$) or not ($x_2=0$), so we have two clusters of patients. But when we have more dimensions, there are a lot more possible combinations, and so a lot more possible clusters. Since we have 128 features, with two possible values each, there are $2^{128}$ possible, unique patients. We want to examine if we can find some pattern in the data, i.e if there we can divide the patients into different clusters. We use the k-means algorithm to divide the data into $$k$$ clusters, and find optimal $$k$$ by silhouette score and elbow method of k-means score. \n",
    "Say we look at the two first attributes. Then a person can be either male or female and they can smoke or not smoke, i.e. we have four potential combinations. Think of a square with a cluster in each corner. obviously it can be that there are no female smokers. Then we have three clusters. Then we can think of the clusters as being on a line. Male smokers are more similar to male non-smokers than female non-smokers, and male non-smokers are equally similar to both (assuming equal weighting of the attributes). So we have \"male smokers\" -- \"male non-smokers\" -- \"female non-smokers\". In a hypercube we would still have clusters in each corner, and this gives us $2^{128}$ potential clusters. This is an astronomical number. So we must assume that there is pattern in the data, which will lower this number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two histograms bellow we see that there are more people of the sex zero and more non-smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lars9\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8lNed7/HPT733grpER4BoMsUtuHewg+2YuMQbO940Z3M3N7vZJOvsjTd30+5mk40dh7imGFzigm1sxx0bTBEGRAcBQhoJUO91Zs79QyKryAINaEbPzDO/9+ulFxrN4ZmfH4++nDnPec4RYwxKKaXsJcTqApRSSnmfhrtSStmQhrtSStmQhrtSStmQhrtSStmQhrtSStmQhrtSStmQhrtSStmQhrtSStlQmFUvnJaWZgoLC616eaWUCkjbtm1rMMakj9bOsnAvLCykrKzMqpdXSqmAJCLHPGmnwzJKKWVDo4a7iDwuInUisvsMbZaKyA4R2SMiH3i3RKWUUmfLk577k8DVp3tSRJKAh4FlxpiZwC3eKU0ppdS5GjXcjTHrgaYzNPk88IIxpmqwfZ2XalNKKXWOvDHmPhVIFpH3RWSbiNzlhWMqpZQaA2/MlgkDFgCXAdHAxyKyyRhzcHhDEbkPuA8gPz/fCy+tlFJqJN7ouTuAN4wxncaYBmA9MGekhsaYVcaYUmNMaXr6qNM0lVJKnSNvhPvLwEUiEiYiMcAiYJ8XjquUUuocjTosIyKrgaVAmog4gB8A4QDGmEeMMftE5A2gHHADjxpjTjttUimllO+NGu7GmJUetPkZ8DOvVKSUzT29ucrqEs7J5xfpdbJAoneoKqWUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDWm4K6WUDY26E5OyP90ZSCn7GbXnLiKPi0idiJxxX1QROU9EXCJys/fKU0opdS48GZZ5Erj6TA1EJBT4CfCmF2pSSik1RqOGuzFmPdA0SrP7gT8Ddd4oSiml1NiM+YKqiOQANwGPeND2PhEpE5Gy+vr6sb60Ukqp0/DGbJn/Av7ZGOMaraExZpUxptQYU5qenu6Fl1ZKKTUSb8yWKQXWiAhAGnCtiDiNMS954dhKKaXOwZjD3RhTdOp7EXkSeFWDXSmlrDVquIvIamApkCYiDuAHQDiAMWbUcXallFLjb9RwN8as9PRgxpi7x1SNUkopr9DlB5RSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoZGDXcReVxE6kRk92mev11Eyge/NorIHO+XqZRS6mx40nN/Erj6DM8fBT5jjCkBHgRWeaEupZRSY+DJHqrrRaTwDM9vHPJwE5A79rKUUkqNhbfH3O8BXvfyMZVSSp2lUXvunhKRSxgI9wvP0OY+4D6A/Px8b720UkqpYbzScxeREuBRYLkxpvF07Ywxq4wxpcaY0vT0dG+8tFJKqRGMOdxFJB94AbjTGHNw7CUppZQaq1GHZURkNbAUSBMRB/ADIBzAGPMI8ACQCjwsIgBOY0yprwpWSik1Ok9my6wc5fl7gXu9VpFSSqkx0ztUlVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhjTclVLKhry2QbZSyl6cLjeH6zvYd7ydXqeLow0dFKXFcdO8HKIjQq0uT43Ck232HgeuB+qMMbNGeF6AXwLXAl3A3caYT7xdqFJqfBhj2HasmXW7j9PT7yYyLISYiFD2n2in1+nmP986yFeWTuKOxflEhmnI+ytPeu5PAr8Gfn+a568Bpgx+LQJ+M/inUirA9PS7eHF7DbtqWilKi+XiKWlMSo8jLDSElQvzKDvWzC/eOsiDr+7lrb0nWHVXKQlR4VaXrUYw6pi7MWY90HSGJsuB35sBm4AkEcnyVoFKqfHR2+/i0Y+OsKe2lSuLM7nnwiKmTUggLHQgJkSE8wpTePpLi/nF5+ZQVtnMbb/dRF17j8WVq5F444JqDlA95LFj8GdKqQDhdLt5eksVJ1p7uGNxAUunZRAictr2N83L5dEvlHK0oZOVqzbR0escx2qVJ7wR7iO9A8yIDUXuE5EyESmrr6/3wksrpcbKGMOLn9RwqK6Dm+blMH1Cgkd/b+m0DB67u5TKxi7++flyjBnx115ZxBvh7gDyhjzOBWpHamiMWWWMKTXGlKanp3vhpZVSY7W9uoXt1S1cNj2DBQUpZ/V3z5+Uxj9dNY3Xdh3n8Q2VvilQnRNvhPta4C4ZsBhoNcYc98JxlVI+1trdz6vltRSmxnDJ9IxzOsZ9F0/kyuJM/mPdPnY5Wr1coTpXo4a7iKwGPgamiYhDRO4RkS+LyJcHm6wDjgAVwO+Ar/qsWqWU1xhjeHG7A5fbsGJ+7hnH2M9ERPjZLXNIjo3g+y/twuXW4Rl/MOpUSGPMylGeN8DXvFaRUmpc7Khu4eDJDm4oySI1LnJMx0qMDuf7183gH9bsYM3WKm5fVOClKtW50uUHlApCfU43b+45QW5yNIsmpnrlmMvmZLNkYio/feMAjR29XjmmOnca7koFoY2HG2jrcXLNrKxzHo4ZTkR48MaZdPY6+flfDnrlmOrc6doyQarc0cK+4200dPSxvaqFyemx5KbEeO0XXfmvjl4nHxysZ0ZWAkVpsV499uSMeO5YXMAfNx3jK5+ZRH5qjFePrzyn4R5EjDG8d6COR94/wpbKv73p+O19EBMRysVT0rlgchqhIRrydvXe/jr6XW6umpnpk+N/dekkVm+p4lfvHuLnt8zxyWuo0Wm4B4k+p5t/fWk3z5RVk5MUzQPXF3NFcSbp8ZH8aVMVh+ra2V7Vwht7TrC7tpUV83PJTIiyumzlZW3d/WypbGJBQTIZ8b75/5uREMWdiwt4fMNRvnbJZK9/OlCe0TH3INDY0csdj27mmbJq7r90Mu9/eylfvLCIvJQYosJDiY4IpSQ3ibuWFHDbeXk0dfbxyAeHqW7qsrp05WUbKhpwuw0XT/HtTYR//5lJRIaF8qt3Dvn0ddTpabjbXEevkzse28JORwu/WjmPb105jfDQkf+3iwgluUncf+kUYiPDeGLjUWqau8e5YuUr3X0uNlc2MTs3ccxTH0eTHh/JXecX8NKOGo41dvr0tdTINNxtzOU2fGP1dg6ebGfVXaUsm5Pt0d9LjA7nnguLiAoP5fENR6lv12ltdvDxkUb6nG4+M3V8lv6454IiwkKEJ3RZAktouNvYj17bx7v76/i3ZTPP+hc6OSaCey+ciAis2VpFv8vtoyrVeOhzutl4uIFpmfFkJUaPy2tmJESxbE4Oz5ZV09rdPy6vqf6HhrtNvb33JI9vOMrd5xdy5+Jzu1swJTaCmxfkcry1h9d363JBgWxHdQtdfS4uHqde+yn3XFhEV5+LNVuqxvV1lYa7LbV09fEvL+5i+oR4vnvtjDEda/qEBC6cnMamI03sqdVFoQKRMYZNRxrJSoyicJznnRdnJ3D+pFSe3Fipn/7GmYa7Df3wlb00dfbx81vmEBE29v/FV87MJCcpmrU7aunpd3mhQjWeKhu7ONHWw+KJqYgFN6nde1ERx1t7WLdLP/2NJw13m3lvfx0vbK/ha0snMSsn0SvHDAsJYfncbDp6nbyz76RXjqnGz6YjjUSFhzAnN8mS1186NYOC1Bj+tFmHZsaThruN9LvcPPjqXiamx/L1S6d49di5yTGcV5TCx0caOd6q0yMDRWt3P3tqWyktSPHKp7hzERIirFyYz5ajTVTUtVtSQzDScLeRpzdXcaShk+9eM8Mnv8hXFmcSFR7K2p21uqVagNha2YQxsKjo7HZY8rabF+QSHiraex9HGu420drdz3+9fZAlE1O5bMa57agzmpiIMK4snsCxxi72n9AemL9zG8O2Y81Mzojz+U1Lo0mLi+SqmRP48zaHXrcZJxruNvHwexW0dPfzvetm+PSi2YKCZFJjI3hr70nc2nv3axV1HbR291NaaG2v/ZTPL8qnrcfJa+V6YXU8aLjbQF17D09urOSmuTleu4h6OqEhwmUzMjnR1sPuGp0a6c/KKpuIiQhlxoR4q0sBYMnEVCamxfK0znkfFx6Fu4hcLSIHRKRCRL4zwvP5IvKeiGwXkXIRudb7parTefTDo/S73HzjMu9eRD2dktxEMhMieXvfSd0v00919DrZd7ydeXlJhJ1mLaHxJiJ87rw8th1r5kh9h9Xl2J4nG2SHAg8B1wDFwEoRKR7W7PvAs8aYecBtwMPeLlSNrKmzjz9uOsayOdkUjtPSqiEiXD4jk4aOPnZWt4zLa6qzs6O6BZcxLPCTIZlTbpqXQ4jAnz9xWF2K7XnyT/pCoMIYc8QY0wesAZYPa2OAhMHvE4Fa75WozuSxj47Q3e/i65dOHtfXLc5KYEJCFOsP1evYu58xxlBW2URucjQT/GxN/oyEKC6ems4Ln9Topz4f8yTcc4DqIY8dgz8b6t+AO0TEAawD7h/pQCJyn4iUiUhZfX39OZSrhmrt6uepjce4dlYWkzPGd1xVRLh4ahp17b0c1JkzfqW2pYe69l4WFCRbXcqITq1XtPFwg9Wl2Jon4T7S1Ivh/+SuBJ40xuQC1wJ/EJFPHdsYs8oYU2qMKU1PH98FjOzo6S1VdPQ6+eolkyx5/dk5SSRFh7P+kP5D7U8+qW4mNEQoybHmjtTRXD4jk4SoMJ7fpkMzvuRJuDuAvCGPc/n0sMs9wLMAxpiPgSggzRsFqpH1u9w8tbGSCyanMjPbtzNkTic0RLhgchqVjV1U6YYMfsHlNpRXtzB9QjzREaFWlzOiqPBQls3N5o3dJ2jr0aWAfcWTcN8KTBGRIhGJYOCC6dphbaqAywBEZAYD4a7dOR9at+s4J9p6uOfCIkvrKC1MJjo8lPWH9CO2PzhU105nn4v5+f45JHPKivm59DrdvLH7hNWl2Nao4W6McQJfB94E9jEwK2aPiPxQRJYNNvsW8CUR2QmsBu42en+6zxhjeOyjo0xMj2XpVN/cjeqpyLBQFhWlsO94G82dfZbWomB7VQsxEaFMyYyzupQzmpuXREFqDGt36NwLX/FoAqwxZp0xZqoxZpIx5keDP3vAGLN28Pu9xpgLjDFzjDFzjTF/8WXRwa7sWDPljla+eEERISHjv4TrcIsmpiICm442Wl1KUOvpd7HveBsluYmEhfjH3PbTERGWzclm4+EG6tp7rC7Hlvz7HaBG9MSGoyTFhLNifq7VpQADe64WZyVQVtlMn1M3ZLDK7ppWnG7DvDz/HpI5ZfncbNwGXY7ARzTcA8zJth7e3HOSW0vz/OqC2ZJJaXT3u9jp0JuarFLuaCU1NoLc5PHZI3WsJmfEU5yVwMs6NOMTGu4BZvWWKlxuw+2L8q0u5W8UpsYwISGKjw836nLAFmjv6edwfQcluYmW7LZ0rpbPzWZHdQvHdLaV12m4BxCny82aLdVcPDWdgtTxWWrAUyLCkkmpnGjr4Vhjl9XlBJ3dtW0YoMSi3ZbO1fVzsgH0wqoPaLgHkLf31XGirYc7FxdYXcqI5uQmERkWQtmxJqtLCTrljhYyEyLJ9LPlBkaTkxTNwsIUXtYNYLxOwz2A/HHTMbITo7h0urXTH08nImxgn85dNa109+mGDOOlpauPY41dAddrP2XZ3Gwq6jrYd1yXsfAmDfcAUdXYxUcVDaxcmE+oH0x/PJ3zClPodxm9sDqOdg2uq1/i47X8feXa2VmEhQgv76yxuhRb0XAPEM9vqyZE4OZS/5j+eDrZSVFkJUZRVqlDM+Ol3NFKTlK05VvpnauU2AgumpLGKztqcetKkV6j4R4AXG7D89scXDglnaxE/57mJiKUFqZQ29pDTUu31eXYXkNHLzUt3czJDcxe+ynL5+ZQ29pD2bFmq0uxDQ33ALDxcAO1rT3cssC/e+2nzM1NIixE2Kq9d58rdwwMycwO0PH2U64oziQqPIS1OjTjNRruAeC5MgcJUWFcUZxpdSkeiY4IZXZOIjurW/SOVR8rd7RQmBpDYnS41aWMSWxkGFcUT+C18uP0u/Q94w0a7n6utbufN/ec4MZ5OUSF+88dqaMpLUyh1+nWTbR96ETbwKYcgTpLZrhlc7Jp7upnQ4WuMOoNGu5+7pWdtfQ63dyyIG/0xn6kMDWGtLgIHZrxoXJHCwLMCtBZMsNdPDWN+KgwXtmpa814g4a7n3tum4PpE+KZlZMwemM/IiKUFqRwrKmLujZd9c/bjDGUO1qZlBFHXGSY1eV4RWRYKFfNnMBf9pyg16n3SYyVhrsfO3iynZ3VLdy8IDeg1gs5ZV5+EiGCzoDwgZqWbpo6+wJ2bvvpXF+SRXuvkw8O6F4/Y6Xh7seeK6smLES4ad7w/cgDQ3xUODOyEvikqhmnXiTzqnJHK6Eilm2x6CsXTE4jOSacV3UZ4DHTcPdT/S43L26v4dLpGQF7cwpAaUEyXX0u9p/QW8u9xW0M5Y4WpmbG+dWyz94QHhrCNbOzeGvvSbr6nFaXE9A8CncRuVpEDohIhYh85zRtbhWRvSKyR0Se9m6Zwef9A/U0dPRxS2lgXUgdbnJGPPFRYWzToRmvOdbYRVuP0zazZIa7viSL7n4X7+6vs7qUgDZquItIKPAQcA1QDKwUkeJhbaYA/wJcYIyZCXzTB7UGlefKqkmLi2TptHSrSxmT0BBhfn4yB0+26073XlLuaCE8VJieFW91KT6xqCiV9PhIXtVZM2PiSc99IVBhjDlijOkD1gDLh7X5EvCQMaYZwBij/+SOQUNHL+/ur+Oz83MIDw38kbMF+ckYYEeVLiY2Vi63YXdNK9MnJBAZZq8hmVNCQ4TrZmfx7oE62rVDcM48SY4coHrIY8fgz4aaCkwVkQ0isklErvZWgcHope01ON0mYJYbGE1afCT5KTFsO9asa3aP0ZGGDjr7XJQE+Foyo7lhThZ9Tjdv7ztpdSkBy5NwH2kO3vDf0DBgCrAUWAk8KiKfGhAUkftEpExEyurrdarTSIwZWCRsTl4SUzLt87F7QUEy9R29VDfrYmJjUe5oJTIshKk2em+MZF5eMjlJ0XpD0xh4Eu4OYOhVvVxg+J5YDuBlY0y/MeYocICBsP8bxphVxphSY0xpenpgjyX7yq6aVvafaLdNr/2U2TmJhIeKXlgdA6fLzZ7aVmZmJ9hiuO5MQkKE60qyWH+wnpauPqvLCUievEO2AlNEpEhEIoDbgLXD2rwEXAIgImkMDNMc8WahweK5MgeRYSHcMLi3pF1EhYcyKzuRcocuJnauDtV10NPvtu0smeFuKMnG6Ta8ueeE1aUEpFHD3RjjBL4OvAnsA541xuwRkR+KyLLBZm8CjSKyF3gP+LYxptFXRdtVT7+Ll3fUcNXMCQG/yt9I5hck0+t0s/e4LiZ2LnY6WoiJCGVSepzVpYyLWTkJFKTG6NDMOfJoUQpjzDpg3bCfPTDkewP84+CXOkdv7T1JW4+TWwN8bvvpFKXFkhwTzrZjzczNS7a6nIDS53Sz73gb8/KS/XqbRW8SEW4oyebh9yto6OglLYBv5rOCvQfuAsxz2xzkJEVz/qRUq0vxiRAZmPN+pL6TZh1HPSv7T7TR7zK2nyUz3A1zsnEbeH2X9t7Ploa7n6ht6ebDQ/WsmJ9DiI17ZvMH57x/UqUXVs9GuaOV+KgwCtNirS5lXE2bEM+UjDhe0bVmzpqGu5944RMHxsDNAbZu+9lKjo1gYnosnxxrxq1z3j3S3efi4Ml2ZuckEhKAq4OO1Q1zstla2cTxVp1GezY03P3Aqbnti4pSyE+Nsbocn1uQn0xzVz+VDZ1WlxIQ9tS24nQb5uYFxyyZ4a4vycIYeE1772dFw90PbK1sprKxK+AXCfPUzOxEIsNCdM67h7ZXt5AWF0FOUrTVpVhiYnocM7MTdBngs6Th7geeK6smNiKUa2dPsLqUcRERFkJJbiK7a1vp7dcdd86kpauPyoZO5uYlBeSGLd5yw5xsdlS3UNXYZXUpAUPD3WKdvU5e23Wc60uyiYmwx3ZpnliQn0y/y7BLN9A+o3JHKwaYEyQ3Lp3OqZv6Xt5RY3ElgUPD3WLrdh2nq8/FLaX2Wm5gNHkpMaTFRerQzCh2VLeQnxIT0Bu2eENOUjSLilJ4cXuNLj7nIQ13iz1X5mBiWiwLCoLrph4RYUFBMseaumho77W6HL90vLWbE209QXshdbjPzs/hSEMnOx36ac8TGu4WqmzoZEtlEysCdAPssZqXl4QA23TO+4h2VLcQIgOLrim4ZnYWkWEhvPiJw+pSAoKGu4We3+YgRGDF/OAakjklITqcqZnxbK/SOe/DuY1hZ3ULUzPjiY0MnmsxZ5IQFc7lxZm8Un6cft1wfVQa7hZxuQ1//sTBRVPSmZAYZXU5lplfkExbj5OKug6rS/ErRxs6aetx6pDMMJ+dl0NTZx8fHND9IEaj4W6R9QfrOd7aw+fOC4657aczY0I80eGhemF1mB3VLUSGhTB9QoLVpfiVi6emkxIbwYs6a2ZUGu4WeXpLFWlxEVw+I9PqUiwVFhrC3Lwk9h5vo6vPaXU5fqHf5WZ3TSszsxOJCNNf0aHCQ0O4oSRrcAVV3V/1TPSdY4ETrT28u7+Omxfk6S8vA1vwudxGZ0EM2n+inV6nW4dkTuOm+bn0Od26UuQoNFks8FxZNS634bYgH5I5JTspmuzEKLYebdI5zMCOqmYSosKYmB5cK0B6ak5uIhPTYnnhEx2aORMN93HmchvWbK3mgsmpQbd865ksKkrlRFsPVU3BfXt5e08/B062MycvKShXgPSEiHDTvBw2H23C0Rzc75cz8SjcReRqETkgIhUi8p0ztLtZRIyIlHqvRHv58FA9NS3drFyYb3UpfmVOXhKRYSFsPtpkdSmW2lHdgtsQdDe1na0b5+UA8PKOWosr8V+jhruIhAIPAdcAxcBKESkeoV088A1gs7eLtJPVW6pIjY3gyuLgWCTMUxFhIczPT2ZXTSsdvcF5YdUYQ9mxZvJTYsiID97psZ7IS4lhYWHK4D4IOpQ3Ek967guBCmPMEWNMH7AGWD5CuweBnwI9XqzPVuraenh7Xx03L8jVC6kjWFiUgsttgnZaZHVzN/XtvZRqr90jn52fw+H6TrZXt1hdil/yJGFygOohjx2DP/srEZkH5BljXvVibbbz3DYHLrcJ+rntp5OZEEVRWixbjjYG5R2r2441ER4qutyAh66fk01MRCjPbKkevXEQ8iTcR7qq89ffPBEJAX4BfGvUA4ncJyJlIlJWXx9cd5i53YbVW6pYMjGVielxVpfjtxYVpdDc1c+hk+1WlzKu+pxuyh2tzM5JIjI81OpyAkJcZBg3lGTzSnlt0A7lnYkn4e4AhnY1c4GhVzHigVnA+yJSCSwG1o50UdUYs8oYU2qMKU1PTz/3qgPQRxUNOJq7WblIL6SeSXF2AnGRYUF3YbXc0UKv061DMmfp1vPy6Opz8Vq5XlgdzpNw3wpMEZEiEYkAbgPWnnrSGNNqjEkzxhQaYwqBTcAyY0yZTyoOUKu3VJEcE85VM4P7jtTRhIWEcF5hMgdOtNPc2Wd1OeNm89EmMuIjKQiCPXS9aX5+ElMy4lizVYdmhhs13I0xTuDrwJvAPuBZY8weEfmhiCzzdYF2UNvSzV/2nuTW0jwiw/Qj92jOK0wBYEtlcPTeHc1d1LR0s2hialAu/TwWIsLnzstje1ULB04E11DeaDyasmGMWWeMmWqMmWSM+dHgzx4wxqwdoe1S7bX/rT9uOoYxhjsWF1hdSkBIiolg+oR4yo414wyCpV03Hx24kDpPlxs4J5+dn0tEaAirt1RZXYpf0fl4PtbT72L1lioun5FJXop+5PbUoompdPY62V1r7/VmuvtclDtamJuXRJReSD0nKbERXFeSxZ+3OejUC6t/peHuY2t31tLc1c/d5xdaXUpAmZwRR1pcJB9VNNj6JpXt1c30uwwLi1KtLiWg3bG4gPZeJy/pUsB/peHuQ8YYntpYydTMOJZM0l/esxEiwgWTU6lt6eFoQ6fV5fiE2xg+PtxIXnI0OUnRVpcT0ObnJ1GclcAfPj5m687A2dBw96Gtlc3sqW3jC+cX6oWyczA/P5mYiFA+qmiwuhSfOHCincbOPs6fnGZ1KQFPRLhzSQH7T7RTFqR3OA+n4e5Dq9YfJiU2gs/OC849UscqPDSExRNT2X+inbp2+61qseFwA4nR4czK1jtSvWH53Gzio8L4/cfHrC7FL2i4+0hFXTtv76vjzsUFREfohbJztXhiKmEhwoaKRqtL8arjrd0cqe9kycRUQkP0U503xESEcWtpHq/vOs7x1m6ry7GchruP/G79USLDQrhriU5/HIu4yDDm5yfzSVUzbd322VZtY0Uj4aHy1zn9yjvuPr8QtzE8ubHS6lIsp+HuA3VtPby4vYZbSnNJjYu0upyAd/HUdIwxfHjIHusRtXX3s8PRwvz8ZP1U52V5KTFcMyuLpzdXBf16MxruPvDExkr63W7uvXCi1aXYQkpsBHNyk9hS2WSLX9hT0zsvmhJc6yuNl3svKqK9x8lzZcG9JIGGu5e1dPXxh4+Pce3sLN1Gz4uWTsvA6TJsCPCZM02dfWw+2sic3CRSYiOsLseW5uUns6Agmcc3HMXlDt5pkRruXvb4hko6ep3cf+lkq0uxlfT4SGblJPLxkUa6+gK39/7EhqM4XYbPTNVeuy996aKJVDd189qu41aXYhkNdy9q6+nniQ1HuWpmJtMnJFhdju1cMj2Dfqeb9QcDc+y9raefJzdWUpydQEaCbqPnS1cWZzI5I46H3q3AHaS9dw13L3pqQyXtPU7uv3SK1aXY0oSEKObkJbHxcCOtAThz5snB98fSaRlWl2J7ISHC1y/Eop+KAAAPGklEQVSZzIGT7by176TV5VhCw91L2nr6efSjo1w+I4NZuk2az1w+IxNj4N39dVaXclaaOvtYtf4IV8+coEsNjJPrS7IoTI3hv989FJRLEmi4e8mqD47Q2t3PNy+fanUptpYSG8F5RSlsO9YUUGvOPPxeBV19Tv73Vfr+GC9hoSF8delkdte08f6BwBzKGwsNdy+oa+vhsY+OcsOcbO21j4NLpqUTFhLCj1/fZ3UpHqlp6eb3m46xYn4ukzPirS4nqNw4L4ecpGj+862DQTf2ruHuBb969xD9LjffukJ7ZeMhPiqcz0xL5809J/nokP9PjfzFWwfBwDf1/THuIsJC+F9XTGVXTSvrdgfXzBkN9zGqbOhkzZZqbluYp/Pax9GFk9PIT4nh317ZQ78f79a0o7qF57c5uPuCQh1rt8hN83KYlhnPz9884NfvFW/zKNxF5GoROSAiFSLynRGe/0cR2Ssi5SLyjogEzYIqP1q3j4iwEL6hM2TGVXhoCA9cX0xFXQdP+ek6Ii634YGXd5MRH6n3PVgoNET49lXTqGzs4pkg2kh71HAXkVDgIeAaoBhYKSLFw5ptB0qNMSXA88BPvV2oP/rgYD1v7T3J/ZdO0XnLFrhsRgafmZrOf719iNoW/1sF8NmyasodrXz32hnER4VbXU5Qu2xGBqUFyfzynUO2WMLCE5703BcCFcaYI8aYPmANsHxoA2PMe8aYrsGHmwDbL2De53Tzf17ZQ2FqDF+8sNDqcoKSiPDg8lm43IZ/eWGXX013a+rs46dv7GdhUQrL52ZbXU7QExG+d90M6tt7+e93DlldzrjwJNxzgKGfZRyDPzude4DXR3pCRO4TkTIRKauvD+ypSU9trORIfScP3FBMZJiu7GeV/NQY/vnqaXxwsJ7ntzmsLgcY2F7xX1/aTUevkweXz9JduPzEvPxkbi3N5fENR6mo67C6HJ/zJNxHemeO2EUSkTuAUuBnIz1vjFlljCk1xpSmpwfu2hrVTV384u2DXDItnUunZ1pdTtC7a0khCwtT+OGre/1ik4a1O2t5bddxvnn5VKZN0KmP/uSfrp5OVHgo/+eVPX71Sc8XPAl3B5A35HEuUDu8kYhcDnwPWGaM6fVOef7HmIEhAAH+/abZVpejGLjV/Kc3l+ByG/5h9Q6cFs6IONnWwwMv72FefhJ/f7Eu+exv0uIi+dYVU/nwUAPrdp2wuhyf8iTctwJTRKRIRCKA24C1QxuIyDzgtwwEe2DdF36Wnitz8FFFA9+5ZrpObfMjhWmx/N+bZrOlsomf/eWAJTU4XW7+Yc12ep0u/t8tcwgL1ZnG/uiOxQXMzknkgZd309hh237o6OFujHECXwfeBPYBzxpj9ojID0Vk2WCznwFxwHMiskNE1p7mcAHteGs3D762l4VFKdy+KGhmewaMG+flcPuifH77wRHe2jv+i0X9x+v72XSkiR/dOJuJ6XHj/vrKM2GhIfzslhLaevr5wdo9VpfjMx51LYwx64wxU40xk4wxPxr82QPGmLWD319ujMk0xswd/Fp25iMGHpfb8M01O3C5DT9ZUUKIbmrsl/71+mJm5yTyzTXb2V3TOm6v+/KOGh776Ch3n1/IigW2nywW8KZPSOAbl07h1fLjvG7TNd/1c6OHfv1uBZuPNvHg8lkU6Z2ofisqPJRHv1BKUkwEdz+xharGrtH/0hhtPNzAPz1fzsLCFL533Qyfv57yji8vncSsnAS+++Iuv7xPYqw03D2w5WgTv3znIDfNy9FeWQDITIjiqS+eh9NtuOvxzZxo7fHZa2071sy9T5VRkBrDI3cuIFzH2QNGeGgIv7ptHn1ON/ev3m67pQn0nTiKmpZuvvqnbRSkxvLgjbOsLkd5aHJGPI994TwaOvpY8ZuNHKn3/rzmT6qaufuJLWTER/LHexbpnqgBaGJ6HP+xooRtx5r5+ZvWXIj3FQ33M+jsdXLvU2X0Ot387q5S4iLDrC5JnYUFBcmsuW8xPf0ubnnkY7ZXNXvt2Gt31nLbqk0kx0Twx3sX6fITAWzZnOyBC/Hrj/DKzk/N8g5YGu6n4XIb/vHZHRw40cZ/r5zH5Ayd/RCIZuUk8tyXlxAdEcotj3zMb94/PKZ1vXudLn76xn6+sXo7c3OTeOlrF5CbHOPFipUVHrihmIWFKXzruZ2UVTZZXY5XaLiPwO02fPeFXby55yTfv65Y97wMcBPT43jt/ou4cmYmP3ljPyt/t4ldjrOfSVNW2cS1v/yQh98/zG3n5fGHexfqUIxNRIaF8ts7F5CTFM2Xfl9GZQDt8nU6Gu7DGGN48LW9PFNWzTcuncwXLyyyuiTlBYkx4Tz0+fn8ZMVsDp5s54Zff8RX/7SNjYcbcJ2hJ+92G97bX8cdj27m5kc+pqffzVNfXMiPV5TomkI2kxwbwRN3nwfA7Y9uprrJ9zOtfEkHkYdwuw3//to+nthQyRcvKOJ/6c45tiIifO68fK6dncXvPjzKYx8eYd2uE6TFRbBkUhpFqTFkJUXT0++irdvJrppWtlY20drdT2ZCJN++ahp3n19IrF57sa3CtFj+cM8ibn90M7et2sSa+xaTlxKYw276Lh3U53TzT8/v5KUdtfzdBYX86/UzdDU/m4qPCucfr5jKlz8zkff217Nu13F2VDfzWnktQzvxBakxXDUzk4unpnNl8QQiwvSDbjCYlZPIn+79n4B/8u/OY0pm4C0Ap+HOwNrb31i9nY8qGvj2VdP46tJJGuxBICYijOtKsriuJAsYuFja2NFHdHgosZFhGuZB7FTA/92TW/nsbzbym9sXcOGUNKvLOitB/+4td7Rww39/xJajTfz05hK+dslkDfYgFRkWSnZSNMmxERrsilk5ibz0tQvITozm7ie28OiHR8Y002q8Be072Oly89B7Fdz8m48BeP4rS7i1NG+Uv6WUCiY5SdE8/5UlXDI9g39/bR9ffGorDQGykmRQhvvumlZuengjP3vzAJcXZ/DK/RdSkptkdVlKKT8UHxXOqjsX8ODymWw83MgV//kBz2yt8vtefFCNuTuau/h/fznIi9trSI2N4OHb53Pt7Cyry1JK+TkR4c4lhSyamMr3X9zNP/95F2u2VvPtq6axZGKqXw7lBkW4765p5dEPj/Bq+XFCQ4SvLJ3EV5ZOIkF3pFdKnYWpmfE88/eLeeGTGn7yxn4+/7vNLCxM4b6LJ3LJ9AxC/WgpcNuGe21LN+t2HeelHTXsrmkjNiKUu5YUcu9FRWTrDkpKqXMkIqxYkMt1JVk8s7Wah9+v4N7fl5GVGMWK+blcPWsCM7MTLO/N2yLce50uKhu62F3TSrmjhY8qGjhcP3D7cEluIg9cX8yKBbkkRmtPXSnlHVHhoXzh/EI+vyifd/ad5OktA0H/6/cqyE6MYvHEVBYUJjM7J5GJ6XHjvvCgR68mIlcDvwRCgUeNMT8e9nwk8HtgAdAIfM4YU+ndUgeUVTaxav0ROvuctPc4OdnWw8m2/7l6HR0eysKiFFYuzOeS6RlM0u3OlFI+FB4awtWzsrh6VhaNHb28s7+Od/fVsf5QPS9sr/lru7S4SNLiIkiJjeDGeTk+n503ariLSCjwEHAF4AC2ishaY8zeIc3uAZqNMZNF5DbgJ8DnfFFwd7+LqqYu4iLDSI6JYPqEeHKSYihIjWFWTgJFaXF+Ne6llAoeqXGR3Fqax62leRhjqGrqYv+Jdg7Xd1DV2EVjZx9NnX1097l8XosnPfeFQIUx5giAiKwBlgNDw3058G+D3z8P/FpExBjj9blCF01J541vpnv7sEop5VUiQkFqLAWp1mzL6ck89xygeshjx+DPRmxjjHECrUCqNwpUSil19jzpuY80xjG8R+5JG0TkPuC+wYcdImLFvlZpQIMFr+vPAvKc3O7bwwfkOfGl2/WcDGfV+SjwpJEn4e4Aho785wLD96I61cYhImFAIvCp7UyMMauAVZ4U5isiUmaMKbWyBn+j5+TT9Jx8mp6Tv+Xv58OTYZmtwBQRKRKRCOA2YO2wNmuBLwx+fzPwri/G25VSSnlm1J67McYpIl8H3mRgKuTjxpg9IvJDoMwYsxZ4DPiDiFQw0GO/zZdFK6WUOjOP5rkbY9YB64b97IEh3/cAt3i3NJ+xdFjIT+k5+TQ9J5+m5+Rv+fX5EB09UUop+wnKJX+VUsrubB/uIpIiIm+JyKHBP5NP084lIjsGv4ZfMA54InK1iBwQkQoR+c4Iz0eKyDODz28WkcLxr3J8eXBO7haR+iHvi3utqHM8icjjIlInIrtP87yIyK8Gz1m5iMwf7xrHmwfnZKmItA55nzwwUrvxZvtwB74DvGOMmQK8M/h4JN3GmLmDX8vGrzzfG7KExDVAMbBSRIqHNfvrEhLALxhYQsK2PDwnAM8MeV88Oq5FWuNJ4OozPH8NMGXw6z7gN+NQk9We5MznBODDIe+TH45DTaMKhnBfDjw1+P1TwI0W1mKVvy4hYYzpA04tITHU0PP0PHCZWL1mqW95ck6CjjFmPSPcozLEcuD3ZsAmIElEbL3jjQfnxC8FQ7hnGmOOAwz+mXGadlEiUiYim0TEbv8A6BISn+bJOQFYMTj88LyI6Ca7np+3YLNERHaKyOsiMtPqYsAm67mLyNvAhBGe+t5ZHCbfGFMrIhOBd0VklzHmsHcqtJzXlpCwEU/+e18BVhtjekXkywx8srnU55X5t2B7n3jiE6DAGNMhItcCLzEwbGUpW4S7Meby0z0nIidFJMsYc3zw42PdaY5RO/jnERF5H5gH2CXcvbaEhI2Mek6MMY1DHv4Om1+H8JAn76WgYoxpG/L9OhF5WETSjDGWrsMTDMMyQ5dG+ALw8vAGIpI8uOEIIpIGXMDfLmkc6HQJiU8b9ZwMG0teBuwbx/r81VrgrsFZM4uB1lPDnsFKRCacuj4lIgsZyNXGM/8t37NFz30UPwaeFZF7gCoG76QVkVLgy8aYe4EZwG9FxM3A/5gfD9uMJKDpEhKf5uE5+YaILAOcDJyTuy0reJyIyGpgKZAmIg7gB0A4gDHmEQbuVL8WqAC6gL+zptLx48E5uRn4iog4gW7gNn/oGOkdqkopZUPBMCyjlFJBR8NdKaVsSMNdKaVsSMNdKaVsSMNdKaVsSMNdKaVsSMNdKaVsSMNdKaVs6P8DTn0Zu0iwaM0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(obs_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lars9\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD9CAYAAABHnDf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4VdW9//H395yTgQQyTyQhIQTCaMIQRCbFGatCB2vF2lqvSrXW9lZvq733/myvrc+tteOtVovW0mqdWifEsU4MMsgcxkAIIWQiE0nIPK3fHwk+EQI5Sc7JPmfn+3oeHpKcxd5fNicfVtZeey0xxqCUUspeHFYXoJRSyvM03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyob6DHcReVpEykVkz1leDxeRN0Rkl4jsFZFbPF+mUkqp/nCn574SWHyO1+8C9hljsoBFwK9FJHDwpSmllBqoPsPdGLMWqD5XE2CUiAgwsrttu2fKU0opNRAuDxzjUWAVUAKMAr5mjOn0wHGVUkoNkCfC/UpgJ3AJkA78S0TWGWPqTm8oIsuB5QChoaGzJk2a5IHTK6XU8LFt27ZKY0xsX+08Ee63AL8wXYvU5InIEWAS8OnpDY0xK4AVANnZ2Wbr1q0eOL1SSg0fInLUnXaemApZCFzafdJ4YCKQ74HjKqWUGqA+e+4i8jxds2BiRKQI+AkQAGCMeQL4GbBSRHYDAtxnjKn0WsVKKaX61Ge4G2OW9fF6CXCFxypSSik1aPqEqlJK2ZCGu1JK2ZCGu1JK2ZCGu1JK2ZCGu1JK2ZCGu1JK2ZAnnlBVfuy5zYVWlzBgN85JsboEpXyW9tyVUsqGNNyVUsqGNNyVUsqGNNyVUsqGNNyVUsqGNNyVUsqGNNyVUsqGNNyVUsqG+gx3EXlaRMpFZM852iwSkZ0isldE1ni2RKWUUv3lTs99JbD4bC+KSATwR2CJMWYq8FXPlKaUUmqg+gx3Y8xaoPocTW4EXjHGFHa3L/dQbUoppQbIE2PuGUCkiHwsIttE5JseOKZSSqlB8MTCYS5gFnApMALYKCKbjDEHT28oIsuB5QApKbrok1JKeYsneu5FwDvGmAZjTCWwFsjqraExZoUxJtsYkx0bG+uBUyullOqNJ8L9dWChiLhEJASYA+z3wHGVUkoNUJ/DMiLyPLAIiBGRIuAnQACAMeYJY8x+EXkHyAE6gaeMMWedNqmUUsr7+gx3Y8wyN9o8AjzikYqUUkoNmj6hqpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNqThrpRSNtRnuIvI0yJSLiLn3F1JRGaLSIeIXOe58pRSSg2EOz33lcDiczUQESfwMPCuB2pSSik1SH2GuzFmLVDdR7O7gZeBck8UpZRSanAGPeYuIknAl4An3Gi7XES2isjWioqKwZ5aKaXUWXjihurvgPuMMR19NTTGrDDGZBtjsmNjYz1waqWUUr1xeeAY2cALIgIQA3xBRNqNMa954NhKKaUGYNDhboxJO/WxiKwEVmuwK6WUtfoMdxF5HlgExIhIEfATIADAGNPnOLtSSqmh12e4G2OWuXswY8y3BlWNUkopj9AnVJVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY03JVSyoY8sbaMUqofnttcaHUJA3LjnBSrS1D9oD13pZSyIQ13pZSyIQ13pZSyIQ13pZSyIQ13pZSyIQ13pZSyoT7DXUSeFpFyEdlzlte/LiI53b82iEiW58tUSinVH+703FcCi8/x+hHgImNMJvAzYIUH6lJKKTUI7uzEtFZExp7j9Q09Pt0EJA++LKWUUoPh6TH3W4G3PXxMpZRS/eSx5QdE5GK6wn3BOdosB5YDpKToo8xKKeUtHum5i0gm8BSw1BhTdbZ2xpgVxphsY0x2bGysJ06tlFKqF4MOdxFJAV4BvmGMOTj4kpRSSg1Wn8MyIvI8sAiIEZEi4CdAAIAx5gngASAa+KOIALQbY7K9VbBSSqm+uTNbZlkfr98G3OaxipRSSg2aPqGqlFI2pOGulFI2pDsxDUP7S+v4yydHOFzRQElNEwFOB5nJ4UxPjiAkSN8SStmBficPI8U1TfznK7tZc7CCkEAn08dEED4igLqmNlbnlPL2njIunhjHoomxOLpujiul/JSG+zCxp7iWW1Zuobm1gx9eOZGb5qQSHhLw2X6epbVNfJxbwfv7j1NS08R1s5IJDnBaXLVSaqB0zH0YWHeoguv/tJFAp4OXvzOPuy4eT3hIwOfajA4fwQ2zx3D1eaM5UFbHk+vyaWnrsKhipdRgabjbXF55PXc+u52UqBBe/c48MuJHnbWtiDB/fAzfnDuW43XNvLj1GJ3GDGG1SilP0XC3sfqWdr79zFaCXA6e/tZs4sKC3fpzGfGjuCYzkQNlJ3lnT5mXq1RKeYOOuduUMYb/eGkXBVWNPHvrHBIjRvTrz18wLpryky2sz6skNTqEqYnhXqpUKeUN2nO3qVW7Snhnbxn3LZ7I3PToAR3j6vNGMzo8mFW7Smhq1fF3pfyJhrsN1Ta18fM395OZHM6tC8YN+DhOh/DlGcnUN7fzzl4dnlHKn2i429Cv38ulqr6Fh754Hk7H4OarJ0WOYMH4GLYUVJNfWe+hCpVS3qbhbjM5RTU8s+ko35w7lvOSPTNOfunkeCJDAngzp1RnzyjlJzTcbeaX7+QSFRLIPVdkeOyYgS4Hl09JoLS2md1FtR47rlLKezTcbWRzfhXr8yq5c1E6YcEBff+BfshMDichLJh/7T9OR6f23pXydX2Gu4g8LSLlIrLnLK+LiPyfiOSJSI6IzPR8maovxhh+/a+DxI0K4qYLUj1+fIcIV0yJp7qhla1Hqz1+fKWUZ7nTc18JLD7H61cBE7p/LQceH3xZqr8+yavi0yPV3HXxeK+tCTMxYRQpUSF8dKCcto5Or5xDKeUZfYa7MWYtcK6u2lLgb6bLJiBCREZ7qkDlnt+9f5DE8GBuOH+M184hIlw2OZ665nZ2Havx2nmUUoPniTH3JOBYj8+Lur+mhsi2oyfYevQEyy8cR5DLuys5pseGMjo8mHWHKnXmjFI+zBPh3ttE6l6/60VkuYhsFZGtFRUVHji1Anh6/RHCgl18Ndt7vfZTRISFE2KpqG8ht+yk18+nlBoYT4R7EdAzVZKBkt4aGmNWGGOyjTHZsbGxHji1OlbdyNt7SrlxTiqhQ7SL0nlJ4YSPCGDdIf0PWilf5YlwXwV8s3vWzAVArTGm1APHVW5YuaEAhwg3z/P8DJmzcTq6lgYuqGrkWHXjkJ1XKeU+d6ZCPg9sBCaKSJGI3Coid4jIHd1N3gLygTzgSeA7XqtWfU5dcxsvbjnGNZmjGR3ev1UfB2t2aiRBLgcb86uG9LxKKff0+XO8MWZZH68b4C6PVaTc9ur2Yupb2vm3BWlDfu6gACczUiLYUnCCq88bPWRDQkop9+gTqn7KGMNzmwvJTA4nMznCkhrOT4umo9Ow7egJS86vlDo7DXc/tb3wBLnHT7Ls/BTLakgICyY1OoRPC6p1WqRSPkbD3U/9fXMhI4NcLMlKtLSOOWnRVDe0crhclwNWypdouPuh2sY23swpZen0RMvHuqclhhES6GTzEV1vRilfouHuh17ZUURLeyc3zrFuSOYUl9PBrJRIDpTVUd/SbnU5SqluGu5+6MUtx8hMDveZTatnpkbSaWCnrjejlM/QcPcze0tqOVB2kq/OSra6lM/EhwWTHDmC7UdPYPTGqlI+QcPdz7y8rZhAp4NrLb6RerqZKZGU1TVTUtNsdSlKKTTc/UpbRyev7yzm0slxRIQEWl3O52QlR+ByCNsKdc67Ur5Aw92PfJxbQVVDK9f50JDMKSMCnUweHcauYzW060YeSllOw92PvLytiJiRgVyY4Zsras5KjaSprYMDuhSwUpbTcPcTtY1tfHDgOEunJxHg9M1/tvTYkYQGucgp0lkzdtLe0UlTawdNrR106ubofkNXe/IT7+4to63D8MXpvrvJldMhnJcUztaCaprbOry2l6vyvtb2TrYVniC3rI78igbaOw0/e3MfIYFOLp8Sz5KsRC7KiMXlox0NpeHuN97IKSE1OoRpSWFWl3JO05PD2ZRfxb7SOmamRFpdjuonYwz7Sut4M6eUmqY2okMDmZ0WRVRIINOSwjla1cDbe8p4fWcJmcnh/PK6TCYl+PZ7crjScPcDlfUtbDhcxZ0XpSPS266GvmNMVAiRIQHsOlaj4e5n2jo6eXl7ETlFtSSEBXN79hjSYkI/e/3UE9EPLp3Gm7tL+Pnq/Vz7h/X84PIMv3hvDjdu/UwlIotFJFdE8kTk/l5eTxGRj0Rkh4jkiMgXPF/q8PX2njI6Og3XZI22upQ+iQiZyREcrqjX5Qj8SHNbBys3FJBTVMsVU+K56+Lxnwv2ngJdDr40I5l/3XMRV0xJ4Jfv5PKz1fv1ATYf485OTE7gMeAqYAqwTESmnNbsv4GXjDEzgBuAP3q60OFs9a4SxseNZGL8KKtLcUvWmAg6DewurrW6FOWGptYOnlyXT2FVI9dnj2HRxDicjr574VGhgTx64wxumT+Wpz85wo9f2U2H3nD1Ge703M8H8owx+caYVuAFYOlpbQxwauAtnLNskK3673hdM58WVHNtZqLf/NibEBZMfFgQu3StGZ/X0Wl47tOjlNe18I25qUwf07+NX0SEB66Zwt2XjOeFLcf41Xu5XqpU9Zc74Z4EHOvxeVH313r6KXCTiBTRtafq3R6pTvFmTinG4BdDMj1lJUdQWN3IiYZWq0tRZ2GMYdWuYg5XNPDFGUlkDPAnQxHhnsszWHZ+Co9/fJjXdxZ7uFI1EO6Ee2/dxdN/9loGrDTGJANfAJ4RkTOOLSLLRWSriGytqKjof7XD0OqcEqaMDiM9dqTVpfTLqa3/dM6779p8pJotBSdYlBHLrNTB3fwWEf5nyVTOHxvFj/6Zw+4iHZKzmjvhXgSM6fF5MmcOu9wKvARgjNkIBAMxpx/IGLPCGJNtjMmOjfXNpyx9SdGJRrYX1vhdrx26xmNTokLYpd/kPqm8rpm3dpeSET+Sy6bEe+SYgS4Hf7xpJtGhgdz9/HYaW/WGupXcCfctwAQRSRORQLpumK46rU0hcCmAiEymK9y1az5Ib+aUAnBtpm+tAOmurORwyuqaKavTlSJ9SXtnJy9tO0agy8FXZibj8OC9nJiRQfz6+ukUVDXy8NsHPHZc1X99hrsxph34LvAusJ+uWTF7ReRBEVnS3exe4HYR2QU8D3zL6LyoQXsjp4SsMRGMiQqxupQBmZYUjgA5emPVp3x4oJySmma+PCOJUcEBHj/+3PRobpk/lr9uPMqGvEqPH1+5x6157saYt4wxGcaYdGPMQ91fe8AYs6r7433GmPnGmCxjzHRjzHveLHo4KKhsYE9xHddm+t+QzCmjggMYHzeSXUU1OgfaR5TVNbP2YAUzUyKZ4sWdvH505STGxYTyw3/m6PCMRXRhCB+1OqfrtsbVfhzu0HVj9URjG0UnmqwuZdgzxrBqZwlBLidXTUvw6rlGBDp5+LpMimuaeOyjPK+eS/VOw91HvbGrlNljIxkdPsLqUgZlyugwnA7RB5p8wM5jNRRUNbB4agKhQd5feWT22Ci+PCOJJ9ceoaCywevnU5+n4e6DDh4/Se7xkz63ld5AjAh0MiFuJDlFNXTq0Ixlmts6eGtPGWMiRzBr7NCt+XP/VZMIdDl4cPW+ITun6qLh7oNW7yrBIXDVNP8ekjklMzmCuuZ2CqsarS5l2FpzsIKGlnaWZCV5dHZMX+LCgvn+pRP48EA5Hx0oH7LzKg13n2OMYXVOKXPTo4kdFWR1OR4xOWEULoeQo0MzlqhtauOTvEqmj4kgKXLoh/m+NX8sY6ND+MXbB3TtmSGk4e5j9pbUkV/ZwDV+Ore9N0EBTiYmjGJPca0OzVjg/f3HMcDlkz3zsFJ/BTgd3HvFRHKPn+S1Hbo0wVDRcPcxq3NKcTmExVO9O5thqGUmR1Df0s4RvbE2pI7XNbP96AkuSIsiMjTQsjquPm8005LC+M2/DtLS3mFZHcOJhrsP6RqSKWHBhBhLvxG9YWL8KAKdDnJ0OYIh9d6+4wS6HFw8Mc7SOhwO4UdXTqK4pom/byq0tJbhQsPdh+w8VkPRiSZbDcmcEuhyMGn0KPaW1Oq46xApqWlif2kdCybEEDIEUx/7snBCDPPSo3nsozyaWrX37m0a7j5kdU4pgU4HV0y1ZmzU2zKTImhs7eBwRb3VpQwLHxwoJzjAwbxxZ6zhZwkR4QeXZ1DV0MrfNx+1uhzb03D3EZ2dhjdzSrloYixhXljvwxdkxI8kyKVDM0PhVK99/vgYRgQ6rS7nM7PHRjEvPZon1uTT3Ka9d2/ScPcRW4+eoKyu2RYPLp2Ny+lgyugw9pXW0t7RaXU5tnaq1z4/3Td67T1979IJVNa38NxmHXv3Jg13H/HGrhKCAxxcOsnaG1/elpkcQXNbJ4fKdWjGW8rqmj/rtQcH+E6v/ZQLxkUzJy2KJ9Yc1t67F2m4+4D2jk7e3lPKpZPih2TNDyuNjxvJiACn7tDkResPVRLgFOaOi7a6lLP6/qUTKD/Zwsvbi6wuxbY03H3ApvxqKutbudYPd1zqL6dDmJoYxv6yk7Tp0IzH1Ta1setYDdmpUYQE+m5HYW56NFnJ4Ty5Nl9nT3mJW+EuIotFJFdE8kTk/rO0uV5E9onIXhF5zrNl2tvqnBJCA50ssngu8lDJTI6gtb2T3LKTVpdiOxsPV9JpDPPH+95Ye08iwrcvSqegqpH39pZZXY4t9RnuIuIEHgOuAqYAy0RkymltJgA/BuYbY6YC/+6FWm2ptb2Td/aWccXUBJ8cH/WGtJhQQoNcutaMhzW3dbD5SDXTksKJ8oOH4K6cmkBqdAhPrDmsm7l4gTs99/OBPGNMvjGmFXgBWHpam9uBx4wxJwCMMbr8m5s+yaukprGNa/x8U47+cDqEaYlh5JbV6aPoHrS1oJqW9k4WTvDtXvspTodw+8Jx7CqqZfORaqvLsR13wj0JONbj86Lur/WUAWSIyCcisklEFnuqQLt7I6eEsGAXCyfEWl3KkMpMjqCtw3CgVIdmPKGj0/DJ4SrSYkJJjvSfPXevm5VMdGggf1pz2OpSbMedcO9t8efTf4ZyAROARcAy4CkRiTjjQCLLRWSriGytqKjob62209zWwXt7j7N4WgKBruF1bzs1OoSwYB2a8ZTdxTXUNrX5Ta/9lOAAJ9+aN5aPcis4UFZndTm24k6iFAFjenyeDJT00uZ1Y0ybMeYIkEtX2H+OMWaFMSbbGJMdGzu8eqq9WXOwgvqWdls/uHQ2DhGmJYVz8PhJnes8SMYY1h2qJG5UEBnxo6wup9++MTeVEQFOVqzNt7oUW3En3LcAE0QkTUQCgRuAVae1eQ24GEBEYugaptF/qT68sauE6NBAn56P7E2ZyRF0dBr2lWiPbTDyKuoprW1m4YSYId1lyVMiQgK54fwxrNpZQkmNbqTuKX2GuzGmHfgu8C6wH3jJGLNXRB4UkSXdzd4FqkRkH/AR8ENjTJW3iraDxtZ2PthfzuJpCbicw2tI5pQxkSOICAkgp1gfaBqM9YcqGRXsIiv5jJFQv3HbwnEY4On1R6wuxTbcShVjzFvGmAxjTLox5qHurz1gjFnV/bExxtxjjJlijDnPGPOCN4u2g/f2HqeprYOl00+/Nz18iAjnJYWTV15PY0u71eX4pdLaJg6V1zNvXLRfdxKSIkawJCuR5z8tpLapzepybMF/3w1+7rWdxSRFjCA7deh2ovdFmUkRdBrYW6pDMwOx/lAlgU4H56f5/9DebQvTaGjt4PlPdUExT9Bwt0BlfQvrDlWydHoiDof/jZF6UmJEMNGhgbrWzADUNLayq6iG2WMjfWpZ34GamhjOvPRoVn5SQGu7Lk0xWBruFli9q4SOTsMXZwzfIZlTRITzksPJr2jgZLP+ON4fGw533daa5+NLDfTH7QvHUVbXzFu7S60uxe9puFvgtZ0lTB4d5pfT1rwhMykCA+zVWTNua27rYEtB11IDkSG+v9SAuy7KiGV83EieXJevSxIMkob7EDtS2cDOYzV8acbwm9t+NvFhQcSNCmLnMR2acdenR04tNWCv50UcDuG2BWnsLaljY75OuBsMDfch9vrOYkRgSZYOyZwiIswYE0FhdSNV9S1Wl+Pz2js72XC4knGxoSRFjLC6HI/74owkokMDeWqdToscDA33IWSM4bUdxVyQFk1CeLDV5fiUrDERCGjv3Q05RbXUNbdzoc167acEBzj5xtxUPjxQTl65rj00UBruQ2hXUS0FVY18SW+kniEiJJC0mFB2HqvRsdZzMMaw/lAl8WFBTIgbaXU5XvONC1IJcjn48/oCq0vxWxruQ+i1HcUEuhwsPi/B6lJ80oyUCKoaWjl2Qh9BP5tD5fWU1TWzcHws4odLDbgremQQX56ZzCvbi3SoboA03IdIe0cnq3NKuHRSHGHBAVaX45OmJobjcgg7Ck9YXYrPWneogrBgF5ljwq0uxetuXZBGS3snz2w6anUpfknDfYisz6uksr5V57afQ3CAkymJYeQU1dKu+6ueobimicMVDcxLj8HlsP+37vi4kVwyKY5nNh7VlUMHwP7vEB/x2o5iwoJdLJpoz5tgnjIzJZKmtg726/6qZ1h/qIIgl4Pz06KsLmXI3LYwjaqGVl7dUWx1KX5Hw30InGxu4529ZVyTlUiQy/8fE/em8XEjCQt2sf2oDs30dKKxld3FtcweGzVs9toFmDsumqmJYfx5/RE6O/VGe39ouA+B1TmlNLd1cn32mL4bD3MOEWamRnLw+EldHbCHDXmVAMxL9/8FwvpDRLhtYRp55fWsOai7t/WHhvsQeGnrMTLiR5KVbP+bYJ4wKyUSA3pjtVtjaztbjp4gMzmCCBstNeCuazITSQgL5sl1uv9Pf2i4e9mh4yfZUVjD9dljbD11zZOiRwaRFhPKtqMndM47sDG/itb2Tts+tNSXAKeDb80fy4bDVezRPXfd5la4i8hiEckVkTwRuf8c7a4TESMi2Z4r0b/9Y1sRLofoLJl+mpUaSVVDKwVVjVaXYqnW9k42Hq5iUsKoYf1U841zUhgV5OLxjw9bXYrf6DPcRcQJPAZcBUwBlonIlF7ajQK+B2z2dJH+qq2jk1e2F3Hp5DhiRgZZXY5fmZYYTpDLwZaCaqtLsdSWgmoaWztYlDE8e+2nhAUHcNPcVN7aU0p+Rb3V5fgFd3ru5wN5xph8Y0wr8AKwtJd2PwN+CTR7sD6/9sH+41TWt+qN1AEIdDmYkRLJ7uJaGobpFnztHZ2sO1RBWkwoKdGhVpdjuX+bn0ag08Gf1ujYuzvcCfck4FiPz4u6v/YZEZkBjDHGrD7XgURkuYhsFZGtFRX2v/P97KZCEsODWTQxzupS/NL5aVF0dBq2D9MbqzuP1VDX3D7se+2nxI4K4muzx/DKjiJKa3WJir64E+693QX87C6XiDiA3wL39nUgY8wKY0y2MSY7Ntbeb9gjlQ2sz6tk2fkpOIf5VnoDlRAWTGp0CJ8eqaZzmN1Y7TSGNQcrSIwIZryNFwjrr9sXjqPTwJNrdTngvrgT7kVAz3GFZKCkx+ejgGnAxyJSAFwArBruN1Wf23wUl0P42mwdkhmMOWlRVDW0kl/RYHUpQ2pPcS1VDa0syojTWVY9jIkKYWlWIs9/Wkh1Q6vV5fg0d8J9CzBBRNJEJBC4AVh16kVjTK0xJsYYM9YYMxbYBCwxxmz1SsV+oLmtg39sK+KKqfHEhQ3fGQ6eMC0xnJBAJ5uG0a48prvXHjMyiCmJYVaX43PuWJROU1sHKzcUWF2KT+sz3I0x7cB3gXeB/cBLxpi9IvKgiCzxdoH+6K3dpdQ0tvH1OalWl+L3XE4H2alR7C+t48Qw6akdKq+ntLaZizJicWiv/QwZ8aO4Yko8Kz85Qv0wvdnuDrfmuRtj3jLGZBhj0o0xD3V/7QFjzKpe2i4azr12YwwrNxQwLiZ02D0q7i0XjItChGGxp6Yxho9yywkfEUDWMFjWd6C+c/F46prbeW6zLgd8NvqEqodtLzxBTlEtt8wfq2OlHhIREsi0pHC2FFTTYvOlX/Mq6jla1chFGbHDYlnfgZo+JoJ56dE8ue6ILgd8Fvru8bA/rz9CWLCLr8xKtroUW5mfHkNLeyfbbDwt0hjD+/uOEzEigOzUSKvL8Xl3XzKBipMtPLe50OpSfJKGuwcVnWjknT1lLJuTQkigy+pybGVMVAgpUSFsOFxl22mRucdPcuxEExdPisPl1G/NvsxNj2buuGj++PFhmlq19346fQd50N82HkVEuHnuWKtLsaX542OobmhlX0md1aV4nDGG9/cfJyo0kJkp2mt31z1XZFBZ38KzuhXfGTTcPeRkcxvPf1rI4mkJJEaMsLocW5qaGEZ0aCAf55bbbrXIvSV1lNQ0c8nEOH3orR9mj41i4YQYHl9zeNguU3E2Gu4e8uymQk42t3PHhelWl2JbDhEuyoilpLaZg8fts3hUR6fh3b1lxI0KYnpKhNXl+J0fXJ5BdUMrf/lEn1rtScPdA5rbOvjz+nwuzIjlPN2Qw6ump0QQPiLAVr33LQXVVDW0snhags5rH4CZKZFcPiWeJ9bk61OrPWi4e8CLW45RWd/KXYu01+5tLoeDCyfEcLS6kc1H/H854Ja2Dj7Yf5y0mFAmxo+yuhy/dd/iiTS2tvOHDw9ZXYrP0HAfpNb2Tv605jDZqZHDald6K2WPjWJkkIvf/uug3/fe1x6qoKG1g6umJehzEYMwPm4U12eP4dlNRykc5hu8nKLhPkiv7iiipLaZuy4er9+cQyTA6eDiibFsPlLN2kOVVpczYNUNraw7VElmcjjJkSFWl+P3fnB5Bk6H8Mh7uVaX4hM03Aehpb2D379/iKzkcBZNtPcSxr5mdloUyZEj+OU7B+js9M/e+5u7S3H0DFQaAAAO5UlEQVSIcNW00VaXYgvxYcHcvnAcb+wqYesw38ELNNwH5e+bCimpbeaHV07SXvsQczkc3HtFBntL6nhzd6nV5fTbweMn2V9ax8UTYwkfEWB1ObZx56J0EsKC+ekbe+nw0//0PUXDfYAaWtp57KM85qVHs2BCjNXlDEtLspKYGD+KX72XS0u7/zyh2NbRyeqcEqJDA5k/Xt87nhQS6OLHX5jEnuI6/rH1WN9/wMY03AfoL58coaqhlf+4cqLVpQxbTofw4y9M4mhVI0+vL7C6HLd9lFtOZX0r12Yl6jIDXrAkK5HZYyN55N1capvarC7HMvrOGoDyumYe//gwl0+J10fFLbZoYhyXT4nnDx8e8ot9NfeV1LH2YAUzxkSQoVMfvUJE+Mm1UznR2MrD7xywuhzLuBXuIrJYRHJFJE9E7u/l9XtEZJ+I5IjIByJi610qHn4nl9aOTv7zC5OtLkUBD1wzhY5Ow0Nv7re6lHNq7+jkvpdzGBHo4urz9CaqN01LCufWBWk8t7mQT23wPMRA9BnuIuIEHgOuAqYAy0RkymnNdgDZxphM4J/ALz1dqK/YUXiCl7cX8W8L0kiLCbW6HEXXipF3LkpndU4p6314auQTaw6zu7iWJVmJhATpqqHe9oPLM0iKGMGPX8nxq3synuJOz/18IM8Yk2+MaQVeAJb2bGCM+cgYc+rJgU10baJtO52dhp++sY/YUUHcfckEq8tRPdxxUTrjYkK57+UcTjb73jjrtqMn+O37h7g2K5Fpui/qkAgJdPHzL03jcEUDj32YZ3U5Q86dcE8Cet52Lur+2tncCrw9mKJ81XOfFrLrWA33LZ7ESO15+ZTgACe/uj6L0tomfr7at4Zn6prb+P4LOxgdHsxDX5qm02aH0MUT4/jyzCQe+/gwO2y80Utv3An33t6JvU4gFZGbgGzgkbO8vlxEtorI1oqKCver9AElNU384u0DzB8fzVdmnuv/NmWVmSmR3HFROi9uPcaHB45bXQ7QtU77j1/ZTWltM7+/YQZhwTqnfaj9dMlUEsKC+cGLO2lsHT7LArsT7kXAmB6fJwMlpzcSkcuA/wKWGGNaejuQMWaFMSbbGJMdG+s/T3QaY/jPV3fT0Wn4xZczteflw75/2QQmJYzih//IoaTG+tkzj685zJs5pdx7RQazdOs8S4QFB/Dr67M4Wt3Iz338prsnuRPuW4AJIpImIoHADcCqng1EZAbwJ7qCvdzzZVrr1R3FfJxbwQ+vnMiYKF0DxJcFuZw8euNMWto7ufPZbZZunvz+vuM88m4u12YlcudFumKolS4YF83yheN4bnMhq3ad0Te1pT7D3RjTDnwXeBfYD7xkjNkrIg+KyJLuZo8AI4F/iMhOEVl1lsP5nSOVDfy/1/Ywe2wkN88ba3U5yg3j40byq69msauolp+8vteSGvYU1/LvL+5kWmI4v/yK/rTnC/7jyolkp0Zy/8s5HDp+0upyvM6tee7GmLeMMRnGmHRjzEPdX3vAGLOq++PLjDHxxpjp3b+WnPuI/qGlvYO7n99OgMvB72+Yoduf+ZHF0xK46+Ku8fc/fjy0MyXyyk/yzac/JXxEACu+OYsRgc4hPb/qXYDTwaM3ziQk0Mkdz26j3ubb8ukTqufwv28dYE9xHY9cl6X7ovqhey+fyNLpifzynVyeGaINlAurGvn6U5txiPDsbXMYHa7vG1+SEB7M/y2bwZHKBr73/A7aOzqtLslrNNzP4qWtx1i5oYBb5o/l8inxVpejBsDhEH711SwumxzHA6/v4SUvLyS1p7iWrzyxgZb2Tv5+2xx9yM1HzUuP4cGl0/jwQDn/88Y+v9/w5Ww03HuxKb+K/3p1NwvGx+gSA37u1I/iC8bH8KN/5vC7972ze9OagxV87U8bCXQ6+Me35zIxQdeN8WU3XZDKty8cxzObjrJibb7V5XiFhvtp8ivquePZbaREhfDY12cSoKv2+b3gACd/vnk2181K5nfvH+Kel3Z5bLy1vaOT37yXyy1/+ZSU6FBe+c48JuiCYH7hvsWTuDpzNP/79gH+trHA6nI8Th+z7OFoVQM3PrkZpwh/vnm2bqJgI4EuB49cl0lKVAi/ff8gW49W88h1WVwwLnrAx8wtO8n9r+Swo7CG62Yl89MlU/XJZT/icAi/vX46re2dPPD6XpwO4etz7LPmoXZLuxWdaOTGJzfT3N7Bs7fNYayOl9qOiPC9Syfw0rfn4hBh2ZObuPv5HRzs57S44pomfvTPXVz1+7XkVzTwh2Uz+NVXszTY/VCgy8GjN87gkklx/Nere3jSRkM0+m6ka8uzW/6yhZPNbTx3+wVMHq0LO9nZ7LFRvP39hTz6YR5/3VDA6pwSLsqIZfHUBC6ZHEfcqODPtTfGUFLbzJYj1byyo5j1hypwORzcuiCNuy4eT0RIoEV/E+UJQS4nj980k3te3MVDb+2ntLaZ/756Mg4/n/o87MN94+Eqlj+zleAAJ8/dfgHTksKtLkkNgZBAFz9aPInbF47j6U+O8OqOYu7P3Q1A+IgAUqNDCHA6aG7r4HhdM5X1rQAkRYzguxeP5/rZY0iO1KeV7SLI5eQPy2YQHxbM058cobC6gV9/dTrhIf47NDtsw90Yw183FPDQW/tJjQ5l5S2z9Zt1GIoMDeTeKyZyz+UZHCg7ySd5lRRUNXC0qpFOY4gYEcCU0WGclxxOVnIE5yWF+32PTvXO4RAeuHYKqdEh/Gz1Pq55dB2Pf32W33b4hmW41zS2ct/LOby79ziXTorjN9f79//QavBEhMmjw3RITnHzvLFMSwrnu89t50t//IS7L5nAnYvS/W7mnH9VO0jGGF7fWcxlv1nDB/vL+e+rJ/PUzdka7Eqpz5mVGsmb31vI4mmj+c2/DrLk0U/YWuBf2/UNm3DfdayGb/z5U77/wk4SI0bw2l3zuW3hOF3QSSnVq6jQQP6wbAYrvjGL6oYWrntiI3c8s43DFfVWl+YWWw/LGGPYUnCCFWvzeX//cSJDAvifJVO56YJUXQRMKeWWK6YmsGBCDE+tO8ITaw7z7r4yrpgSz/ILxzEzJdJnO4i2DPfimibe2VPGS1uOkXv8JGHBLu69PINbFqTpXGSlVL+FBLr43qUTuHFOCn/dUMDfNh7l3b3HGR83kq/MTOaazNE+t9eDLZKusr6F3UW1bD5SzcbDlewqqgVgWlIYD3/lPK7NSiQk0BZ/VaWUhWJGBnHvFRO546J0Xt9Zwsvbi3j4nQM8/M4B0mNDuTAjllmpkcxIiSQxPNjSXr1biScii4HfA07gKWPML057PQj4GzALqAK+Zowp8GypXfaW1PLq9mLK6po5XtdMfkUDVQ1dc5ADnEJmcgQ/vHIiV01LYFzsSG+UoJQa5kKDXNw4J4Ub56RwtKqB9/eX89GBcv6+uZC/fFIAwMggF2kxoSRHjiB6ZCBRIYEEBTgJcArTx0RyflqUV2vsM9xFxAk8BlxO136qW0RklTFmX49mtwInjDHjReQG4GHga94ouPhEE89uPkpCWDBxYcFcNjmejIRRTB49ihljInVjBKXUkEqNDuXWBWncuiCN1vZODpTVsetYDXnl9eRXNnCovJ5N+S2caGz77M/cuSjd+nAHzgfyjDH5ACLyArAU6BnuS4Gfdn/8T+BRERHjhbVVL5scz/4HF/vsTQyl1PAV6HKQmRxBZnLEGa8ZY2jrMLR1dA7JhA53pkImAT13OSjq/lqvbbr3XK0FBr7c3jk4HKLBrpTyOyJCoMtBaJCL4ADvjzC403PvLUlP75G70wYRWQ4s7/60XkRy3Ti/J8UAlUN8Tl/nt9fk6949vN9eF2/5ul6T3lhxTdxal9idcC8CxvT4PBkoOUubIhFxAeHAGY9zGWNWACvcKcwbRGSrMSbbqvP7Ir0mvdPrcia9Jmfy5WvizrDMFmCCiKSJSCBwA7DqtDargJu7P74O+NAb4+1KKaXc02fP3RjTLiLfBd6layrk08aYvSLyILDVGLMK+DPwjIjk0dVjv8GbRSullDo3t+a5G2PeAt467WsP9Pi4GfiqZ0vzCsuGhHyYXpPe6XU5k16TM/nsNREdPVFKKfsZNqtCKqXUcGLrcBeRKBH5l4gc6v498iztOkRkZ/ev028W24KILBaRXBHJE5H7e3k9SERe7H59s4iMHfoqh5Yb1+RbIlLR471xmxV1DiUReVpEykVkz1leFxH5v+5rliMiM4e6xqHmxjVZJCK1Pd4nD/TWbqjZOtyB+4EPjDETgA+6P+9NkzFmevevJUNX3tDosYTEVcAUYJmITDmt2WdLSAC/pWsJCdty85oAvNjjvfHUkBZpjZXA4nO8fhUwofvXcuDxIajJais59zUBWNfjffLgENTUJ7uH+1Lgr90f/xX4ooW1WOmzJSSMMa3AqSUkeup5rf4JXCr2fhTYnWsy7Bhj1tLLMyo9LAX+ZrpsAiJEZPTQVGcNN66JT7J7uMcbY0oBun+PO0u7YBHZKiKbRMSO/wH41BISPsKdawLwle7hh3+KyJheXh9u3L1uw81cEdklIm+LyFSriwEbrOcuIu8DCb289F/9OEyKMaZERMYBH4rIbmPMYc9U6BM8toSEjbjz930DeN4Y0yIid9D1k80lXq/Mtw2394k7tgOpxph6EfkC8Bpdw1aW8vtwN8ZcdrbXROS4iIw2xpR2/+hYfpZjlHT/ni8iHwMzADuFu8eWkLCRPq+JMaaqx6dPYvP7EG5y5700rBhj6np8/JaI/FFEYowxlq7DY/dhmZ7LItwMvH56AxGJ7N5sBBGJAebz+eWM7UCXkDhTn9fktLHkJcD+IazPV60Cvtk9a+YCoPbU0OdwJSIJp+5Picj5dOVq1bn/lPf5fc+9D78AXhKRW4FCup+iFZFs4A5jzG3AZOBPItJJ1z/KL07biMTv6RISZ3LzmnxPRJYA7XRdk29ZVvAQEZHngUVAjIgUAT8BAgCMMU/Q9aT6F4A8oBG4xZpKh44b1+Q64E4RaQeagBt8oWOkT6gqpZQN2X1YRimlhiUNd6WUsiENd6WUsiENd6WUsiENd6WUsiENd6WUsiENd6WUsiENd6WUsqH/Dy2dwxgQYJZ0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(obs_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the proportions of smokers among sex 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lars9\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(obs_train[1][obs_train[0] == 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the proportions of smokers among sex 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lars9\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPW9//HXZzJZIAtkXwgJAcK+E0AEFa0KaBVtrQK2ta2W295ab9tfe6u3Vqxtvb23i7euLVZvrXWttQgVpYgoKIuE1bCHQBYSyEr2Pd/fHxl6x0jIkExyZuZ8no/HPDJzlpnPTJJ3Tr7ne75fMcaglFLKPhxWF6CUUmpgafArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNOK0u4Hzi4uLMiBEjrC5DKaX8xq5du8qNMfGebOuTwT9ixAiys7OtLkMppfyGiOR7uq029SillM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM345JW7yje9uKPA6hI8tnxOmtUlKOWzegx+EXkW+CxQaoyZdJ71PwBud3u+8UC8MaZSRE4CtUA70GaMyfJW4UoppXrHk6aePwKLultpjPmlMWaaMWYacB/wvjGm0m2TK13rNfSVUsoH9Bj8xpjNQGVP27ksA17qU0VKKaX6lddO7orIYDr/M/ir22ID/ENEdonIih72XyEi2SKSXVZW5q2ylFJKdeHNXj03AB92aeaZZ4yZASwGviUil3e3szFmlTEmyxiTFR/v0ZDSSimlesGbwb+ULs08xphi19dS4G/AbC++nlJKqV7wSvCLyBDgCuANt2XhIhJ57j5wLZDjjddTSinVe55053wJWADEiUgRsBIIBjDG/M612c3AP4wx9W67JgJ/E5Fzr/OiMeZt75WulFKqN3oMfmPMMg+2+SOd3T7dl+UBU3tbmFJKqf6hQzYopZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTNaPArpZTN9Bj8IvKsiJSKSE436xeISLWI7HXdHnBbt0hEjohIrojc683ClVJK9Y4nR/x/BBb1sM0WY8w01+0hABEJAp4AFgMTgGUiMqEvxSqllOq7HoPfGLMZqOzFc88Gco0xecaYFuBlYEkvnkcppZQXeauNf66I7BORt0RkomvZMKDQbZsi17LzEpEVIpItItllZWVeKksppVRX3gj+3UC6MWYq8Biw2rVczrOt6e5JjDGrjDFZxpis+Ph4L5SllFLqfPoc/MaYGmNMnev+OiBYROLoPMIf7rZpKlDc19dTSinVN30OfhFJEhFx3Z/tes4KYCeQKSIZIhICLAXW9PX1lFJK9Y2zpw1E5CVgARAnIkXASiAYwBjzO+AW4Jsi0gY0AkuNMQZoE5G7gfVAEPCsMeZAv7wLpZRSHusx+I0xy3pY/zjweDfr1gHreleaUkqp/qBX7iqllM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM1o8CullM30GPwi8qyIlIpITjfrbxeR/a7bVhGZ6rbupIh8LCJ7RSTbm4UrpZTqHU+O+P8ILLrA+hPAFcaYKcBPgVVd1l9pjJlmjMnqXYlKKaW8ydnTBsaYzSIy4gLrt7o93A6k9r0spZRS/cXbbfx3Am+5PTbAP0Rkl4isuNCOIrJCRLJFJLusrMzLZSmllDqnxyN+T4nIlXQG/3y3xfOMMcUikgBsEJHDxpjN59vfGLMKVzNRVlaW8VZdSimlPskrR/wiMgX4A7DEGFNxbrkxptj1tRT4GzDbG6+nlFKq9/oc/CKSBrwOfMkYc9RtebiIRJ67D1wLnLdnkFJKqYHTY1OPiLwELADiRKQIWAkEAxhjfgc8AMQCT4oIQJurB08i8DfXMifwojHm7X54D0oppS6CJ716lvWw/i7grvMszwOmfnoPpVRXL+4osLoEjy2fk2Z1CaqP9MpdpZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSyGQ1+pZSymR5n4FL2VdfcxoaDp1m7r4Tc0jpqm1pxiDA6IYKJKUPIiAsnyCFWl6mUukga/OpTjDG8+FEB/7nuMHXNbaQMCSNrRAyFlQ00tbazu6CKHScqSYoK43MzhpEaPdjqkpVSF0GDX33CmZomvv+XfWw5Vs680bF89+oxzEiLxuGQf84L29LWwcGSGt7OKeGp945z+Zh4rpmQiEP06F8pf+BRG7+IPCsipSKS0816EZFHRSRXRPaLyAy3dXeIyDHX7Q5vFa6879TZRm79/TZ25Vfxs5sm8ec755A1IgZHl+acEKeDacOH8m+fGcOM9GjeP1rGa7uKaO8wFlWulLoYnh7x/xF4HPhTN+sXA5mu2xzgKWCOiMQAK4EswAC7RGSNMaaqL0Ur7yusbGDZ09upbmjlhbvmMD0tusd9BoUE8fkZqcSEh7Dh4Bna2ju4ddZwnA7tM6CUL/PoN9QYsxmovMAmS4A/mU7bgaEikgwsBDYYYypdYb8BWNTXopV3VTe08sVndlDT2MoLX/cs9N1dOTaB6yYlkVNcw5q9xf1UpVLKW7zVxj8MKHR7XORa1t3yTxGRFcAKgLS0NC+VpXrS0WH4zit7KD7byMsr5jIldWivnmd+Zjz1Le28f7SM1OjBzM6I8XKlSilv8db/5Oc7q2cusPzTC41ZZYzJMsZkxcfHe6ks1ZNH3z3GpiNlPHDDRGamX9yRflfXTEgkMyGCtfuKKaio91KFSilv81bwFwHD3R6nAsUXWK58wNbccn678RifmzGML87p+39ZDhFumzWcIYODeXlnIc2t7V6oUinlbd4K/jXAl129ey4Bqo0xJcB64FoRiRaRaOBa1zJlscaWdu59/WPSYwbz85smI17qijk4xMmtM1Opbmzl7QOnvfKcSinv8qiNX0ReAhYAcSJSRGdPnWAAY8zvgHXAdUAu0AB81bWuUkR+Cux0PdVDxpgLnSRWA+Q3G45QUNnAS1+/hEEhQV597rTYcC4dFcuHxyuYkjqUjLhwrz6/UqpvPAp+Y8yyHtYb4FvdrHsWePbiS1P9ZV/hWZ754ATLZqcxd1Rsv7zGNROSOHS6ltd3F3HPZzIJDtIunkr5Cv1ttJmODsOP38ghLiKU+64b12+vE+J0cNO0YVTUt/BBbnm/vY5S6uJp8NvMG/tOsb+omnsXjyMqLLhfX2t0QgQTkqN4/0gZNU2t/fpaSinPafDbSFNrO798+wiThw3hpmnnvZzC6xZPSqK9w/DOwTMD8npKqZ5p8NvIMx+coLi6iR9dP/5T4+/0l9iIUOaOimVXfhXFZxsH5DWVUhemwW8TlfUtPLkpl2snJHLJyP45odudK8cmMCgkiPXavVMpn6DBbxNPb8mjobWdf180dsBfe1BIEJdnxnOstE6v6FXKB2jw20BlfQvPbT3JDVNSGJ0QaUkNl4yMJTwkiHcOl1ry+kqp/6PBbwNPb8mjsbWdez4z2rIaQpwOLh8TT25pHSfL9ahfKStp8Ac4XzjaP2dORizhoU7eOaw9fJSykgZ/gHvmA+uP9s8JcTq4IjOOvLJ6CiobrC5HKdvS4A9gdc1tPL8tn0UTkyw/2j9nVkYMg4KD2Hy0zOpSlLItDf4A9vJHBdQ0tbHi8pFWl/JPoc4gLhkZw6GSGkprm6wuRylb0uAPUK3tHTzzwQnmZMRc9FSK/W3uqDiCHMIHx3QMH6WsoMEfoNbuK6akuolvXDHK6lI+JSLUycz0aPYUnqWmUcfwUWqgafAHIGMMqzbnMSYxggVjfXMay8sy4+noMGzLq7C6FKVsR4M/AG07XsHh07XcNX+k12bW8raY8BDGJ0ex82Qlre0dVpejlK1o8Aeg/916kpjwEG6clmJ1KRc0d1QsDS3t7C86a3UpStmKBn+AKaho4J1DZ1g+O42wYO9OqehtI+PCSYgMZdvxCjoncVNKDQQN/gDz3LaTBInwpbnpVpfSIxFh7qhYiqubyK/QC7qUGigeBb+ILBKRIyKSKyL3nmf9IyKy13U7KiJn3da1u61b483i1SfVNbfx6s5CrpucTGJUmNXleGT68GjCgh1s1ZO8Sg2YHidbF5Eg4AngGqAI2Ckia4wxB89tY4z5rtv23wamuz1FozFmmvdKVt1ZvecUtc1tfGXeCKtL8ViI00FWegxbj5dT3djKkEH9Ox2kUsqzI/7ZQK4xJs8Y0wK8DCy5wPbLgJe8UZzynDGGF3YUMDEliunDh1pdzkW5ZGQsxsAOPepXakB4EvzDgEK3x0WuZZ8iIulABvCu2+IwEckWke0iclOvK1UXtKfwLIdKarh9TrrPduHsTkx4COOSo/hIu3YqNSA8Cf7zpUh3XTCWAq8ZY9rdlqUZY7KA5cD/iMh5LyUVkRWuPxDZZWU6gNfFemF7ARGhTp/vwtmduSPPde2stroUpQKeJ8FfBAx3e5wKFHez7VK6NPMYY4pdX/OA9/hk+7/7dquMMVnGmKz4eN+82tRXnW1o4e/7i7lpegoRoT2etvFJo+LPde0s166dSvUzT4J/J5ApIhkiEkJnuH+qd46IjAWigW1uy6JFJNR1Pw6YBxzsuq/qm7/uPkVzWwfLZ/t+F87uuHft1LH6lepfPQa/MaYNuBtYDxwCXjXGHBCRh0TkRrdNlwEvm08ero0HskVkH7AJ+IV7byDVd50ndfOZnjaUCSlRVpfTJ9OGDyXU6WDHiUqrS1EqoHnULmCMWQes67LsgS6PHzzPfluByX2oT/Vge14leWX1/OoLU60upc9CnUFMGz6U7Pwqrp+cTLifNlsFkg5jKKttprCygZKaJoyBo2dqSY0eRNaIGCamRBEcpNeB+hv9zfJzL+zIJyrMyWenJFtdilfMGRnLjhOV7Mqv4vIxeq7HKk2t7ezKr2Lr8XKqGjqHzg5xOnA6hAPF1dQ2tQEQFeZk+Zx0vjpvhN9cNKg0+P1aWW0z6w+c5kuXjPD5cXk8lRQVRnrsYD46Wcn8zDgcftY11d8ZY9iVX8W6nBKaWjtIjx3MVeMSSI8JJzYiBBFh+Zw0ztQ0kX2yijc/LmbV5uM880Eed102ku9cnUmoMzB+FgOZBr8f+8uuQlrbDcvnpFldilfNyYjl1exCckvrGJPoG3MF28HZhhb+uruI42X1ZMSFs3hSEqnRg8+7bWJUGNdPSeb6KcnkV9Tz6MZcnnrvOO8cPMOvb53KlFT/uojQbrRxzk91dBhe3FHAJSNjGJ0QYXU5XjUpJYrwkCA+0pO8A6awsoEn3ztOUVUjS6alcOf8jG5Dv6v02HB+fetU/vjVWdQ1t3HLU9tYs6+7Ht/KF2jw+6nNx8ooqmrk9jn+24WzO84gBzPTOydkr9apGfvdx6eqeXpLHsFBwjeuGMWcjNheNbEtGJvAunsuY9rwodzz0h6e2JSr12T4KA1+P/XCjgJiw0NYODHJ6lL6xeyMGAB2ntSj/v60v+gsL39UQMrQQXxzweg+n6CNDg/h+btms2RaCr9cf4TfbDjqpUqVN2nw+6GS6kY2HjrDrbOGE+IMzG9hTHgImYkR7DxZSXuHHjX2hwPF1byaXUh67GC+Ni/Da1d9hzqD+J/bprF01nAeezeXJzbleuV5lfcEZmoEuJc/KsQAy2YF1kndruZkxFLb1MahkhqrSwk4x8vqePmjQoYNHcQdc0d4/QBCRPj5zZO5yXXk//y2k159ftU3Gvx+pq29g5d3FnB5ZjxpsZ6dfPNXY5MiGToomB0ndLhmbyqvbeaFHfnERoTwlUszCO2nrsBBDuFXX5jK1eMTWbnmAJuP6uCLvkKD389sPFzKmZpmbg+wLpzn4xBhVkYMx8vqKa9ttrqcgNDQ0sZz207iEOHLc0cwKKR/+9w7gxz8duk0xiRG8q0Xd3O8rK5fX095RoPfz7ywo4CkqDCuGpdgdSkDIis9GofAR3qSt886jOGVnYWcbWzli3PSiQkPGZDXDQ918vSXswgOcvD157KpbdKeWlbT4PcjBRUNbD5axtLZw3HaZHyUyLBgJqYMYVd+lU7S0kebj5ZxrLSOz05JZkRc+IC+9vCYwTx1+wxOVtTzo7/laDdPi9kjPQLEix8V4BC4bdbwnjcOILMzYmhsbedjnaSl1/LK69hw8AxTUocwe0SMJTXMGRnL964Zw5p9xbyaXdjzDqrfaPD7iea2dv6SXchnxieSPGSQ1eUMqJFx4cRHhOpJ3l5qaG7jlZ2FxEaEcPO0YZZOzfnNBaOZPzqOlWsOcPRMrWV12J0Gv59Yf+AMFfUttjip25WIMDsjhsKqRorPNlpdjl8xxrB67ykamttZOiut33rweCrIITxy2zTCQ5x895W9tLRp850VNPj9xAvb80mNHsTlmfYcqnhGWjTBQaJH/Rdpb+FZcopruHpCIilDfeM/xfjIUB7+3GQOFNfwuF7cZQkNfj9w7EwtO05UsnxOGg6HPYcpHhQSxJTUoewtPEtTa7vV5fiFsw0trNlXTHrsYC7LjLO6nE9YODGJz80YxhObctlXeNbqcmxHg98PPL89n5AgB7dl2eukbldzMmJobTfsKaiyuhSfZ4zhb3tOYQx8YeZwn5zXYOUNE0mIDOX7f9mnTT4DTIPfx9U1t/H67lNcPyWZ2IhQq8uxVGr0YIYNHcSOE5XaHbAHewrOcqy0joUTEwesv/7FGjIomIdvnsyx0jp+//5xq8uxFQ1+H7d6zynqmtv44iWBN/xyb8zJiKG0tpmTFQ1Wl+KzaptaefPjEtJjBzNnZKzV5VzQleMSuH5KMo9tyiVPr+odMB4Fv4gsEpEjIpIrIveeZ/1XRKRMRPa6bne5rbtDRI65bnd4s/hAZ4zhz9vzmZgSxYw0ndEIYErqUMKCHXqS9wLW7Cumtb2Dz01P9ckmnq5WfnYCoU6HXtg1gHoMfhEJAp4AFgMTgGUiMuE8m75ijJnmuv3BtW8MsBKYA8wGVopItNeqD3DZ+VUcPl3Lly5Jt7TvtS8JcTqYmRZNzqlqnaTlPA6fruFAcQ1XjUsgPtI/mgYTosL44aJxbMur4K+7T1ldji14csQ/G8g1xuQZY1qAl4ElHj7/QmCDMabSGFMFbAAW9a5U+3l+Wz6RYU5unJZidSk+Ze6oOIyB7Xl61O+upa2DtfuKSYgMZb6P9eLpyfLZacxMj+bnbx6ksr7F6nICnifBPwxwv766yLWsq8+LyH4ReU1EznU/8XRf1UVZbTNv5ZRwy8xUBod4Z4KMQBETHsKElCg+OlGpvUHcbDpSSlVDK0umDcPp8K/Tdw6H8PDNk6ltauNnbx60upyA58lPx/naGLo2xK0FRhhjpgDvAM9dxL6dG4qsEJFsEckuK9Nxu1/NLqS13ehJ3W7MGxVHY2s7ewq1ayfAmZomthwrY0ZaNBkDPACbt4xNiuRfrhjJ67tP8WFuudXlBDRPgr8IcO9AngoUu29gjKkwxpwbMP1pYKan+7o9xypjTJYxJis+3p5Xp57T3mF4YXs+80fHMSo+wupyfFJ6bGfXzq25FXTY/ISgMYY39hYT6gxi0ST/noP521dlkh47mB+vzqG5TS/U6y+eBP9OIFNEMkQkBFgKrHHfQESS3R7eCBxy3V8PXCsi0a6Tute6lqkLePdwKcXVTXq0fwEiwrzRsZTVNZNbau9ugHsKznKyop5Fk5K8Nm+uVcKCg/jJjRPJK6/nD1tOWF1OwOox+I0xbcDddAb2IeBVY8wBEXlIRG50bXaPiBwQkX3APcBXXPtWAj+l84/HTuAh1zJ1Ac9tPUlSVBhXj7fHZCu9NWnYECLDnLZuFmhobmNdTglpMYOZmR4YHeYWjE1g4cREHnv3GKd0UL5+4dEZIGPMOmPMGGPMKGPMz13LHjDGrHHdv88YM9EYM9UYc6Ux5rDbvs8aY0a7bv/bP28jcBwsruGD3HLuuHSEbSZb6S2nw8HckbEcK63jTE2T1eVYYv3B0zS1trNkWopf9Nn31AM3TEQQHlp7wOpSApImi4/5wwd5DA4JYvls+w2/3BuzRsTgdAhbj9vvqD+/op6dJ6uYNyou4OZoGDZ0EN/+zGjWHzjDpiOlVpcTcDT4fciZmibW7ivm1qzhDBkcbHU5fiE81Mn0tGj2FJylvrnN6nIGTHtH5wndIYOCuSpAmwTvmj+SkfHhPLjmgI7I6mUa/D7kua0nae8wfG1ehtWl+JVLR8XS1mFsNYzD1uPlnK5p4oYpyYQ6rZ1cpb+EOB08dOMk8isa+P37eVaXE1A0+H1EQ0sbL+woYOHEJNJiB1tdjl9JjApjbGIkW49X2OKCrrMNLWw8VMq4pEjGJ0dZXU6/mp8Zx/VTknnyvVwKdGA+r9Hg9xGv7SqiurGVuy7To/3eWDA2noaWdnaeDPxOY3/fX4LBcMOUFFuM4fTj6ycQ5BB+oid6vUaD3we0dxie+eAE09OGMjM9xupy/FJ6bDgZceFsOVZGW0fgHvUfKqnhYEkNV41LJNpHx9n3tqQhYXzn6kw2Hi7lnYNnrC4nIGjw+4B3Dp0hv6KBu+aPtLoUv7ZgTDw1TW3sLQjMqfxa2jpYu981CNto/xqEra++Oi+DMYkRPLj2AI0teqK3rzT4fcAftuSRGj2IhRMTrS7Fr41OiGDY0EG8f7SMtvbAO+rfePgMZ12DsAXZbO7l4CAHDy2ZRFFVI0+9pxO095UGv8X2Fp5l58kqvjYvQy/Y6iMR4cqxCVTUt/D6nsAa1/1UVSMfHCtn1gj/HYStry4ZGctN01L43ft5nCivt7ocv6ZJY7EnN+USFebk1ln2nkjdW8YnRzJs6CAe3XgsYHr4tHcYXt9TRESYk0UTk3veIYD9x/XjCXU6WLnmgM7W1Qca/BY6VFLDPw6e4avzMvx+cC1fISJcPT6RoqpG/rKrsOcd/MAHx8ooqW7ixqkpDAoJzD77nkqIDOO714xh89Ey1h84bXU5fkuD30JPbMolItSpF2x52ZjECGakDeWxjbl+f8VneW0zGw+XMjEliokpQ6wuxyd8eW4645IieWjtQRpa7HO1tjdp8Fskt7SONz8u4ctz03V4Bi8TEf7ftWM5XdPEn7fnW11Or3UYw+t7TuEMEm6YqtNvnuMMcvCzmyZRXN3EY+/qid7e0OC3yJObcglzBnHnfD3a7w/zRsdxWWYcj248RpWfzuGafbKKkxX1XDcpmagwPThwlzUihltmpvKHLXm2n4+hNzT4LZBbWsvqvaf44iVpxEaEWl1OwPrR9eOpa27j0XePWV3KRatubOWtnBJGxoUHzDj73nbv4nEMCg5i5ZocPdF7kTT4LfCbDUcZFBzENxeMtrqUgDYuKYrbZg3n+W35ftX9r8MY/rq7iA5juHn6MFsMy9AbcRGh/GDhWD7MrWDt/hKry/ErGvwDLOdUNes+Ps2dl40kxiaX3Fvpu9eMIdTp4OdvHup5Yx+xPa+C3NI6rpucrP8R9mD5nHSmpA7hJ2sOUFHX3PMOCtDgH3C/+scRhgwK1sHYBkhCZBjf/kwm7xw6wwY/GOeltLaJt3NOMzYxktkjdNymngQ5hF/eMpWaplYeXHvQ6nL8hgb/ANqeV8F7R8r4xhWj9GTdALpzfuc4LyvfyPHpyVpa2zt4ZWchIU4Hn5uhTTyeGpsUyT1XZbJ2XzFv52iTjyc0+AdIR4fhZ28eJHlIGF+5dITV5dhKcJCDh2+eTHF1E7/d6Lsnet/KKaGkuolbZqYSqQcGF+UbC0YxMSWK+1fn+G0vroHkUfCLyCIROSIiuSJy73nWf09EDorIfhHZKCLpbuvaRWSv67bGm8X7k9f3nCLnVA0/XDTO9ldfWiFrRAxLZw3nmQ9OsL/I90bv/PhUNdvzKpk/Oo5xSYE9uUp/CA5y8KsvTOVsQysP6rj9Peox+EUkCHgCWAxMAJaJyIQum+0BsowxU4DXgP92W9dojJnmut3opbr9SkNLG79cf5ipqUO4US/Escx9i8cTHxHKd17Z61ND+x4vq+P13UUMjx7EtTpCa6+NT47i21dl8sbeYv6hwzlckCdH/LOBXGNMnjGmBXgZWOK+gTFmkzHm3Lxo24FU75bp3373fh5napr58Wcn4LDZcLq+ZMjgYH5961Tyyur5z7d8o5dPdWMrX38uG6dDWDo7DadDW1/74l+vHMX45Ch+tDqHsw3a5NMdT37KhgHuo10VuZZ1507gLbfHYSKSLSLbReSmXtTo106U1/O7945zw9QUsrSXhuXmjY7ja/My+NO2fDYdLrW0lvYOwz0v7aGgsoHlc9KJHqzde/uqs8lnClX1Ldz3+sd6YVc3PAn+8x2invfTFJEvAlnAL90WpxljsoDlwP+IyKhu9l3h+gORXVZW5kFZvs8YwwNv5BDqdPDj68dbXY5y+fdFYxmXFMl3XtlLfoU1F3YZY3ho7QHeP1rGT5ZMtO0Y+/1hYsoQvr9wLG/lnOblnYExQqu3eRL8RYD7YPGpQHHXjUTkauBHwI3GmH9eSWGMKXZ9zQPeA6af70WMMauMMVnGmKz4+HiP34AvW7u/hC3HyvnBorEkRIVZXY5yCQsOYtWXsgBY8addlnTxfPzdXJ7bls/XL8vg9jnpPe+gLsqKy0Yyf3QcP1l7gNzSWqvL8TmeBP9OIFNEMkQkBFgKfKJ3johMB35PZ+iXui2PFpFQ1/04YB5gi6sszja08NO/H2RK6hD9xfZBabGDeWL5DI6V1vK9V/fS3jFwTQJ/3p7Przcc5XMzhnHfYv1PsD84HMJvbp3K4BAnd7+4x6dO5vuCHoPfGNMG3A2sBw5X58DOAAAMMElEQVQBrxpjDojIQyJyrpfOL4EI4C9dum2OB7JFZB+wCfiFMcYWwb9yzQGq6lt4+ObJtpsf1V/Mz4zj/usnsP7AGe796346BiD8n9t6kvtX53DVuAT+6/NT9GR/P0qICuM3t07lyJla7l+tA7m582jaJ2PMOmBdl2UPuN2/upv9tgKT+1KgP1r3cQlv7C3me9eMYdIwnTzDl31tfgZnG1t5dOMxBocE8eCNE/vtitmn3jvOf719mGsmJPL48ukE6xzL/W7B2ATuuSqT3248RtaIaJbNTrO6JJ+g8/15WVltM/evzmHysCF8c8F5z2MrH/PdqzNpbGnj6S0naGxt52c3TSbE6b1Qbmnr4MG1B3hxRwE3Tk3h17dO1dAfQPd8JpM9hWdZ+cYBxiVFMj1Nh7nWnz4v6ugwfO/VvdQ1t+kvtx8REf7juvHcc9VoXs0u4o5nP6K6odUrz32mpollT2/nxR0FfHPBKB65bZr+XAywIIfw29umkTw0jK//aRfFZxutLsly+hPoRU9symXLsXIevGEiYxIjrS5HXQQR4XvXjuWR26ayK7+K6x7dwvtHe9+t2BjDKzsLuOY373OwuIYnls/gh4vG6fkei0SHh/DMHVk0t7Zz53PZPj1Y30DQ4PeSrcfLeeSdoyyZlsKy2cN73kH5pJunp/LKv1xCWLCDO579iO+9upfCyoaed3QxxrA1t5zbfr+dH/71Y8YlR/H3e+Zz/ZTkfqxaeWJ0QiSPLZ/OkdM13P3iblrbO6wuyTLaxu8FhZUN3PPSHkbEhfPwzZN1OF0/Nz0tmjfvuYzH3j3Gqs15rN5zisWTk/nc9GHMzog578iZhZUNbDpSyl93n2Jf4VniIkJ5+ObJLJ01XHvu+JAFYxP42U2T+Y+/fcwPX9vPr74w1ZbfHw3+PqptauXO53bS0tbBqi9lER6qH2kgCAsO4gcLx/HluSP43w9P8sKOfN7cX0KQQ8hMiCAmPISIUCcV9S0Un22kpLoJgJHx4fzspkncMjOVsGAdhdUXLZ+TRkVdM7/ecJTo8BDuv3687Q7WNKX6oK29g7tf3ENeWT3PfW02oxMirC5JeVliVBj3Lh7Hd67OZHdBFR/mlnPkdC1VDa2U19UTGx7K3FGxTEiO4qpxCYyM158Bf3D3VaOpqG/hmQ9O4AwS7l00zlbhr8HfSx0dhu//ZR/vHy3j4ZsnM290nNUlqX4UFhzEpaPiuHSUfp8DgYiw8oYJtHV08Pv38zAG7ltsn/DX4O8FYww/Wp3D6r3F/GDhWJbP0YtClPI3IsJPl0xCEFZtzqO+uY2HlkyyRc8rDf6L1NFhWLnmAC99VMC/LhjFt64cbXVJSqleEhEeWjKRwaFB/P79PMpqm3l02fSAPz+j3TkvQktbB//2yl6e357PistH8oOFY60uSSnVRyLCfYvHs/KGCWw4dIalq7ZzpqbJ6rL6lQa/h6obO3vvrN1XzL2Lx/Ef19mvJ4BSgeyr8zJ46vYZHD1Ty2cf+4Dsk5VWl9RvNPg9cOR0LUse/4DteRX89+en8I0rdAwepQLRoknJrP7WPCJCnSxdtZ0nNuUO6JDdA0WD/wKMMfwlu5Cbn/yQ+pZ2Xvr6Jdw6S6/KVSqQjUmMZPW35rFwUhK/XH+Epau2UVDh+dXb/kCDvxtltc18/U+7+MFr+5k0bAh///Z8nTNXKZsYMiiYx5dN55HbpnK4pJZrHnmfx989RnNbYEzoor16umht7+DP2/N5ZMNRmto6uP/68XxtXoYtL+tWys5EhJunpzJ3ZBwP/f0Av/rHUV7ffYrvLxzL4klJfn2OT4PfpaPD8FbOaR555yi5pXVclhnHyhsmMDpBR9lUys6ShoTx5O0zee9IKQ+vO8S/vrCbKalD+NaVo7lmfKJfHhTaPvgbWtpYu6+Yp7ecILe0jpHx4az60kyumZDo13/RlVLetWBsApdlxvO3Paf4n3eO8i/P7yIjLpyvXDqCm6YNY8jgTw/e56tsGfztHYadJyv5+/5i3thTTG1zG+OSInls2XSum5xsiyv3lFIXL8gh3DIzlZumpfBWzmme3pLHyjUH+Pm6Q1w7IZHrJidzxZh4nx+s0ber8xJjDEVVjXx0opIPj5ez+Wg55XXNhDodLJqUxBcvSScrPVqP8JVSHnEGObhhago3TE0h51Q1r+0q4o29p/j7/hJCnQ5mZ8Qwd1QsczJimZgS5XNXAnsU/CKyCPgtEAT8wRjziy7rQ4E/ATOBCuA2Y8xJ17r7gDuBduAeY8x6r1XvxhhDQWUDZbXNlNc1c+psEyfL6zlRXs+B4mqqXFPpxYSHcOmoWBZNSuLKsQk+/5dZKeXbJg0bwqRhQ7j/+vHsPFnFPw6e5sPccv777SMA/xzKe3RCBBlx4QyPHkxCVChxEaFEhjkJD3US7HCAdG4bMQCZ1OMriEgQ8ARwDVAE7BSRNcaYg26b3QlUGWNGi8hS4L+A20RkArAUmAikAO+IyBhjTL/0ibrmN5tpcZtVJzLUyYi4cK6dkMTk1CHMSItmXFKkX56MUUr5NmeQg7mjYpk7Khbo7BK+u6CKnFPV5Jyq5uNT1az7uIQLXQ8WFxFK9v1X93+tHmwzG8g1xuQBiMjLwBLAPfiXAA+67r8GPC6d7SZLgJeNMc3ACRHJdT3fNu+U/39EhEdum0ZEmJO4iBASo8KIDQ/R5hullCXiI0NZODGJhROT/rmsua2d0ppmSmubKKttoa65jfrmNto6DMYYBoUMTJOQJ8E/DCh0e1wEzOluG2NMm4hUA7Gu5du77Dus19X2QOc1VUr5slBnEMNjBjM8ZrCldXgS/Oc7ZO76z0p323iyb+cTiKwAVrge1onIEQ9qG2hxQLnVRVjIb97/7f331H7zGfSX2/Uz8NX3n+7php4EfxHgPkBNKlDczTZFIuIEhgCVHu4LgDFmFbDKs7KtISLZxpgsq+uwit3fP+hnAPoZBML792Ssnp1ApohkiEgInSdr13TZZg1wh+v+LcC7xhjjWr5UREJFJAPIBD7yTulKKaV6o8cjfleb/d3Aejq7cz5rjDkgIg8B2caYNcAzwPOuk7eVdP5xwLXdq3SeCG4DvtVfPXqUUkp5RjoPzJUnRGSFq0nKluz+/kE/A9DPIBDevwa/UkrZjI7Hr5RSNqPBfwEiEiMiG0TkmOtrdDfbtYvIXtet64lvvyMii0TkiIjkisi951kfKiKvuNbvEJERA19l//LgM/iKiJS5fd/vsqLO/iIiz4pIqYjkdLNeRORR1+ezX0RmDHSN/cmD979ARKrdvv8PDHSNfaHBf2H3AhuNMZnARtfj82k0xkxz3W4cuPK8z22IjsXABGCZa+gNd/8cogN4hM4hOgKGh58BwCtu3/c/DGiR/e+PwKILrF9MZy+9TDqvv3lqAGoaSH/kwu8fYIvb9/+hAajJazT4L2wJ8Jzr/nPATRbWMlD+OUSHMaYFODdEhzv3z+U14DMSWGNjePIZBDRjzGY6e+h1ZwnwJ9NpOzBURALm0nkP3r9f0+C/sERjTAmA62tCN9uFiUi2iGwXEX//43C+ITq6DrPxiSE6gHNDdAQKTz4DgM+7mjleE5Hh51kfyDz9jALZXBHZJyJvichEq4u5GLYfk1hE3gGSzrPqRxfxNGnGmGIRGQm8KyIfG2OOe6fCAdeXIToChSfvby3wkjGmWUS+Qed/QFf1e2W+I9B/BnqyG0g3xtSJyHXAajqbvfyC7YPfGNPtGKgickZEko0xJa5/Y0u7eY5i19c8EXkPmA74a/D3ZYiOQNHjZ2CMqXB7+DQBdp7DAx4PxxKIjDE1bvfXiciTIhJnjPHFMXw+RZt6Lsx9KIo7gDe6biAi0a6JaBCROGAenxyy2t/0ZYiOQNHjZ9ClPftG4NAA1ucL1gBfdvXuuQSoPtcsagciknTuvJaIzKYzSysuvJfvsP0Rfw9+AbwqIncCBcAXAEQkC/iGMeYuYDzwexHpoPOb/4suk9T4lb4M0REoPPwM7hGRG+kciqQS+IplBfcDEXkJWADEiUgRsBIIBjDG/A5YB1wH5AINwFetqbR/ePD+bwG+KSJtQCOw1J8OfvTKXaWUshlt6lFKKZvR4FdKKZvR4FdKKZvR4FdKKZvR4FdKKZvR4FdKKZvR4FdKKZvR4FdKKZv5/9eJ9K5Np+OwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(obs_train[1][obs_train[0] == 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a higher percentage of sex=0 that smoke than sex=1 that smoke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means and Optimal K\n",
    "We try to cluster the data using the k-means algorithm, and try a few different methods to find the optimal number of clusters, $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1: Inertia = 239540.303200   Score = -79850.912267   Elbow = 79850.912267\n",
      "k =  2: Inertia = 217551.179908   Score = -72787.555318   Elbow = 36393.777659\n",
      "k =  3: Inertia = 205968.797886   Score = -68748.876434   Elbow = 22916.292145\n",
      "k =  4: Inertia = 197617.569763   Score = -66451.303391   Elbow = 16612.825848\n",
      "k =  5: Inertia = 191447.542229   Score = -64478.504827   Elbow = 12895.700965\n",
      "k =  6: Inertia = 186241.744263   Score = -62658.956506   Elbow = 10443.159418\n",
      "k =  7: Inertia = 181845.101811   Score = -61098.197257   Elbow = 8728.313894\n",
      "k =  8: Inertia = 177945.015793   Score = -59921.047013   Elbow = 7490.130877\n",
      "k =  9: Inertia = 174903.531138   Score = -58880.136150   Elbow = 6542.237350\n",
      "k = 10: Inertia = 172314.999372   Score = -58167.164673   Elbow = 5816.716467\n",
      "k = 11: Inertia = 169870.300780   Score = -57303.945625   Elbow = 5209.449602\n",
      "k = 12: Inertia = 167817.242421   Score = -56755.152357   Elbow = 4729.596030\n",
      "k = 13: Inertia = 165736.584281   Score = -56025.939353   Elbow = 4309.687643\n",
      "k = 14: Inertia = 163908.208439   Score = -55500.641863   Elbow = 3964.331562\n",
      "k = 15: Inertia = 162270.453356   Score = -54990.188905   Elbow = 3666.012594\n",
      "k = 16: Inertia = 160511.393235   Score = -54410.719166   Elbow = 3400.669948\n",
      "k = 17: Inertia = 158995.872353   Score = -53902.474760   Elbow = 3170.733809\n",
      "k = 18: Inertia = 157577.519129   Score = -53523.041385   Elbow = 2973.502299\n",
      "k = 19: Inertia = 156017.659168   Score = -53048.962193   Elbow = 2792.050642\n",
      "k = 20: Inertia = 154774.930182   Score = -52706.880045   Elbow = 2635.344002\n"
     ]
    }
   ],
   "source": [
    "elbows_score = np.zeros(21) \n",
    "for k in range(1,21):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=1).fit(obs_train)\n",
    "    \n",
    "    # Sum of distances of samples to their closest cluster center.\n",
    "    inertia = kmeans_model.inertia_\n",
    "    \n",
    "    elbows_score[k] = -kmeans_model.score(obs_test)/k\n",
    "    \n",
    "    print(\"k = %2d: Inertia = %f   Score = %f   Elbow = %f\" % (k,inertia,kmeans_model.score(obs_test), elbows_score[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8XVWd///XJ/dL26RN2th7Utph5CKXBihiIQgDBR2Lo8yUr0pVxo58wVFnHIXH/Gbw/sUZFUURp0qhOGhBlKEqDFQg3KTQcistRXqFlpbe0kvSNM3t8/tjr7SH9CQ5yck5J5f38/E4j7P32mvv8zmb03zYe629lrk7IiIi/SEr0wGIiMjQoaQiIiL9RklFRET6jZKKiIj0GyUVERHpN0oqIiLSb5RUZFgzs0+a2VMx625m0zMZU38ys6+a2X/307Heca5E4lFSkSHPzDab2SEza4h5/TjTcfU3M6sxs62ZjkOGt5xMByCSJn/t7n/MdBAiQ52uVESOdamZbTSz3Wb2n2aWBWBmWWb2/5nZG2a208zuNLOSsG2xmf1zWJ4YbqP937A+3czqzMw6f1C4pfS0md1kZvvC5743lG8JnzM/pn6+mX3XzN40sx1m9lMzKzSzYuBBYELM1diEsFteiLXezNaYWXXM8d5tZrXhs9eY2YditpWZ2VIzO2BmzwHH9f+plqFGSUXkWB8GqoHTgbnAp0P5J8PrfGAaMALouI32OFATls8DNoZ3gHOBJ73rMZHOAlYBZcAvgSXAGcB04OPAj81sRKj7HeAvgFPD9onAv7v7QeASYJu7jwivbWGfD4VjlgJLO2I2s1zgd8DDwDjgc8BdZnZ82O8WoAkYH85Bx3kQ6ZKSigwX/xP+b7zj9Zlu6n7H3evc/U3gB8AVofxjwPfdfaO7NwDXA/PMLIcoqcwOVzXnAv8BnBP2Oy9s78omd7/d3duAu4HJwNfd/bC7Pww0A9PDlc5ngC+G+OqBbwPzevjuT7n7A+H4vwBOCeWziBLjje7e7O6PAr8HrjCzbOAjhITl7quBxT18jojaVGTYuKwXbSpbYpbfADpuI00I67HbcoAKd99gZg1EVxCzgW8AV4X/6z8PuLmbz9sRs3wIwN07l40AxgJFwPMxd9IMyO7h+7wds9wIFIREOAHY4u7tnb7TxPBZORx7LkS6pSsVkWNNjlmeAnTcRtoGTO20rZWjSeFx4KNAnru/FdavBEYDL/VDXLuJEsyJ7l4aXiXu3nFrrLdDjm8DJne0GQVTgLeAXUTfrfO5EOmWkorIsf7FzEab2WTg80S3pAB+BXzRzKpCG8e3gbvdvTVsfxy4FngirNcStVM8FW49JSVcUfwMuMnMxsGRTgEXhyo7gLKOzgMJeBY4CHzZzHLNrAb4a2BJiPe3wFfNrMjMTgDmd30okYiSigwXv+v0nMp93dS9H3ie6OriD8BtoXwRUZvEE8Amokbsz8Xs9zgwkqNJ5Smi21VP0H++AqwHlpvZAeCPwPEA7v4aUeLbGNqNJnR9GHD3ZqJG/EuIroJ+AlwZjgNRghxBdPvsDuD2fvweMkSZJukSEZH+oisVERHpN0oqIiLSb5RURESk3yipiIhIvxl2Dz+Wl5d7ZWVlpsOI6+DBgxQXF2c6jC4pvuQovuQovuQkE9/zzz+/293HJlTZ3YfVa+bMmT5QPfbYY5kOoVuKLzmKLzmKLznJxAes9AT/xur2l4iI9BslFRER6TdKKiIi0m+UVEREpN8oqYiISL9JaVIxsy+GKUpXm9mvzKwgjPD6rJmtM7O7zSwv1M0P6+vD9sqY41wfyv8cMyIrZjYnlK03s+tS+V1ERKRnKUsqZjYR+Eeg2t1PIppIaB7RdKg3ufsMYC9wVdjlKmCvu08Hbgr1CENuzwNOBOYAPzGz7DAz3S1EI6yeQDRb3Qmp+j4iItKzVN/+ygEKwyxzRcB24P3AvWH7YuCysDyXo9OV3gtcEKZPnUs0v8Nhd99ENOz3meG13qOpXZuJ5uCem4ov0dbu3PLYeh5/fVcqDi8iMmSk7Il6d3/LzL4LvEk0W93DRHNU7POjkxptJZq6lPC+Jezbamb7gbJQvjzm0LH7bOlUfla8WMxsAbAAoKKigtra2l5/n588epAz35WDb8vv9b6Jamho6FNs6aL4kqP4kqP4kpOu+FKWVMxsNNGVQxWwD/g10a2qzjomdLEutnVVHu8qK+7kMO6+EFgIUF1d7TU1Nd2FHtf0NU/TnJ9NTc2sXu+bqNraWvoSW7oovuQovuQovuSkK75U3v66ENjk7rvcvYVoatL3AqXhdhjAJI7O/72VMB922F4C1MWWd9qnq/KUqCorYvPuxlQdXkRkSEhlUnkTmBXmtzbgAuBV4DHgo6HOfKKpWwGWcnQO7I8Cj4YxZ5YC80LvsCpgBvAcsAKYEXqT5RE15i9N1ZeZWlbMtv2HaGpJeqpxEZEhK5VtKs+a2b3AC0Ar8CLRLag/AEvM7JuhrGP+79uAX5jZeqIrlHnhOGvM7B6ihNQKXOPubQBmdi3wEFHPskXuviZV36eqvBh32FLXyIyKkan6GBGRQS2lQ9+7+w3ADZ2KNxL13Opctwm4vIvjfAv4VpzyB4AHko+0Z5Xl0ZDRm3YfVFIREemCnqhPUFVZlFQ27zmY4UhERAYuJZUElRTlMrool01qrBcR6ZKSSi9UlhezebeuVEREuqKk0gtVZcW8odtfIiJdUlLphahbcZO6FYuIdEFJpRcqy4sAeGOP2lVEROJRUumFqphuxSIiciwllV7oeFZF3YpFROJTUumFUQW5lBXnqQeYiEgXlFR6qbK8WLe/RES6oKTSS5VlxWqoFxHpgpJKL1WVF/H2gSYONatbsYhIZ0oqvTRVY4CJiHRJSaWXOroVq7FeRORYSiq9dGQIfF2piIgcQ0mll0bk51A+Il9XKiIicaQsqZjZ8Wb2UszrgJl9wczGmNkyM1sX3keH+mZmN5vZejNbZWanxxxrfqi/zszmx5TPNLNXwj43h2mLU66qXPPVi4jEk7Kk4u5/dvdT3f1UYCbQCNwHXAc84u4zgEfCOsAlRPPPzwAWALcCmNkYotkjzyKaMfKGjkQU6iyI2W9Oqr5PrMqyYjXUi4jEka7bXxcAG9z9DWAusDiULwYuC8tzgTs9shwoNbPxwMXAMnevc/e9wDJgTtg2yt2fcXcH7ow5VkpVlhezs/4wBw+3puPjREQGjZTOUR9jHvCrsFzh7tsB3H27mY0L5ROBLTH7bA1l3ZVvjVN+DDNbQHRFQ0VFBbW1tcl8Fw7uiJLJvQ89ztRR2UkdK1ZDQ0PSsaWS4kuO4kuO4ktOuuJLeVIxszzgQ8D1PVWNU+Z9KD+20H0hsBCgurraa2pqegile2O37ecnLz1FeeUJ1LxnfFLHilVbW0uysaWS4kuO4kuO4ktOuuJLx+2vS4AX3H1HWN8Rbl0R3neG8q3A5Jj9JgHbeiifFKc85Sr1AKSISFzpSCpXcPTWF8BSoKMH13zg/pjyK0MvsFnA/nCb7CHgIjMbHRroLwIeCtvqzWxW6PV1ZcyxUqo4P4dxI/M1sKSISCcpvf1lZkXAXwH/EFN8I3CPmV0FvAlcHsofAC4F1hP1FPsUgLvXmdk3gBWh3tfdvS4sXw3cARQCD4ZXWlSWF+tZFRGRTlKaVNy9ESjrVLaHqDdY57oOXNPFcRYBi+KUrwRO6pdge6mqrJhHXtvZc0URkWFET9T3UWV5MbsbDlPf1JLpUEREBgwllT6qLCsC0NwqIiIxlFT66MjAkmpXERE5Qkmlj450K1ZSERE5QkmljwrzsnnXqAINgS8iEkNJJQmV5UW6UhERiaGkkoSq8mI11IuIxFBSSUJlWTF7DjZzQN2KRUQAJZWkTFVjvYjIOyipJKFK3YpFRN5BSSUJU8MDkJpaWEQkoqSShILcbCaUFGgIfBGRQEklSZXlxbr9JSISKKkkqbK8WFcqIiKBkkqSqsqK2dfYwr7G5kyHIiKScUoqSTrSWK+HIEVElFSS1dGtWM+qiIikOKmYWamZ3Wtmr5nZWjM728zGmNkyM1sX3keHumZmN5vZejNbZWanxxxnfqi/zszmx5TPNLNXwj43h7nq02rymCLM9KyKiAik/krlh8D/uvtfAqcAa4HrgEfcfQbwSFgHuASYEV4LgFsBzGwMcANwFnAmcENHIgp1FsTsNyfF3+cYUbfiQjXWi4iQwqRiZqOAc4HbANy92d33AXOBxaHaYuCysDwXuNMjy4FSMxsPXAwsc/c6d98LLAPmhG2j3P2ZML/9nTHHSquq8mLd/hIRAXJSeOxpwC7gdjM7BXge+DxQ4e7bAdx9u5mNC/UnAlti9t8ayror3xqn/BhmtoDoioaKigpqa2uT+mKd5R0+zLq3W3nsscdI5g5cQ0NDv8fWnxRfchRfchRfctIVXyqTSg5wOvA5d3/WzH7I0Vtd8cT7a+x9KD+20H0hsBCgurraa2pqugmj99Znb+TRLWs59cxzGF2c1+fj1NbW0t+x9SfFlxzFlxzFl5x0xZfKNpWtwFZ3fzas30uUZHaEW1eE950x9SfH7D8J2NZD+aQ45WnXMbWwZoEUkeEuZUnF3d8GtpjZ8aHoAuBVYCnQ0YNrPnB/WF4KXBl6gc0C9ofbZA8BF5nZ6NBAfxHwUNhWb2azQq+vK2OOlVaV6lYsIgKk9vYXwOeAu8wsD9gIfIookd1jZlcBbwKXh7oPAJcC64HGUBd3rzOzbwArQr2vu3tdWL4auAMoBB4Mr7SbMqaILFNSERFJaVJx95eA6jibLohT14FrujjOImBRnPKVwElJhpm0vJwsJo4uZJOeqheRYU5P1PeTyjJ1KxYRUVLpJx3PqkQXXCIiw5OSSj+pLCum/nArdQc1WrGIDF9KKv2ksrxjtGLdAhOR4UtJpZ8ceVZF89WLyDCmpNJPJo8pIjvL1FgvIsOakko/yc3OYtLoQj1VLyLDmpJKP1K3YhEZ7pRU+pG6FYvIcKek0o8qy4o42NzG7gZ1KxaR4UlJpR9N7RhYUu0qIjJMKan0o6oj3YqVVERkeFJS6UeTRheSo27FIjKMKan0o5zsLCaPKdLtLxEZthJOKmZWnMpAhorKsiI9VS8iw1aPScXM3mtmrwJrw/opZvaTlEc2SFWWF/PGHnUrFpHhKZErlZuAi4E9AO7+MnBuKoMazKrKi2lsbmNX/eFMhyIiknYJ3f5y9y2ditoS2c/MNpvZK2b2kpmtDGVjzGyZma0L76NDuZnZzWa23sxWmdnpMceZH+qvM7P5MeUzw/HXh30tkbhSqVI9wERkGEskqWwxs/cCbmZ5ZvYlwq2wBJ3v7qe6e8e0wtcBj7j7DOCRsA5wCTAjvBYAt0KUhIAbgLOAM4EbOhJRqLMgZr85vYgrJTqSihrrRWQ4SiSpfJZo7viJwFbgVLqYSz5Bc4HFYXkxcFlM+Z0eWQ6Umtl4oltvy9y9zt33AsuAOWHbKHd/Jsxvf2fMsTJmQmkBudmmxnoRGZZyuttoZtnAJ9z9Y308vgMPm5kD/+XuC4EKd98O4O7bzWxcqDsRiL3NtjWUdVe+NU55vO+xgOiKhoqKCmpra/v4dRJTVgArXttMbeHbvdqvoaEh5bElQ/ElR/ElR/ElJ13xdZtU3L3NzOYSNdb3xTnuvi0kjmVm9lo3deO1h3gfyo8tjJLZQoDq6mqvqanpNuhknbh5BW/tO0RNTe/6M9TW1pLq2JKh+JKj+JKj+JKTrvgSuf31tJn92Mxmm9npHa9EDu7u28L7TuA+ojaRHeHWFeF9Z6i+FZgcs/skYFsP5ZPilGdcZXkxm/ccpL1d3YpFZHhJJKm8FzgR+DrwvfD6bk87mVmxmY3sWAYuAlYDS4GOHlzzgfvD8lLgytALbBawP9wmewi4yMxGhwb6i4CHwrZ6M5sVen1dGXOsjKosL6appZ2d6lYsIsNMt7e/ANz9/D4euwK4L/TyzQF+6e7/a2YrgHvM7CrgTeDyUP8B4FJgPdAIfCp8fp2ZfQNYEep93d3rwvLVwB1AIfBgeGVc7MCS7yopyHA0IiLp02NSMbMSoi69HQ0EjxP9Yd/f3X7uvhE4JU75HuCCOOVOF73K3H0RsChO+UrgpB6+QtpNLSsCom7FZx9XluFoRETSJ5HbX4uAeuBvw+sAcHsqgxrsJpQWkpedpdGKRWTY6fFKBTjO3T8Ss/41M3spVQENBdlZxpSyIj1VLyLDTiJXKofM7H0dK2Z2DnAodSENDZVlxXqqXkSGnUSuVK4GFoe2FYC9wCdTFtEQUVVexJPrdtHe7mRlZXxIMhGRtEik99dLwClmNiqsH0h5VENAZXkxh1vbeftAExNKCzMdjohIWiQyn8q3zazU3Q+4+4HwvMg30xHcYNbRrViN9SIynCTSpnKJu+/rWAmDOl6aupCGhqnl4VkVtauIyDCSSFLJNrP8jhUzKwTyu6kvwPhRBeTnqFuxiAwviTTU/zfwiJndTjRg46c5OnS9dCEry5iq+epFZJhJpKH+P8xsFXAh0cjA33D3h1Ie2RBQWVbMRl2piMgwkkhDfTHwsLt/iWj4+Hwzy015ZENAVXkxb+5ppE2jFYvIMJFIm8oTQIGZTQT+SDTQ4x2pDGqoqCwvprmtnW379KyoiAwPiSQVc/dG4G+AH7n7h4ETUhvW0NAxX/0be9SuIiLDQ0JJxczOBj4G/CGUJdLAP+xVlkejFatbsYgMF4kklc8D1wP3ufsaM5sGPJbasIaGipEFFOSqW7GIDB+J9P56gqhdpWN9I/CPqQxqqMjKsmhgSSUVERkmErlSSYqZZZvZi2b2+7BeZWbPmtk6M7vbzPJCeX5YXx+2V8Yc4/pQ/mczuzimfE4oW29m16X6u/RFZVmxbn+JyLCR8qRCdPtsbcz6d4Cb3H0G0YjHV4Xyq4C97j4duCnUw8xOAOYBJwJzgJ+ERJUN3AJcQtRx4IpQd0CpLC9mS10jrW3tmQ5FRCTlEnlOpc+TrJvZJOADwM/DugHvB+4NVRYDl4XluRx9Uv9e4IJQfy6wxN0Pu/smojnszwyv9e6+0d2bgSWh7oBSVV5ES5uzbV9TpkMREUm5RHpxrTazHcCTRG0rT/c0P32MHwBfBkaG9TJgn7u3hvWtwMSwPBHYAuDurWa2P9SfCCyPOWbsPls6lZ8VLwgzWwAsAKioqKC2tjbB8JO3r64NgKWP/YmTyrs/3Q0NDWmNrbcUX3IUX3IUX3LSFV8iDfXTzWwKMBv4INHtp33ufmp3+5nZB4Gd7v68mdV0FMf7iB62dVUe7yor7qPr7r6QaDQAqqurvaamJl61lHj3gSb+33OPMGridGrOruy2bm1tLemMrbcUX3IUX3IUX3LSFV+PSSXcwjqHKKmcAqwBnkrg2OcAHzKzS4ECYBTRlUupmeWEq5VJwLZQfyswGdhqZjlACVAXU94hdp+uygeMcSPzKcrL1nz1IjIsJNJQ/ybwBeBBdz/b3T/g7v+vp53c/Xp3n+TulUQN7Y+6+8eInnH5aKg2H7g/LC8N64Ttj7q7h/J5oXdYFTADeA5YAcwIvcnywmcsTeD7pJWZMVXdikVkmEikTeU04H3A/wnddtcBj7v7bX38zK8AS8LskS8CHce5DfiFma0nukKZBxAeuLwHeBVoBa5x9zYAM7sWeAjIBha5+5o+xpRSVeVFrN1en+kwRERSLpE2lZfNbAOwgegW2MeBczmaDHrk7rVAbVjeSNRzq3OdJuDyLvb/FvCtOOUPAA8kGkemVJYV8/CaHbS2tZOTnY5e3CIimZFIl+KVwDPAh4HXgHPDLS1JUGV5Ma3tzta9Gq1YRIa2RG5/XeLuu1IeyRBWFear37znIJVhWURkKErkXkyzmX3fzFaG1/fMrCTlkQ0hU8ui0YrVWC8iQ10iSWURUA/8bXgdAG5PZVBDzdgR+ZQU5rLyjb2ZDkVEJKUSuf11nLt/JGb9a2b2UqoCGorMjMtnTuL2P21mS10jk8cUZTokEZGUSORK5ZCZva9jxczOAdTi3EtXza4iy+C2pzZlOhQRkZRJJKlcDdxiZpvN7A3gx8A/pDasoWd8SSFzT53IkhVvUnewOdPhiIikRI9Jxd1fcvdTgPcAJ7v7ae6+KvWhDT2fPW8aTS3tLP7T5kyHIiKSEok8p1JmZjcTPbz4mJn90MzKUh7ZEDR93EgufHcFi5/ZTGNza4/1RUQGm0Rufy0BdgEfIRqTaxdwdyqDGsqurpnGvsYW7l6xpefKIiKDTCJJZYy7f8PdN4XXN4HSVAc2VM2cOobqqaP5+ZObaNFskCIyxCSSVB4zs3lmlhVefwv8IdWBDWWfPe843tp3iD+s2p7pUERE+lWXScXM6s3sAFFPr18Ch8NrCfDF9IQ3NL3/L8cxY9wIfvr4BqLR/UVEhoYuk4q7j3T3UeE9y91zwyvL3UelM8ihJivL+IfzjuO1t+upfV3DqonI0NHlE/Vmdnp3O7r7C/0fzvDxoVMm8L2H/8xPazdw/vHjMh2OiEi/6G6Ylu91s82B9/dzLMNKXk4WV72vim/+YS0vvrmX06aMznRIIiJJ6zKpuPv56QxkOLrizCn86NH1/PTxDfzXJ6ozHY6ISNK6a6j/cszy5Z22fbunA5tZgZk9Z2Yvm9kaM/taKK8ys2fNbJ2Z3R3mlyfMQX+3ma0P2ytjjnV9KP+zmV0cUz4nlK0PUx0PKsX5OXxi1lQefnUHG3Y1ZDocEZGkddeleF7M8vWdts1J4NiHgfeHIV5OBeaY2SzgO8BN7j4D2AtcFepfBex19+nATaEeZnZCiOXE8Lk/MbNsM8sGbgEuAU4Argh1B5VPnlNJXnYWP3tiY6ZDERFJWndJxbpYjrd+DI90/O93bnh1tMXcG8oXA5eF5blhnbD9AjOzUL7E3Q+7+yZgPdEc92cC6919o7s3E3V1nttTXANN+Yh8Lq+exG9feIt9TXoYUkQGt+4a6r2L5XjrcYWrieeB6URXFRuAfe7eMfDVVmBiWJ4IbAFw91Yz2w+UhfLlMYeN3WdLp/KzuohjAbAAoKKigtra2kTCT5v35LVzV1s7v1/XSGlBbabD6VJDQ8OAO3exFF9yFF9yFF+ku6RySnj40YDCsExYL0jk4O7eBpxqZqXAfcC741WLOW68bV2Vx7vKipvs3H0hsBCgurraa2pqug88A57Y9wKPvLqd73/mHEYV5GY6nLhqa2sZiOeug+JLjuJLjuKLdPfwY3bMw485YbljvVd/9dx9H9Eox7OAUjPrSGaTgG1heSswGSBsLwHqYss77dNV+aD02fOO41Ar3LX8zUyHIiLSZ4mM/dUnZjY2XKFgZoXAhcBa4DGi0Y4B5gP3h+WlYZ2w/VGPxjBZCswLvcOqgBnAc8AKYEboTZZH1Ji/NFXfJ9VOmljCiWVZLHp6E00tbZkOR0SkT1KWVIDxRINRriJKAMvc/ffAV4B/MrP1RG0mt4X6twFlofyfgOsA3H0NcA/wKvC/wDXu3hbaZa4FHiJKVveEuoPWpVV57Ko/zP+8+FamQxER6ZPu2lSSEmaHPC1O+Uainludy5uAyzuXh23fAr4Vp/wB4IGkgx0gTijL4qSJo1j4xEYur55MdlaPnexERAaUVF6pSC+ZGZ897zg27j7IslffznQ4IiK9pqQywFxy0nimlhVx6+MbNSy+iAw6SioDTHaW8ZnZ03h5yz6Wb6zLdDgiIr2ipDIAfXTmJMpH5PHTxzdkOhQRkV5RUhmACnKz+dQ5VTz++i5e3Xag5x1ERAYIJZUB6uNnTaU4L5uFT+hqRUQGDyWVAaqkKJcrzpzC71ZtZ0tdY6bDERFJiJLKAHbV7CqyDG57alOmQxERSYiSygA2vqSQuadOZMmKN6k72JzpcEREeqSkMsB99rxpNLW0s/hPmzMdiohIj5RUBrjp40Zy4bsrWPzMZhqbW3usLyKSSUoqg8DVNdPY19jCIrWtiMgAp6QyCMycOoZLTnoX3334dX71nOZbEZGBS0llkPjBvFM5//ixXP/bV7h7hRKLiAxMSiqDRH5ONrd+fCY1x4/lut++wj0rtmQ6JBGRYyipDCIFudn89OMzmT1jLF/57Sp+vVKJRUQGllROJzzZzB4zs7VmtsbMPh/Kx5jZMjNbF95Hh3Izs5vNbL2ZrTKz02OONT/UX2dm82PKZ5rZK2Gfm81syM9qVZCbzcJPzOR908v58m9W8Zvnt2Y6JBGRI1J5pdIK/LO7vxuYBVxjZicQTRP8iLvPAB4J6wCXEM0/PwNYANwKURICbgDOIpox8oaORBTqLIjZb04Kv8+AUZCbzc+urOac48r50r0vc9+LSiwiMjCkLKm4+3Z3fyEs1xPNIz8RmAssDtUWA5eF5bnAnR5ZDpSa2XjgYqL57evcfS+wDJgTto1y92c8ms3qzphjDXkdieW9x5Xxz/e8rHntRWRAsHTMLmhmlcATwEnAm+5eGrNtr7uPNrPfAze6+1Oh/BHgK0ANUODu3wzl/wYcAmpD/QtD+WzgK+7+wTifv4DoioaKioqZS5YsSc0XTVJDQwMjRozo1T6H25wfPN/Ea3XtLHhPPmdPyElRdH2LL50UX3IUX3KGcnznn3/+8+5enUjd1P0FCsxsBPAb4AvufqCbZo94G7wP5ccWui8EFgJUV1d7TU1ND1FnRm1tLX2JbfbsVj59xwp+9kodJ554Ah86ZUL/B0ff40sXxZccxZccxRdJae8vM8slSih3uftvQ/GOcOuK8L4zlG8FJsfsPgnY1kP5pDjlw05RXg6LPnkG1ZVj+MKSF/ndy8PyNIjIAJDK3l8G3Aasdffvx2xaCnT04JoP3B9TfmXoBTYL2O/u24GHgIvMbHRooL8IeChsqzezWeGzrow51rBTlJfD7Z88g+qpY/jC3S/xh1XbMx2SiAxDqbxSOQf4BPB+M3spvC4FbgT+yszWAX8V1gEeADYC64GfAf8XwN3rgG8AK8Lr66EM4Grg52GfDcCDKfw+A15xfg63f+oMTp9Syj8ueZEHX1FiEZH0SlmbSmhw76oB5YI49R24potjLQIWxSlfSdT4L0GUWM5k/qLn+NyvXuTHBnNOGp9tzY17AAASlElEQVTpsERkmNAT9UPQiPwc7vjUGbxnUgnX/vJFHlrzdqZDEpFhQklliBpZkMviT5/JyZNKuOauF3hYiUVE0kBJZQjrSCwnTizhml++wK9XbiEdzyWJyPClpDLEjSrI5c5Pn8mpk0v5l3tX8Xf/tZy12w9kOiwRGaKUVIaBksJc7l5wNjf+zcms21nPB25+kq8uXcP+Qy2ZDk1EhhgllWEiK8uYd+YUHvtSDR+fNZU7n9nM+79byz0rttDerltiItI/lFSGmdKiPL4+9yR+97n3UVVezJd/s4oP3/onVm3dl+nQRGQIUFIZpk6cUMKvP3s2N/3dKWzbd4i5tzzN9b9dRd3B5kyHJiKDmJLKMGZmfPi0STz6z+fx9++r4tcrt3L+d2v5xTObadMtMRHpAyUVYWRBLv/6gRN48POzOXHCKP7t/jX89Y+eYuXmup53FhGJoaQiR8yoGMldf38WP/nY6exrbOajP32Gf7rnJXbWN2U6NBEZJFI+n4oMLmbGpSePp+b4sdzy2Hp+9sQmHl6zgy9cOINK3RITkR4oqUhcRXk5/MvFf8lHZ07ma79bwzf/sJbSfONjLa/xd9VTmFJWlOkQRWQA0u0v6VZVeTG3f/IM7vjUGUwdlcWttRs49z8f42M/X87Sl7fR1NKW6RBFZADRlYr0yMyoOX4cbC/g+NPO4t6VW7l75Rb+8VcvUlqUy9+cNol5Z07mLypGZjpUEckwJRXplfElhXzughlcc/50nt6wmyUrtvCL5ZtZ9PQmTptSyhVnTOED7xlPcb5+WiLDkf7lS59kZRmzZ4xl9oyx7Gk4zH0vvsWSFVv48m9W8bXfreFDp05g3hlTeM+kEqLZnkVkOEjlHPWLzGynma2OKRtjZsvMbF14Hx3KzcxuNrP1ZrbKzE6P2Wd+qL/OzObHlM80s1fCPjeb/nJlTNmIfP5+9jSWffFcfnP12Vxy8njue/Et5t7yNJf88EkW/2kz+xs1eKXIcJDKhvo7gDmdyq4DHnH3GcAjYR3gEmBGeC0AboUoCQE3AGcBZwI3dCSiUGdBzH6dP0vSzMyYOXUM3738FJ771wv55mUnkZudxQ1L13DGt//IZ+5cyS+Wv8Ebew5mOlQRSZFUzlH/hJlVdiqeC9SE5cVALfCVUH5nmKd+uZmVmtn4UHeZu9cBmNkyYI6Z1QKj3P2ZUH4ncBnwYKq+j/TOqIJcPj5rKh+fNZXVb+3n1yu38Me1O1n26g4ApowpYvaMcs79i7GcfVwZowpyMxyxiPQHS+VMgCGp/N7dTwrr+9y9NGb7XncfbWa/B25096dC+SNEyaYGKHD3b4byfwMOESWjG939wlA+G/iKu3+wizgWEF3VUFFRMXPJkiX9/2X7QUNDAyNGjMh0GF1KNj53Z0ejs3p3G6t3t/FaXRtNbZBlcFxJFieVZ3NieTZVo7LIzur93cyhfv5STfElZyjHd/755z/v7tWJ1B0oDfXx/oJ4H8rjcveFwEKA6upqr6mp6UOIqVdbW8tAjQ36P77m1nZefHMvT67bzZPrdvE/G/Zz3/oWRhXkcM708tARoJzJYxJ70HK4nb/+pviSo/gi6U4qO8xsvLtvD7e3dobyrcDkmHqTgG2hvKZTeW0onxSnvgwieTlZnDWtjLOmlfGli49n78Fmnt6wmyde38WT63bz4Oq3AZhWXszsGeWcUTWGkyeWMGVMkXqUiQxQ6U4qS4H5wI3h/f6Y8mvNbAlRo/z+kHgeAr4d0zh/EXC9u9eZWb2ZzQKeBa4EfpTOLyL9b3RxHh98zwQ++J4JuDsbdjXwxOvRVcw9K7ey+Jk3ABhVkMNJE0uOvE6eWMLUBK9mRCS1UpZUzOxXRFcZ5Wa2lagX143APWZ2FfAmcHmo/gBwKbAeaAQ+BRCSxzeAFaHe1zsa7YGriXqYFRI10KuRfggxM6aPG8n0cSP59PuqaG5t589v17N6235eeWs/q9/azx1Pb6a5rR2Akfk5TChq56mGVzl5UgknTihhWnkxWX1omxGRvktl768ruth0QZy6DlzTxXEWAYvilK8ETkomRhk88nKyOHlSCSdPKqHjh9XS1s7rO+pZ/VaUaP60diu/WP4Gh1ujRFOcl82JE0o4ceIoTp5YwvHvGsm08hEU5mVn7ouIDHEDpaFepNdys7OipDGhhL87A2pL93DO7HNZv7OB1eFqZvW2Ayx5bgu3t2w+st+EkgKmjR3BtLHFVJUXR8vlxUwsLdSVjUiSlFRkSMnNzuLd40fx7vGjuLw66vvR1h61z6zb0cDGXQ1s3H2QjbsPct+Lb1Hf1Hpk37ycLKrKipk2NrzKR1A1tpjjykdQUqTnaEQSoaQiQ152lvEXFSOPGUXZ3dnd0MzGXQ1sColm464G/vx2Pcte3UFrzKRkZcV5TCkrYkJpIRNKCqL30kImlBQyobSAMcV56pEmgpKKDGNmxtiR+Ywdmc9Z08resa2lrZ0tdY1s3HWQjbsb2LjrIFv3HmLttgP88dUdR9ptOuTnZIVEUxASTViOST4iw4GSikgcudlZod1lBFDxjm3uzt7GFrbtO8Rb+w6xbd8htu9vOrL85Lrd7KhvovNgFUU5MOGFxxk3Mj96jSpg7Ih8xo2KEtu4kQWMG5XPyPwcXfXIoKWkItJLZsaY4jzGFOdx0sSSuHVa2tp5e3/TOxLOC2s3kDtyBDvrm1j5xl521h+mudMVD0BBbtbRJBMS0NiR+ZSPyGd0+NzRRbmMLsqjtCivT0PaiKSKkopICuRmZzF5TNE7hpipta3U1Mw8su7uHGhqZVd9EzsPHGZn/WF21jexqz4sHzjM6zvqeWr97nd0KIhlFg3eGZtoOhJPaVEuY8L66KJoe0lhLqMKcynIVbdqSQ0lFZEMMTNKCqM/9NPHdT8Vc1NLG3sONrP3YDN7G5upO7LccmR9X2ML2/c38er2A9QdbD6m3SdWfk4WJYW5lIZEU1KYy6H9h3m8fk1UXphLScy2ksJcRhXkMrIgl4LcLN2eky4pqYgMAgW52UwsLWRiaeIN/oea26hrPJqI9jW2sO9QCwcOtbD/UAv7G8P7oRbe2tfEzr1tvLxnKw2H418VdcjOMkbk5zAiP4eRBdH7iIKO9dyjZaF8ZHgvDmVFedkU5+VQlJ9NXrYS1FCjpCIyRBXmZTMxL/FE1DGKbWtbOweaWo8knH2Nzew/1EJ9UysNh1tpCO/RelRed7CZN/c0Uh+2H2ppS+gzc7KM4vwcivOyKep4z8uhOD+b4vycaDlse3tLM2/mb6YwN6pTlJdNYV42ReFVEFOen6NklSlKKiLyDjnZWUc6IvRVa1s7Bw+3UX+45Ugiqj/cSuPhNg42t9J4uJWDzW0cPNxKY3g/2NzKwcNtNDa3sm1fC43NrTSE9cbmKEnd8/qahD4/y6AwN5vCjuSTGyWggtwsCnOjBFSYm01+7rFlBblZFIT1Y8uyyM+JklZ+Tjb5uVnkZWdpJIYYSioi0u9ysrMoKcrqt5EI2tudhx+tZeZZ7+VQcxuNLa0cam6LlpvbaGxp41BIPo2h/FBLx3JUfqiljcMt7exuaKapJVpvammnqaWNppa2dzzs2lt52VlkWzvFTy07knTycrLIz+1IQLHJKGwL73lhW947tkXredlZ5OdmkZ99tG5ux3L20eXcbIveszKf4JRURGTAy8oyCnKih1VTpaWtI8EcTTSxiedQSxvNre0cbm3ncGuUoI4st7azYdMbjH3XuzjcGtU/3FG3pY36plZ2tzbTHOo2t7bT3NYejtFGEvnsGDlZdiT55GZHiSo328hrbyIdc4gpqYiIwJE/wiML+rZ/be3b1NSc3Kd9W9uOJpnmtvaQvI4mpo5k1tLaTkvb0TotbR6tt8aWtceUHd2+f8/OngPpB0oqIiIZlpOdRU52FkV9b8bqUW1tbeoOHiMrLZ8iIiLDgpKKiIj0m0GfVMxsjpn92czWm9l1mY5HRGQ4G9RJxcyygVuAS4ATgCvM7ITMRiUiMnwN6qQCnAmsd/eN7t4MLAHmZjgmEZFhy7zzpA+DiJl9FJjj7n8f1j8BnOXu13aqtwBYAFBRUTFzyZIlaY81EQ0NDYwYMSLTYXRJ8SVH8SVH8SUnmfjOP//85929OpG6g71LcbxHR4/Jku6+EFgIUF1d7TXpeAKoDzrGXhqoFF9yFF9yFF9y0hXfYL/9tRWYHLM+CdiWoVhERIa9wX77Kwd4HbgAeAtYAfwfd+9y1Dkz2wW8kZ4Ie60c2J3pILqh+JKj+JKj+JKTTHxT3X1sIhUH9e0vd281s2uBh4BsYFF3CSXsk9CJyQQzW5nofctMUHzJUXzJUXzJSVd8gzqpALj7A8ADmY5DREQGf5uKiIgMIEoqA8vCTAfQA8WXHMWXHMWXnLTEN6gb6kVEZGDRlYqIiPQbJRUREek3SippZmaTzewxM1trZmvM7PNx6tSY2X4zeym8/j3NMW42s1fCZ6+Ms93M7OYwMvQqMzs9jbEdH3NeXjKzA2b2hU510nr+zGyRme00s9UxZWPMbJmZrQvvo7vYd36os87M5qcxvv80s9fCf7/7zKy0i327/S2kML6vmtlbMf8NL+1i35SPUt5FfHfHxLbZzF7qYt90nL+4f1My9ht0d73S+ALGA6eH5ZFED2+e0KlODfD7DMa4GSjvZvulwINEw+TMAp7NUJzZwNtED2Zl7PwB5wKnA6tjyv4DuC4sXwd8J85+Y4CN4X10WB6dpvguAnLC8nfixZfIbyGF8X0V+FIC//03ANOAPODlzv+WUhVfp+3fA/49g+cv7t+UTP0GdaWSZu6+3d1fCMv1wFpgYmaj6rW5wJ0eWQ6Umtn4DMRxAbDB3TM6QoK7PwHUdSqeCywOy4uBy+LsejGwzN3r3H0vsAyYk4743P1hd28Nq8uJhjjKiC7OXyLSMkp5d/GZmQF/C/yqvz83Ud38TcnIb1BJJYPMrBI4DXg2zuazzexlM3vQzE5Ma2DRoJwPm9nzYYTnziYCW2LWt5KZxDiPrv8xZ/L8AVS4+3aI/tED4+LUGSjn8dNEV57x9PRbSKVrw+25RV3cuhkI5282sMPd13WxPa3nr9PflIz8BpVUMsTMRgC/Ab7g7gc6bX6B6JbOKcCPgP9Jc3jnuPvpRJOfXWNm53bantDo0KlkZnnAh4Bfx9mc6fOXqIFwHv8VaAXu6qJKT7+FVLkVOA44FdhOdIups4yfP+AKur9KSdv56+FvSpe7xSlL6hwqqWSAmeUS/ce/y91/23m7ux9w94aw/ACQa2bl6YrP3beF953AfUS3GWINhNGhLwFecPcdnTdk+vwFOzpuCYb3nXHqZPQ8hkbZDwIf83CDvbMEfgsp4e473L3N3duBn3XxuZk+fznA3wB3d1UnXeevi78pGfkNKqmkWbgHexuw1t2/30Wdd4V6mNmZRP+d9qQpvmIzG9mxTNSgu7pTtaXAlaEX2Cxgf8dldhp1+X+ImTx/MZYCHT1p5gP3x6nzEHCRmY0Ot3cuCmUpZ2ZzgK8AH3L3xi7qJPJbSFV8sW10H+7ic1cAM8ysKly5ziM67+lyIfCau2+NtzFd56+bvymZ+Q2msleCXnF7aryP6PJyFfBSeF0KfBb4bKhzLbCGqDfLcuC9aYxvWvjcl0MM/xrKY+Mz4BainjevANVpPodFREmiJKYsY+ePKLltB1qI/s/vKqAMeARYF97HhLrVwM9j9v00sD68PpXG+NYT3Uvv+A3+NNSdADzQ3W8hTfH9Ivy2VhH9cRzfOb6wfilRb6cN6YwvlN/R8ZuLqZuJ89fV35SM/AY1TIuIiPQb3f4SEZF+o6QiIiL9RklFRET6jZKKiIj0GyUVERHpN0oqIilgZg29rF9jZr9PVTwi6aKkIiIi/UZJRSSFwhVIrZndG+YvuSvmaf85oewpouE+OvYpDoMorjCzF81sbij/JzNbFJZPNrPVZlaUkS8m0gUlFZHUOw34AtEcF9OAc8ysgGhMq78mGun2XTH1/xV41N3PAM4H/jMM8/EDYLqZfRi4HfgH72KIFZFMUVIRSb3n3H2rR4MjvgRUAn8JbHL3dR4Na/HfMfUvAq4LswnWAgXAlLD/J4mGMHnc3Z9O31cQSUxOpgMQGQYOxyy3cfTfXVdjJBnwEXf/c5xtM4AGojGmRAYcXamIZMZrQJWZHRfWr4jZ9hDwuZi2l9PCewnwQ6LpbcvM7KNpjFckIUoqIhng7k3AAuAPoaE+dkrkbwC5wCozWx3WAW4CfuLurxON5HujmcWbzU8kYzRKsYiI9BtdqYiISL9RUhERkX6jpCIiIv1GSUVERPqNkoqIiPQbJRUREek3SioiItJv/n9QfdPJ9u+EZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the elbow score and look for the elbow\n",
    "# From the plot it looks like it is for either K=2 or K=3.\n",
    "x = np.array([i for i in range(1,21)])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, elbows_score[1:21])\n",
    "\n",
    "ax.set(xlabel='Index', ylabel='Elbow score',\n",
    "       title='Elbow method')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the k-means score as high as possible.  The k with the best score is the k we should chose, i.e. the optimal number of clusters. The problem is that this score will keep incresing to zero when k increases. This is because score is calculated from the distance from each point to the closest cluster centroid. Inertia is the sum of the squared distances between the points inside of a cluster. Since the train and test data have the same possible values, the k-means score will keep decreasing until there are a cluster in each corner of the hypercube that defines the feature space. Because of this $2^{128}$ will (potentially) be the best k, if we use the k-means score as the criterion to chose $k$. Usually this score starts to level of, that the increase in absolute value decrease. So one can usually pick a resonable $k$. This is known as the elbow method.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say that K = 2 is a nice treeshold. We take a closer look at K = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=2, random_state=1).fit(obs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-72787.55531829562"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.score(obs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people in cluster 0: 3709\n",
      "Number of people in cluster 1: 3791\n"
     ]
    }
   ],
   "source": [
    "for l in range(2):\n",
    "    print(\"Number of people in cluster %d: %d\" %(l,sum(kmeans_model.labels_ == l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the people are fairly divided between the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means Silhouette Analysis \n",
    "\n",
    "We will also look at the silhouette score as a tool to find the optimal $k$. The silhouette score is defined as follows \n",
    "\n",
    "$$ \\frac{(b - a)}{\\max(a, b)}$$\n",
    "where $a$ is the mean intra-cluster distance, and $b$ is the distance between the sample and the nearest cluster that the sample is not a part of. \n",
    "\n",
    "from this, we see that a silhouette scorea near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster. http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "Using silhouette score as criterion for the optimal $k$, we want the silhouette score to be as big as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.08886993606224575\n",
      "For n_clusters = 3 The average silhouette_score is : 0.07389904607173357\n",
      "For n_clusters = 4 The average silhouette_score is : 0.06938099447933833\n",
      "For n_clusters = 5 The average silhouette_score is : 0.06583929336668182\n",
      "For n_clusters = 6 The average silhouette_score is : 0.06382818007952795\n",
      "For n_clusters = 7 The average silhouette_score is : 0.06379434840757288\n",
      "For n_clusters = 8 The average silhouette_score is : 0.06548722174042636\n",
      "For n_clusters = 9 The average silhouette_score is : 0.06418217499961712\n",
      "For n_clusters = 10 The average silhouette_score is : 0.06438648215882345\n"
     ]
    }
   ],
   "source": [
    "for n_clusters in range(2,11):\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(obs_train)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(obs_train, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we see that we get the highest value of the silhouette score at $k = 2$, so if we use the silhouette score as the criterion, we should choose $k = 2$. For the rest of this project, we will use $k = 2$ when we use clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SilhouetteScore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out Kmeans with 2 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=2, random_state=1).fit(obs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obs_0 = obs_train[kmeans_model.labels_ == 0]\n",
    "train_obs_1 = obs_train[kmeans_model.labels_ == 1]\n",
    "train_lab_0 = lab_train[kmeans_model.labels_ == 0]\n",
    "train_lab_1 = lab_train[kmeans_model.labels_ == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the histogram and see that there are more people with symptom categories 1 and 3  in the 0 cluster. \n",
    "And there are more people with symptom categories 0 and 2 in cluster 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_lab_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_lab_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, we see that there are more patients in cluster 1 that experience symptoms, than in cluster 0. This may mean that the patients in cluster 1 are more ill than the patients in cluster 0. At least it means that the patients in cluster 1, on average, $\\textit{feel}$ more sick than the patients in cluster $0$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selction on the historical data\n",
    "\n",
    "Here we use scikit learn's $\\texttt{SelectKBest}$ (https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) to score the features using the $\\texttt{chi2}$ function. Chi-squared is suited for classification tasks with non-negative features, which fits our scenario. In the code below we look at both the 10 best scores and all the significant explanatory variables. From the printout we see that 102 of the variables are significant, that is, they have a p-value of less than 0.05. By the defintion of the p-value we expect some of these variables are included by chance.\n",
    "\n",
    "We have also created 250 trees from $\\texttt{ExtraTreesClassifier}$ and from this we look at the feature importances of each of the varaibles in this ensamble of trees. Here we see that there is an overlap with the results from the $\\texttt{SelectKBest}$-method. Both methods agree that $x_{130} = a, x_{128}, x_{129}, x_{102}$ are the 4 most important features, in descending order. That means that the treatment and the symptoms are the most important factors for whether or not the patient displays measurable effects after the treatment. The order of the other variables can be shifted in the two methods due to, e.g. high correlation between the variables, but we have not done any further investigation into that. \n",
    "\n",
    "Note that we included the actions here. This is strictly a part of the next question, but either way, we now know that the action is the most important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 131)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "features2 = pandas.read_csv('historical_X.dat', header=None, sep=\" \")\n",
    "features2['a'] = pandas.read_csv('historical_A.dat', header=None, sep=\" \")\n",
    "\n",
    "X, y = features2.values, outcome\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 variables with best score: \n",
      "[130 128 129 102  55   5 126  44  52 101]\n",
      "[3753.63263455  617.44078638  504.95725172  270.78275622  207.93236283\n",
      "  200.7152214   192.89502425  174.65142505  165.34247839  161.54590066]\n",
      "\n",
      "The 102 most significant vairables\n",
      "[130 128 129 102  55   5 126  44  52 101  69 123  94 125   7  48  84  43\n",
      "  97  50  46   3   2  28  10  72  42  85  11  60  83  93 107 110  23 119\n",
      "  15  49  24 113  90  22  66  73  63  91 120  95  53  16 124  26 105  71\n",
      "  31  20  45 103  58  41  68  78  59  19  89 108  70  27  29  18 117  21\n",
      "  12  62  65  77  61  17 118 114 104  51  30 111  92 109  13  88  34  64\n",
      "  98  35   8  75  14  38  79  82 122  87  54   0]\n",
      "[0.00000000e+000 2.69388243e-136 7.93200355e-112 7.66146540e-061\n",
      " 3.88128940e-047 1.45799468e-045 7.42051836e-044 7.13389823e-040\n",
      " 7.70010748e-038 5.19873280e-037 3.77305985e-036 4.47491319e-036\n",
      " 6.35297613e-035 1.35183836e-033 5.10005660e-033 7.50601148e-033\n",
      " 2.95759765e-032 7.90761948e-032 1.66939946e-030 3.56119654e-030\n",
      " 1.45657621e-029 1.74220512e-029 2.92991312e-028 5.18434273e-027\n",
      " 2.08242011e-026 8.85935690e-026 3.46856264e-024 7.90899928e-024\n",
      " 1.65647408e-023 3.25479944e-022 6.01246332e-022 1.71389959e-021\n",
      " 5.31899755e-019 6.82335203e-019 1.67766006e-018 4.80860478e-017\n",
      " 1.72977601e-016 3.38779350e-016 4.39540455e-015 1.07964056e-014\n",
      " 1.12816851e-014 2.06271732e-014 1.02603396e-013 1.17547114e-013\n",
      " 4.47771942e-012 1.12136574e-011 1.53988629e-011 3.13637005e-011\n",
      " 4.50355639e-011 8.18201697e-011 9.16406437e-011 9.27057231e-011\n",
      " 2.40461685e-010 2.62444108e-010 3.79284305e-010 4.43381607e-010\n",
      " 7.29311738e-010 1.01494895e-009 2.03298215e-009 4.30979083e-009\n",
      " 6.19648811e-009 8.14485814e-009 1.07121951e-008 3.77179937e-008\n",
      " 5.75166824e-008 2.34781462e-007 4.30914558e-007 5.79182798e-007\n",
      " 5.80268020e-007 1.31455984e-006 4.01143881e-006 8.19761118e-006\n",
      " 1.22534327e-005 1.41655765e-005 1.50441802e-005 1.65305920e-005\n",
      " 2.93645317e-005 3.01271752e-005 3.58095598e-005 1.88313931e-004\n",
      " 2.54875941e-004 3.57877416e-004 5.77076415e-004 9.57272439e-004\n",
      " 1.20204348e-003 1.88107539e-003 2.25154127e-003 2.70523970e-003\n",
      " 2.92808566e-003 4.25046706e-003 4.82398210e-003 7.09734872e-003\n",
      " 7.52529621e-003 7.60004732e-003 7.72444571e-003 8.12511664e-003\n",
      " 8.39188331e-003 2.23261654e-002 3.31813859e-002 3.51647370e-002\n",
      " 4.29716540e-002 4.58646427e-002]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "k_best = SelectKBest(chi2, k=2).fit(X, y)\n",
    "\n",
    "# Let's look at the 10 best scores\n",
    "# High score is better\n",
    "b = np.argsort(-k_best.scores_)[:10]\n",
    "print(\"The 10 variables with best score: \")\n",
    "print(b)\n",
    "print(k_best.scores_[b])\n",
    "\n",
    "# Let's look at the best p-values. A low p-value indicate that the explanatory variable is significant.\n",
    "# We set the significance limit at 0.05 = 5e-02\n",
    "print(\"\\nThe 102 most significant vairables\")\n",
    "b = np.argsort(k_best.pvalues_)[:102]\n",
    "print(b)\n",
    "print(k_best.pvalues_[b])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the case where create an ensamble of 250 trees and look at the importance of the variables in these trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ten variables with highest scores:\n",
      "[130 128 129 102 101 127   5  23   7 126]\n",
      "[0.34049146 0.03828523 0.02930302 0.01922443 0.010168   0.01010108\n",
      " 0.00924306 0.00907907 0.00903429 0.0086236 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=250)\n",
    "clf = clf.fit(X, np.ravel(y))\n",
    "b = np.argsort(-clf.feature_importances_)[:10]\n",
    "print(\"The ten variables with highest scores:\")\n",
    "print(b)\n",
    "print(clf.feature_importances_[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Measuring the effect of actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to observe the effects of two different therapeutic interventions, one of which is placebo, and the other is an experimental drug. First we calculate the success of the two treatments in the whole data set. Here we assume that treatment 0 is placebo and treatment 1 is active treatment, but it could very well be the other way around. We also assume that Y = 1 means that the patient is cured, and Y = 0 means that the patient is not cured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effectiveness of placebo is: 0.008959 \n",
      "The effectiveness of active treatment is: 0.588338 \n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('historical_X.dat', header=None, sep=\" \")\n",
    "actions = pd.read_csv('historical_A.dat', header=None, sep=\" \")\n",
    "outcome = pd.read_csv('historical_Y.dat', header=None, sep=\" \")\n",
    "\n",
    "active_treatments = 0\n",
    "success_placebo = 0\n",
    "success_active = 0\n",
    "\n",
    "active_treatments = sum(actions.loc[:,0])\n",
    "\n",
    "for i in range(len(actions)):\n",
    "    if actions.loc[i,0] == 1 and outcome.loc[i,0] == 1:\n",
    "        success_active += 1\n",
    "    elif actions.loc[i,0] == 0 and outcome.loc[i,0] == 1:\n",
    "        success_placebo += 1\n",
    "\n",
    "print(\"The effectiveness of placebo is: %f \" %(success_placebo/(10000-active_treatments)))\n",
    "print(\"The effectiveness of active treatment is: %f \" %(success_active/(active_treatments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the treatment is effective in 58.8% of the cases for treatment 1, and 0.9% effective for treatment 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to investigate whether there are some variables that effect the outcome of the treatment. I.e. if there are some genes or other variables that affect the effect of the treatment. From previous variable\n",
    "selection, we found that the most important features were $X_2$, $X_4$, $X_6$, $X_{12}$, $X_{56}$, $X_{84}$, $X_{114}$. To find out if there is some interaction between some parameters, we choose these features and also include the action feature, and do logistic regression for models with interactions with parameter selection. For code see $\\texttt{log_reg_interact.R}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Call:\n",
    "glm(formula = Y ~ X2 + X4 + X6 + X56 + X84 + X114 + A + X2:X4 + \n",
    "    X4:X6 + X84:A, family = binomial(link = \"logit\"), data = df2)\n",
    "\n",
    "Deviance Residuals: \n",
    "    Min       1Q   Median       3Q      Max  \n",
    "-3.0360  -0.5767  -0.3569  -0.1525   2.8913  \n",
    "\n",
    "Coefficients:\n",
    "            Estimate Std. Error z value Pr(>|z|)    \n",
    "(Intercept) -4.67718    0.16487 -28.369  < 2e-16 ***\n",
    "X2          -0.08487    0.14421  -0.589 0.556160    \n",
    "X4           1.05140    0.20175   5.211 1.87e-07 ***\n",
    "X6           2.15315    0.15559  13.838  < 2e-16 ***\n",
    "X56          0.31314    0.07974   3.927 8.60e-05 ***\n",
    "X84          0.51283    0.08225   6.235 4.52e-10 ***\n",
    "X114         1.09017    0.16115   6.765 1.33e-11 ***\n",
    "A            4.75012    0.14823  32.045  < 2e-16 ***\n",
    "X2:X4        0.57515    0.16910   3.401 0.000671 ***\n",
    "X4:X6       -1.24885    0.17152  -7.281 3.31e-13 ***\n",
    "X84:A        1.85978    0.39793   4.674 2.96e-06 ***\n",
    "---\n",
    "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1\n",
    "\n",
    "(Dispersion parameter for binomial family taken to be 1)\n",
    "\n",
    "    Null deviance: 10777.7  on 9998  degrees of freedom\n",
    "Residual deviance:  5832.4  on 9988  degrees of freedom\n",
    "AIC: 5854.4\n",
    "\n",
    "Number of Fisher Scoring iterations: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text above is the output from R after we have done a parameter selection using BIC, allowing interactions of second order. We see here that the only interaction term including $A$ kept by the feature selection is the interaction between $X_{84}$ and $A$. The interaction term is positive, meaning that the treatment is more successfull when the $X_{84}$ feature is present. We repeat this process, but this time using AIC as selection criterion and get the following model. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Call:\n",
    "glm(formula = Y ~ X2 + X4 + X6 + X12 + X56 + X84 + X114 + A + \n",
    "    X2:X4 + X2:X84 + X2:A + X4:X6 + X4:X56 + X4:X84 + X6:X12 + \n",
    "    X6:X56 + X12:X56 + X56:X114 + X84:A, family = binomial(link = \"logit\"), \n",
    "    data = df2)\n",
    "\n",
    "Deviance Residuals: \n",
    "    Min       1Q   Median       3Q      Max  \n",
    "-3.0475  -0.5790  -0.3163  -0.1318   2.9156  \n",
    "\n",
    "Coefficients:\n",
    "            Estimate Std. Error z value Pr(>|z|)    \n",
    "(Intercept) -4.68844    0.24600 -19.058  < 2e-16 ***\n",
    "X2          -0.31497    0.18091  -1.741  0.08169 .  \n",
    "X4           0.89944    0.30607   2.939  0.00330 ** \n",
    "X6           1.88170    0.23232   8.099 5.52e-16 ***\n",
    "X12         -0.09774    0.17791  -0.549  0.58276    \n",
    "X56          0.26167    0.20762   1.260  0.20754    \n",
    "X84          0.65262    0.15372   4.245 2.18e-05 ***\n",
    "X114         1.43465    0.22428   6.397 1.59e-10 ***\n",
    "A            4.68603    0.16591  28.244  < 2e-16 ***\n",
    "X2:X4        0.64661    0.17501   3.695  0.00022 ***\n",
    "X2:X84       0.29707    0.15714   1.891  0.05869 .  \n",
    "X2:A         0.62489    0.36071   1.732  0.08321 .  \n",
    "X4:X6       -1.38088    0.20676  -6.679 2.41e-11 ***\n",
    "X4:X56       0.80771    0.34532   2.339  0.01933 *  \n",
    "X4:X84      -0.33236    0.17645  -1.884  0.05962 .  \n",
    "X6:X12       0.41585    0.18598   2.236  0.02536 *  \n",
    "X6:X56       0.32303    0.19385   1.666  0.09564 .  \n",
    "X12:X56     -0.34621    0.18055  -1.918  0.05517 .  \n",
    "X56:X114    -0.73643    0.33422  -2.203  0.02757 *  \n",
    "X84:A        1.78385    0.40039   4.455 8.38e-06 ***\n",
    "---\n",
    "Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1\n",
    "\n",
    "(Dispersion parameter for binomial family taken to be 1)\n",
    "\n",
    "    Null deviance: 10777.7  on 9998  degrees of freedom\n",
    "Residual deviance:  5809.1  on 9979  degrees of freedom\n",
    "AIC: 5849.1\n",
    "\n",
    "Number of Fisher Scoring iterations: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this model, it does not seem like any features have a negative interaction with $A$, meaning that the active treatment will be effective for all features. However we do observe that some features and some feature combinations seems to have a negative effect on the result of the treatment. In both the AIC and the BIC model, the presence of the $X_2$ feature influences the result of the treatment in a negative way, meaning that these patients are less likely of being cured. Also, both models indicate that the feature combination of $X_4$ and $X_6$ influence the result of the treatment in a negative way. Based on this, we would always recommend the active treatment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would also like to investigate whether the clusters found by K-means clustering are affected differently by the treatment. We found that two clusters were the optimal number of clusters. We choose to do this on the whole data set, so that all the data are divided into one of the two clusters. For this, we repeat the procedure of the first part of Question 2, but this time dividing the data into the two clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effectiveness of placebo in cluster 0 is: 0.017947 \n",
      "The effectiveness of active treatment in cluster 0 is: 0.665198 \n",
      "The effectiveness of placebo in cluster 1 is: 0.001209 \n",
      "The effectiveness of active treatment in cluster 1 is: 0.476496 \n"
     ]
    }
   ],
   "source": [
    "# First fit a K-means\n",
    "kmeans = KMeans(n_clusters = 2, random_state = 1).fit(obs_train)\n",
    "\n",
    "#Divide observations into two clusters. \n",
    "cluster = kmeans.predict(observations)  \n",
    "index_cluster0 = np.where(cluster == 0) \n",
    "index_cluster1 = np.where(cluster == 1)\n",
    "\n",
    "actions_cluster0 = actions.iloc[index_cluster0]\n",
    "outcome_cluster0 = outcome.iloc[index_cluster0]\n",
    "\n",
    "actions_cluster1 = actions.iloc[index_cluster1]\n",
    "outcome_cluster1 = outcome.iloc[index_cluster1]\n",
    "\n",
    "active_treatments0 = sum(actions_cluster0.loc[:,0])\n",
    "active_treatments1 = sum(actions_cluster1.loc[:,0])\n",
    "\n",
    "#First cluster 0:\n",
    "#Successfull and active treatments if both are 1\n",
    "success_active0 = np.sum(np.multiply(actions_cluster0.values, outcome_cluster0.values))\n",
    "#Successfull, active treatments if outcome is 1, but active is 0\n",
    "success_placebo0 = np.sum(outcome_cluster0.values) - success_active0\n",
    "\n",
    "print(\"The effectiveness of placebo in cluster 0 is: %f \" %(success_placebo0/(actions_cluster0.shape[0]-active_treatments0)))\n",
    "print(\"The effectiveness of active treatment in cluster 0 is: %f \" %(success_active0/(active_treatments0)))        \n",
    "\n",
    "#Cluster 1\n",
    "success_active1 = np.sum(np.multiply(actions_cluster1.values, outcome_cluster1.values))\n",
    "success_placebo1 = np.sum(outcome_cluster1.values) - success_active1\n",
    "\n",
    "print(\"The effectiveness of placebo in cluster 1 is: %f \" %(success_placebo1/(actions_cluster1.shape[0]-active_treatments1)))\n",
    "print(\"The effectiveness of active treatment in cluster 1 is: %f \" %(success_active1/(active_treatments1)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the a bigger proportion of patients in cluster 1 are cured than in cluster 0, this apply both to the active treatment and the placebo treatment.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part Two - Improved Policies\n",
    "### Exercise 1 (Measuring utility)\n",
    "#### 1. Measure the utility of $\\pi_0$ on the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('historical_X.dat', header=None, sep=\" \").values\n",
    "actions = pd.read_csv('historical_A.dat', header=None, sep=\" \").values\n",
    "outcome = pd.read_csv('historical_Y.dat', header=None, sep=\" \").values\n",
    "\n",
    "# Actions is an array of 0's and 1's, representing 'placebo' and 'experimantal drug', respectively.\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Outcome is an array of 0' and 1's, representing 'no effect' and 'measurable effect', respectively.\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility function is given as:\n",
    "$$\\frac{1}{T}\\sum_t^T r_t = \\frac{1}{T}\\sum_t^T (-0.1a_t + y_t).$$\n",
    "Here the -0.1 factor implies that the active treatment must be at least 10% more effective than the placebo for the utility to be better for the experimental drug than the placebo. We look at the utility of $\\pi_0$ on the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11912"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = np.sum(-0.1*actions + outcome)/len(outcome)\n",
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the utility is 0.11912. At this point, we are not confident on wheter or not this is a good result. One should note that $t$ span from 0 to 1. So the maximal utility we can achieve is 1. However, in that scenario we give placebo to all the patients and we see a measurable effect in all of them, which is highly unlikely. Because of our utility function, giving a patient the active treatment decrease the utility if the patient is not cured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercise asks for the expected utility. We cannot calculate it exactly, but we can estimate it from the data. That is what we have done above. Below we describe it futher.\n",
    "$$\\hat{E[U]} = E_{data}[U] = \\frac{1}{T}\\sum_t^T (-0.1E_{data}[a_t] + E_{data}[y_t])$$ where $E_{data}[a_t] = 0p(a_t=0) + 1p(a_t=1) = \\frac{\\# a_t = 1}{\\# a_t}$ and $E_{data}[y_t] = 0p(y_t=0) + 1p(y_t=1) = \\frac{\\# y_t = 1}{\\# y_t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1421"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc1out = np.sum(outcome==1)/len(outcome)\n",
    "perc1out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2298"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc1act = np.sum(actions==1)/len(actions)\n",
    "perc1act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11912"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.1*perc1act + perc1out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which was the same as we got above, as expected.\n",
    "We have also implemented this in the python file we have delivered.\n",
    "Simply call policy.estimate_utility(features, actions, outcome)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Provide error bounds on the expected utility\n",
    "To provide error bounds on the expected utility we use bootstraping. We create $B$ datasets by sampling from the original data $10 000$ times with replacement. For each of the $B$ dataset we calculate the expected utility. We do this to get empirical confidence intervals of the expected utility. For a 95% error bound we look at the 2.5% and 97.5% quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 500\n",
    "results = np.zeros(B)\n",
    "\n",
    "for b in range(B):\n",
    "    n = len(outcome)\n",
    "    indices = np.random.choice(n, n)\n",
    "    outcome_bootstrap = outcome[indices]\n",
    "    action_bootstrap = actions[indices]\n",
    "    results[b] = np.sum(-0.1*action_bootstrap + outcome_bootstrap)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11275725, 0.1258845 ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = np.percentile(results, [2.5, 97.5])\n",
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we see that a 95% CI for the utility is $[0.1131, 0.1259]$. So the utility of $\\pi_0$ is well inside these error bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to improve the policy, so that we can increase the utility. For the model, we choose a neural network and logistic regression, which we fit by first making an object of the classes $\\texttt{NNRecommender}$ and $\\texttt{LogisticRecommender}$, in the file $\\texttt{TestRecommender.py}$, where we set the reward function to what it is defined as in the project description. We then call the policies' $\\texttt{fit_treatment_outcome}$-function, so that our policies are trained on the historical data. To find the estimated utility of these improved models, we call $\\texttt{policy_NN.estimate_utility(features, None, None, policy.NN)}$ and $\\texttt{policy_logistic.estimate_utility(features, None, None, policy.logistic)}$. Note that when a $\\texttt{policy}$ argument is given to the $\\texttt{estimate_utility}$-function, the $\\texttt{policy}$ will recommend an action, and it is these actions (and the probabilities of the different outomes) that are used to calculate the estimated utility.  $\\textbf{Skriv hva modellene er}$.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "$\\textbf{Forklar hva dette er }$\n",
    "\n",
    "Below you can see the last printout from $\\texttt{TestRecommender.py}$. From this we see that both logistic regression and neural network are better than the historical policy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network estimating utility   1000 of 10000\n",
      "Neural Network estimating utility   2000 of 10000\n",
      "Neural Network estimating utility   3000 of 10000\n",
      "Neural Network estimating utility   4000 of 10000\n",
      "Neural Network estimating utility   5000 of 10000\n",
      "Neural Network estimating utility   6000 of 10000\n",
      "Neural Network estimating utility   7000 of 10000\n",
      "Neural Network estimating utility   8000 of 10000\n",
      "Neural Network estimating utility   9000 of 10000\n",
      "Neural Network estimating utility  10000 of 10000\n",
      "Logistic model estimating utility   1000 of 10000\n",
      "Logistic model estimating utility   2000 of 10000\n",
      "Logistic model estimating utility   3000 of 10000\n",
      "Logistic model estimating utility   4000 of 10000\n",
      "Logistic model estimating utility   5000 of 10000\n",
      "Logistic model estimating utility   6000 of 10000\n",
      "Logistic model estimating utility   7000 of 10000\n",
      "Logistic model estimating utility   8000 of 10000\n",
      "Logistic model estimating utility   9000 of 10000\n",
      "Logistic model estimating utility  10000 of 10000\n",
      "\n",
      "The historical utility was 0.119120\n",
      "The estimated utility of the improved NN policy is: 0.459083 \n",
      "The estimated utility of the improved logistic policy is: 0.427203\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "features = pandas.read_csv('historical_X.dat', header=None, sep=\" \").values\n",
    "actions = pandas.read_csv('historical_A.dat', header=None, sep=\" \").values\n",
    "outcome = pandas.read_csv('historical_Y.dat', header=None, sep=\" \").values\n",
    "n = features.shape[0]\n",
    "\n",
    "import NNRecommender\n",
    "policy_factory_NN = NNRecommender.NNRecommender\n",
    "policy_NN = policy_factory_NN(2, 2)\n",
    "\n",
    "import LogisticRecommender\n",
    "policy_factory_logistic = LogisticRecommender.LogisticRecommender\n",
    "policy_logistic = policy_factory_logistic(2, 2)\n",
    "\n",
    "def reward_function(action, outcome):\n",
    "    return -0.1*action + outcome\n",
    "\n",
    "# First we need to set the reward\n",
    "policy_NN.set_reward(reward_function)\n",
    "policy_logistic.set_reward(reward_function)\n",
    "\n",
    "## Fit the policy on historical data \n",
    "policy_NN.fit_treatment_outcome(features, actions, outcome)\n",
    "policy_logistic.fit_treatment_outcome(features, actions, outcome)\n",
    "\n",
    "# Utility of the historical policy. Deterministic, so no difference if we call with policy_NN or policy_logistic\n",
    "utility_hist = policy_NN.estimate_utility(features, actions, outcome)/n\n",
    "\n",
    "# Utility of new policy\n",
    "utility_new_policy_NN = policy_NN.estimate_utility(features, None, None, policy_NN)/n\n",
    "utility_new_policy_logistic = policy_logistic.estimate_utility(features, None, None, policy_logistic)/n\n",
    "\n",
    "# Utility of improved policy, using a neural network trained on the historical data\n",
    "print(\"\\nThe historical utility was %2f\" %(utility_hist))\n",
    "print(\"The estimated utility of the improved NN policy is: %2f \" % (utility_new_policy_NN))\n",
    "print(\"The estimated utility of the improved logistic policy is: %2f\"  % (utility_new_policy_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Three - Adaptive Experiment Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part part we are going to test our recommenders on new patients and evaluate the results. We do this by using the $\\texttt{test_policy}$ function. It creates a fixed number of patients, ask the recommenders what treatment each indivdual should recive and then calculate the outcome. At the end it let the recommender observe the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy(generator, policy, reward_function, T, seed = None, printout = False, print_index = 100, actions=False):\n",
    "    policy.set_reward(reward_function)\n",
    "    u = 0\n",
    "    \n",
    "    # Variable to count the number of people who were given a treatment\n",
    "    total_given_treatment = 0\n",
    "    \n",
    "    # For reproducibility we allow the user to set the seed\n",
    "    if (seed != None):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    # Record the number of each treatments \n",
    "    if (actions == True):\n",
    "        actions_count = np.zeros(129)\n",
    "    \n",
    "    for t in range(T):\n",
    "        # We generate 1 new pasient\n",
    "        x = generator.generate_features()\n",
    "        \n",
    "        # Find the best action, from our model\n",
    "        a = policy.recommend(x)\n",
    "        \n",
    "        if (actions == True):\n",
    "            actions_count[a] += 1\n",
    "\n",
    "        # If given a treatment, then we record it\n",
    "        if (a != 0): \n",
    "            total_given_treatment += 1\n",
    "            \n",
    "        # Generate the outcome based on user_data and action\n",
    "        y = generator.generate_outcome(x, a)\n",
    "       \n",
    "        # Add the utility/reward\n",
    "        u += reward_function(a, y)\n",
    "        \n",
    "        # Let the policy now about the result/refit the model.\n",
    "        policy.observe(x, a, y)\n",
    "        \n",
    "        # A small printout\n",
    "        if ((printout) & (t % print_index == 0)):\n",
    "            print(\"Iteration: %6d \\t Current mean reward: %7.4f\" %(t, u/(t+1)))\n",
    "    \n",
    "    if (actions):\n",
    "        return [u/T, total_given_treatment, actions_count] \n",
    "    else:\n",
    "        return [u/T, total_given_treatment] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the introduction we use a slightly modified $\\texttt{reward_function}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(action, outcome):\n",
    "    # Here we use the alternative reward_function discussed in the introduction.\n",
    "    # That is, we assume all medicins have the same cost and that they must be 10% more efficient than the placebo.\n",
    "    if (action >= 1): \n",
    "        return -0.1 + outcome\n",
    "    else: \n",
    "        return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the results one should let each recommender run several times. There is a high variability in the results. That means that the results from two consecutive simulations can yield quite different results. Hence it is important to create empirical confidence intervals for the utility. We have not computed the variance of the empirical data, since this is indirectly visible from the range of the confidence intervals, but the variance is also a good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator generates the data and the outcome\n",
    "# policy_maker is an object that can create policies\n",
    "# reward_function calculate the reward given the action and the outcome\n",
    "# T is the number of patients\n",
    "# N is the number of times we should treat T patients\n",
    "# features are the historical features\n",
    "# actions are the historical actions\n",
    "# outcome are the historical outcome\n",
    "# extra is extra arguments for the policy\n",
    "def create_CI(generator, policy_maker, reward_function, T, N, features, actions, outcome, extra = None):\n",
    "    res = np.zeros((N,2))\n",
    "    for n in range(N):\n",
    "        # Create a policy from the policymaker\n",
    "        if (extra == None):\n",
    "            policy = policy_maker(generator.get_n_actions(), generator.get_n_outcomes())\n",
    "        else:\n",
    "            policy = policy_maker(generator.get_n_actions(), generator.get_n_outcomes(), extra)\n",
    "            \n",
    "        # Set the reward function\n",
    "        policy.set_reward(reward_function)\n",
    "        \n",
    "        # Fit the model\n",
    "        policy.fit_treatment_outcome(features, actions, outcome)\n",
    "        \n",
    "        # Record the results\n",
    "        res[n] = test_policy(generator, policy, reward_function, T, seed = 27183+n)\n",
    "        \n",
    "        if(n % 10 == 0):\n",
    "            print(\"Done with n = %d\" % n)\n",
    "\n",
    "    print(\"Utility percentiles(2.5, 50, 97.5): \", np.percentile(res[:,0], [2.5, 50, 97.5]))\n",
    "    print(\"Percentage of treatments percentiles(2.5, 50, 97.5): \", np.percentile(res[:,1], [2.5, 50, 97.5])/T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - online policy testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "\n",
    "Here we create a $\\texttt{HistoricalRecommender}$ recommender and test it on the testbench. Recall that the $\\texttt{HistoricalRecommender}$ recommends based on the frequency of recommendations in the historical dataset. That is, if the percentage of people given the placebo in the historical data is $30\\%$, then our recommender will also recommend placebo in $30\\%$ of the cases. \n",
    "\n",
    "In hindsight we are uncertain if we mayhaps misinterpreted this model. The idea might have been that we should have used the historical dataset to find the person in this dataset who is most similar to the new patient and give the new patient the same treatment as the historical patient. This could have been done with a KNN with K=1.\n",
    "\n",
    "Whether or not we misinterpreted it, our model yields close to the historical results. Hence we are quite certain that what we have done is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_generation\n",
    "generator = data_generation.DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.08799 0.1064  0.13249]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.202   0.23    0.26305]\n"
     ]
    }
   ],
   "source": [
    "import HistoricalRecommender\n",
    "policy_factory_historical = HistoricalRecommender.HistoricalRecommender\n",
    "\n",
    "T = 500\n",
    "N = 100\n",
    "create_CI(generator, policy_factory_historical, reward_function, T, N, features, actions, outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above we get a bite wider interval than in the previous part, but note that the median is close to the historical utility and that our $95\\%$ empirical confidence interval cover the results from the historical part.\n",
    "Note that the the historical recommender prescribe treatments to about a fifth of the patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "Here we are going to look at the improved recommenders. For these improved recommenders we tested both neural network models and logistic regression models. We tuned  $\\textbf{Skriv om tuning og ksdfkd}$ \n",
    "We also create some trivial recommenders to have more recommenders to compare our improved policies with. \n",
    "We have created a $\\texttt{FixedTreatmentRecommender}$ and a $\\texttt{RandomRecommender}$. These should be self explanatory, but they always recommend a fixed treatment(placebo or active treatment, defined in the initialization) or does a random choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always placebo: \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.004 0.012 0.022]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0. 0. 0.]\n",
      "\n",
      "Always treatment1: \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.38895 0.434   0.478  ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [1. 1. 1.]\n",
      "\n",
      "Random treatment: \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.188095 0.2252   0.26056 ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.4619 0.505  0.54  ]\n"
     ]
    }
   ],
   "source": [
    "import FixedTreatmentRecommender\n",
    "policy_factory_fixed = FixedTreatmentRecommender.FixedTreatmentRecommender\n",
    "\n",
    "import RandomRecommender\n",
    "policy_factory_random = RandomRecommender.RandomRecommender\n",
    "\n",
    "T = 500\n",
    "N = 100\n",
    "\n",
    "print(\"Always placebo: \")\n",
    "create_CI(generator, policy_factory_fixed, reward_function, T, N, features, actions, outcome, extra = 0)\n",
    "\n",
    "print(\"\\nAlways treatment1: \")\n",
    "create_CI(generator, policy_factory_fixed, reward_function, T, N, features, actions, outcome, extra = 1)\n",
    "\n",
    "print(\"\\nRandom treatment: \")\n",
    "create_CI(generator, policy_factory_random, reward_function, T, N, features, actions, outcome, extra = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we in this case know how the outcomes are generated, that is, we have access to $\\texttt{big_generating_matrices.mat}$ and the $\\texttt{data_generation}$ we can create an $\\texttt{OptimalRecommender}$ that recommends the optimal treatment. From the two files we see that the outcome is decided based on the the sign of the dot product between the user and the $a$'th row of the big generating matrices. If the the dot product is positive then $y_t = 1$ and if the dot product is negative then $y_t = 0$. The optimal policy will then chose the action with highest dot product, given that it is positive, else it will recommend the placebo to maximize the reward (to escape the penatlity of using a treatment).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal: \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.440055 0.4806   0.5202  ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.48895 0.534   0.578  ]\n"
     ]
    }
   ],
   "source": [
    "import OptimalRecommender\n",
    "policy_factory_optimal = OptimalRecommender.OptimalRecommender\n",
    "\n",
    "T = 500\n",
    "N = 100\n",
    "\n",
    "print(\"Optimal: \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the optimal recommender performs a lot better than the historical recommender. \n",
    "\n",
    "Now we take a look at our improved policies:\n",
    "Single_logistic\n",
    "Bootstrap_logistic\n",
    "NN_(3,2,2)\n",
    "NN_(5,2)\n",
    "$\\textbf{Forklar}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single logistic model: \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.425695 0.4673   0.50802 ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.6299 0.678  0.712 ]\n",
      "Bootstrap logistic model: \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.4248   0.4665   0.507705]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.63495 0.682   0.72115]\n"
     ]
    }
   ],
   "source": [
    "# Single logistic\n",
    "import LogisticRecommender\n",
    "policy_factory_logistic = LogisticRecommender.LogisticRecommender\n",
    "\n",
    "# Ensamble of logistic models based on bootstraped datasets\n",
    "import LogisticRecommenderBoot\n",
    "policy_factory_logistic_boot = LogisticRecommenderBoot.LogisticRecommenderBoot\n",
    "\n",
    "print(\"Single logistic model: \")\n",
    "create_CI(generator, policy_factory_logistic, reward_function, T, N, features, actions, outcome, extra = 0)\n",
    "\n",
    "print(\"\\nBootstrap logistic model: \")\n",
    "create_CI(generator, policy_factory_logistic_boot, reward_function, T, N, features, actions, outcome, extra = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(5,2): \n",
      "Done with n = 9\n",
      "Done with n = 19\n",
      "Done with n = 29\n",
      "Done with n = 39\n",
      "Done with n = 49\n",
      "Done with n = 59\n",
      "Done with n = 69\n",
      "Done with n = 79\n",
      "Done with n = 89\n",
      "Done with n = 99\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.42499 0.4612  0.50504]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.4878 0.536  0.5801]\n",
      "NN(2,2,3): \n",
      "Done with n = 9\n",
      "Done with n = 19\n",
      "Done with n = 29\n",
      "Done with n = 39\n",
      "Done with n = 49\n",
      "Done with n = 59\n",
      "Done with n = 69\n",
      "Done with n = 79\n",
      "Done with n = 89\n",
      "Done with n = 99\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.42616 0.4671  0.51069]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.53495 0.578   0.6241 ]\n"
     ]
    }
   ],
   "source": [
    "import NeuralNetworkRecommender\n",
    "policy_factory_NN = NeuralNetworkRecommender.NeuralNetworkRecommender\n",
    "\n",
    "print(\"NN(5,2): \")\n",
    "create_CI(generator, policy_factory_NN, reward_function, T, N, features, actions, outcome, extra = [0, [5,2]])\n",
    "\n",
    "print(\"\\nNN(2,2,3): \")\n",
    "create_CI(generator, policy_factory_NN, reward_function, T, N, features, actions, outcome, extra = [0, [2,2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also created two other improved policies that use clustering; $\\texttt{LogisticRecommenderCluster}$ and $\\texttt{NNRecommenderCluster}$. That is, based on the the historical data it divides the population into two subpopulations and fit a model on each of these. The results for $\\texttt{LogisticRecommenderCluster}$ and $\\texttt{NNRecommenderCluster}$ are nearly identical to those obtained by the non-clustered versions. The neural network using clustering actually obtained a lower utility than the neural network that that did not use clustering of the date. We think this might be due to the fact that the training set for the individual neural networks became too small. As we know, it takes a lot of data to fine tune a neural network. Note that the code below takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic cluster: \n",
      "Done with n = 0\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.313625 0.46     0.73975 ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.56125 0.7     0.8775 ]\n",
      "NN cluster(5,2): \n",
      "Done with n = 0\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.320125 0.425    0.675   ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.41125 0.525   0.75   ]\n"
     ]
    }
   ],
   "source": [
    "import LogisticRecommenderCluster\n",
    "policy_factory_logistic_cluster = LogisticRecommenderCluster.LogisticRecommenderCluster\n",
    "\n",
    "# Old code so is hardcoded to (5,2) layers\n",
    "import NNRecommenderCluster\n",
    "policy_factory_NN_cluster = NNRecommenderCluster.NNRecommenderCluster\n",
    "\n",
    "N = 100\n",
    "T = 500\n",
    "\n",
    "print(\"Logistic cluster: \")\n",
    "create_CI(generator, policy_factory_logistic_cluster, reward_function, T, N, features, actions, outcome)\n",
    "\n",
    "print(\"NN cluster(5,2): \")\n",
    "create_CI(generator, policy_factory_NN_cluster, reward_function, T, N, features, actions, outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize the results from this exercise we have made a table. Note that the numbers might be different than the numbers above. That is becaus\n",
    "e we have not fixed a seed so the values change slightly each time you run the code. However, since we run the code 100 times each time the differences are miniscule.\n",
    "\n",
    "![title](Table1.png)\n",
    "\n",
    "From the table we see that the historical recommender and the improved recommenders perform at the same level as in the previous part. When we look at the utility confidence intervals of our improved policies we see that they overlap quite a lot. This means that the models are about equally good. However, one should note that the neural network recommends the drug less often but obtain the same utility as the logistic model. That is, the neural network is better at detecting patients who will respond to the treatment than the logistic model. The logistic model  recommends the treatment more often, so they treat more patients but they also get more patients who do not respond to the treatment. Here it would have been interesting to change the penalty and see if this influence the utility. One could also here look at a confusion matrix, to analyze the percentages of false-positve, false-negative, true-positve and true-negative.\n",
    "\n",
    "The clustered versions yield approximately the same results, and hence we have omitted them from the table.\n",
    "\n",
    "One should also note that utilty our improved policies are not far from the the utility optimal policy.\n",
    "\n",
    "\n",
    "\n",
    "$\\text{skriv om at siden utility er ganske lik \"koster\" det kanskje ikke s mye  gi behandling, eller s kan det vre at de fleste pasienter faktisk trenger den}$\n",
    "\n",
    "The fact that by always recommending the treatment we can obtain an utility which is this close to the optimal utility is quite worrying. At least in the setting where the vague terms treatments represent drugs. If we are in the case where the treatment is a sunscreen and the placebo is body lotion this \n",
    "giving the medicin results in a 95% percentile of the optimal value might it scary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - adaptive experiments\n",
    "\n",
    "In this exercise we are going to look at addaptive models. That is, we let our models observe the outcome of their recommendations such that they can learn from them. Since we have used supervised methods this implies that we have to refit our model with the new data. There is probably a better way to do this, since refitting the models take a long time. One should also note that new observations might drown in the old data in the method we have used. Here one might adress issues such as whether one should weight the most resent data higher than the old data. We have not adressed this issue.\n",
    "\n",
    "We will consider two scenarios. In the first scenario we have still only the placebo and the treatment. In the second scenario we introduced the other treatments. That is, we now have 129 treatments: 1 placebo, 2 general treatments and 126 gene specific treatments. Note that we in this scenario we do not have any data for the new treatments. Thus, one have to explore these new treatments and look at the results. This we will do for a fixed number of treatments, and then we are going to use the best treatment for the rest. \n",
    "\n",
    "Here there are two potential goals according to the text: discover the most effective treatment policy at the end of the trial or maximize the expected number of people to be treated. We have gone for the second on, but with the modified $\\texttt{reward_function}$ discussed earlier. \n",
    "\n",
    "We take a look at the first section first.\n",
    "#### 1. \n",
    "We have alredy described what the code does. It adds the new patient to the old dataset and refit the model. We do this with two of the models above. This is due to the long computation time it takes to run these simulations. Since the single logistic and the bootstrap logistic obtained the same results last time we only look at the simple version here. We also only look at the (5,2) neural network. We would have liked to tested (2,2,3) too, but it takes too long time. We allow our models to observe by changing the zeros to ones in the extra, otherwise the code below is identical to the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reduce the number of patients due to the computation time\n",
    "# We do noe recommend to run this block again since it takes hours to run.\n",
    "N = 100\n",
    "T = 100\n",
    "\n",
    "# Optimal recommender\n",
    "import OptimalRecommender\n",
    "policy_factory_optimal = OptimalRecommender.OptimalRecommender\n",
    "\n",
    "# Single logistic\n",
    "import LogisticRecommender\n",
    "policy_factory_logistic = LogisticRecommender.LogisticRecommender\n",
    "\n",
    "# Nerural network\n",
    "import NeuralNetworkRecommender\n",
    "policy_factory_NN = NeuralNetworkRecommender.NeuralNetworkRecommender\n",
    "\n",
    "print(\"Optimal: \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = 2)\n",
    "\n",
    "print(\"Single logistic model: \")\n",
    "create_CI(generator, policy_factory_logistic, reward_function, T, N, features, actions, outcome, extra = 1)\n",
    "\n",
    "print(\"NN(5,2): \")\n",
    "create_CI(generator, policy_factory_NN, reward_function, T, N, features, actions, outcome, extra = [1, [5,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the results of the code above in the left part of the table below. Note that there is not much improvments compared to the previous table. This might be because the new information drowns in the old data or there is some underlying noise that cannot be reduced. Note that each model now only treats 100 persons, due to the computational time, hence the wider intervals. So if you want to compare the results in this table with the previous table you should look at the medians.\n",
    "\n",
    "\n",
    "![title](Table2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. \n",
    "In this setting we are able to choose among the 129 treatments. We initialy had some difficulites so we will first adress what we had done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are informed that treatment 2 is a general treatment. So we want to compare it to the other genereal treatment; treatment 1. In some scenarios it it possible to test two treatments on a single individual, and in other cases it's impossible. E.g. you cannot donclude which of two painkillers relived you of the pain, under the assumption that both were taken by oral administration. However, you can can apply two different body lotions for dry skin on either arm and check which worked or not. In the code below we simulate the the latter scenario. \n",
    "\n",
    "Note that the analyis above in rooted in the real world. Since we are given the code we can treat the same patient with different treatments no mather the scenario. We also want to note that the analysis we are doing here is perhaps not applicable in the real world, since we just give them treatments and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose medicine 1 and 2 which we want to compare. \n",
    "# Can take values between 0 and 129, inclusive. \n",
    "# N is the number of individuals we want to compare.\n",
    "\n",
    "def compareTwoMedicines(med1, med2, N, seed = 10):\n",
    "    # Number of times medicine 1 worked \n",
    "    num1 = 0\n",
    "\n",
    "    # Number of times medicine 2 worked\n",
    "    num2 = 0\n",
    "\n",
    "    # Number of times only medicine 2 worked\n",
    "    numjust1 = 0\n",
    "\n",
    "    # Number of times only medicine 1 worked\n",
    "    numjust2 = 0\n",
    "\n",
    "    # Number of times both medecines worked\n",
    "    numboth = 0\n",
    "\n",
    "    # Number of times neither medicine worked\n",
    "    numnone = 0\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    for _ in range(N):\n",
    "            # We generate 1 new pasient\n",
    "            x = generator.generate_features()\n",
    "\n",
    "            # Generate the outcome based on user_data and action\n",
    "            y_1 = generator.generate_outcome(x, med1)\n",
    "            y_2 = generator.generate_outcome(x, med2)\n",
    "\n",
    "            if (y_1 == 1): num1 += 1\n",
    "            if (y_2 == 1): num2 += 1\n",
    "            if ((y_1 == 1) & (y_2 == 1)): numboth += 1\n",
    "            if ((y_1 == 0) & (y_2 == 0)): numnone += 1\n",
    "            if ((y_1 == 1) & (y_2 == 0)): numjust1 += 1\n",
    "            if ((y_1 == 0) & (y_2 == 1)): numjust2 += 1\n",
    "    print(\"Med1 = %d and med2 = %3d: %6d %6d %9d %9d %5d %6d\" % (med1, med2, num1, num2, numjust1, numjust2, numboth, numnone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Med1 = 1 and med2 =   2:  53553  54690     19312     20449 34241  25998\n"
     ]
    }
   ],
   "source": [
    "compareTwoMedicines(1, 2, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this printout we see that there is some overlap between the two general treatments. That is, there is about $34.2\\%$ of the patients who display measurable effects to both treatments. Some patients react positively to only one of the treatments while other pasients, about $26\\%$ don't react positively to either treatment. This information is summeraized by the following venn diagram. \n",
    "![Venn](Venn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do the same analysis that we did above with treatment 1 and the gene specific treatments we get some interesting results. From the printout below we see that we never observe an instance where only the gene specific treatment works. If it worked, then the general treatment 1 also worked. So, we are always better of by only recommending the placebo, treatment1 or treatment2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          #med1  #med2 #justmed1 #justmed2 #both  #none\n",
      "Med1 = 1 and med2 =   0:  26766    579     26187         0   579  23234\n",
      "Med1 = 1 and med2 =   1:  26766  26766         0         0 26766  23234\n",
      "Med1 = 1 and med2 =   2:  26766  27305      9677     10216 17089  13018\n",
      "Med1 = 1 and med2 =   3:  26766    365     26401         0   365  23234\n",
      "Med1 = 1 and med2 =   4:  26766    774     25992         0   774  23234\n",
      "Med1 = 1 and med2 =   5:  26766    458     26308         0   458  23234\n",
      "Med1 = 1 and med2 =   6:  26766    889     25877         0   889  23234\n",
      "Med1 = 1 and med2 =   7:  26766    832     25934         0   832  23234\n",
      "Med1 = 1 and med2 =   8:  26766    597     26169         0   597  23234\n",
      "Med1 = 1 and med2 =   9:  26766   1570     25196         0  1570  23234\n",
      "Med1 = 1 and med2 =  10:  26766    737     26029         0   737  23234\n",
      "Med1 = 1 and med2 =  11:  26766   1631     25135         0  1631  23234\n",
      "Med1 = 1 and med2 =  12:  26766    847     25919         0   847  23234\n",
      "Med1 = 1 and med2 =  13:  26766    724     26042         0   724  23234\n",
      "Med1 = 1 and med2 =  14:  26766    906     25860         0   906  23234\n",
      "Med1 = 1 and med2 =  15:  26766    772     25994         0   772  23234\n",
      "Med1 = 1 and med2 =  16:  26766    955     25811         0   955  23234\n",
      "Med1 = 1 and med2 =  17:  26766    655     26111         0   655  23234\n",
      "Med1 = 1 and med2 =  18:  26766    899     25867         0   899  23234\n",
      "Med1 = 1 and med2 =  19:  26766    747     26019         0   747  23234\n",
      "Med1 = 1 and med2 =  20:  26766    357     26409         0   357  23234\n",
      "Med1 = 1 and med2 =  21:  26766   1237     25529         0  1237  23234\n",
      "Med1 = 1 and med2 =  22:  26766    873     25893         0   873  23234\n",
      "Med1 = 1 and med2 =  23:  26766    566     26200         0   566  23234\n",
      "Med1 = 1 and med2 =  24:  26766    828     25938         0   828  23234\n",
      "Med1 = 1 and med2 =  25:  26766    783     25983         0   783  23234\n",
      "Med1 = 1 and med2 =  26:  26766   1761     25005         0  1761  23234\n",
      "Med1 = 1 and med2 =  27:  26766    475     26291         0   475  23234\n",
      "Med1 = 1 and med2 =  28:  26766   1629     25137         0  1629  23234\n",
      "Med1 = 1 and med2 =  29:  26766    446     26320         0   446  23234\n",
      "Med1 = 1 and med2 =  30:  26766    884     25882         0   884  23234\n",
      "Med1 = 1 and med2 =  31:  26766    843     25923         0   843  23234\n",
      "Med1 = 1 and med2 =  32:  26766    875     25891         0   875  23234\n",
      "Med1 = 1 and med2 =  33:  26766    817     25949         0   817  23234\n",
      "Med1 = 1 and med2 =  34:  26766    756     26010         0   756  23234\n",
      "Med1 = 1 and med2 =  35:  26766    738     26028         0   738  23234\n",
      "Med1 = 1 and med2 =  36:  26766    684     26082         0   684  23234\n",
      "Med1 = 1 and med2 =  37:  26766    769     25997         0   769  23234\n",
      "Med1 = 1 and med2 =  38:  26766    683     26083         0   683  23234\n",
      "Med1 = 1 and med2 =  39:  26766    520     26246         0   520  23234\n",
      "Med1 = 1 and med2 =  40:  26766    790     25976         0   790  23234\n",
      "Med1 = 1 and med2 =  41:  26766    814     25952         0   814  23234\n",
      "Med1 = 1 and med2 =  42:  26766    589     26177         0   589  23234\n",
      "Med1 = 1 and med2 =  43:  26766    627     26139         0   627  23234\n",
      "Med1 = 1 and med2 =  44:  26766    676     26090         0   676  23234\n",
      "Med1 = 1 and med2 =  45:  26766    856     25910         0   856  23234\n",
      "Med1 = 1 and med2 =  46:  26766    851     25915         0   851  23234\n",
      "Med1 = 1 and med2 =  47:  26766    616     26150         0   616  23234\n",
      "Med1 = 1 and med2 =  48:  26766    473     26293         0   473  23234\n",
      "Med1 = 1 and med2 =  49:  26766   1091     25675         0  1091  23234\n",
      "Med1 = 1 and med2 =  50:  26766    775     25991         0   775  23234\n",
      "Med1 = 1 and med2 =  51:  26766    874     25892         0   874  23234\n",
      "Med1 = 1 and med2 =  52:  26766    255     26511         0   255  23234\n",
      "Med1 = 1 and med2 =  53:  26766   1135     25631         0  1135  23234\n",
      "Med1 = 1 and med2 =  54:  26766    712     26054         0   712  23234\n",
      "Med1 = 1 and med2 =  55:  26766    719     26047         0   719  23234\n",
      "Med1 = 1 and med2 =  56:  26766    549     26217         0   549  23234\n",
      "Med1 = 1 and med2 =  57:  26766    602     26164         0   602  23234\n",
      "Med1 = 1 and med2 =  58:  26766    726     26040         0   726  23234\n",
      "Med1 = 1 and med2 =  59:  26766    619     26147         0   619  23234\n",
      "Med1 = 1 and med2 =  60:  26766    682     26084         0   682  23234\n",
      "Med1 = 1 and med2 =  61:  26766    819     25947         0   819  23234\n",
      "Med1 = 1 and med2 =  62:  26766    745     26021         0   745  23234\n",
      "Med1 = 1 and med2 =  63:  26766    863     25903         0   863  23234\n",
      "Med1 = 1 and med2 =  64:  26766   1238     25528         0  1238  23234\n",
      "Med1 = 1 and med2 =  65:  26766    823     25943         0   823  23234\n",
      "Med1 = 1 and med2 =  66:  26766    818     25948         0   818  23234\n",
      "Med1 = 1 and med2 =  67:  26766    542     26224         0   542  23234\n",
      "Med1 = 1 and med2 =  68:  26766    905     25861         0   905  23234\n",
      "Med1 = 1 and med2 =  69:  26766    642     26124         0   642  23234\n",
      "Med1 = 1 and med2 =  70:  26766    659     26107         0   659  23234\n",
      "Med1 = 1 and med2 =  71:  26766    628     26138         0   628  23234\n",
      "Med1 = 1 and med2 =  72:  26766    733     26033         0   733  23234\n",
      "Med1 = 1 and med2 =  73:  26766    718     26048         0   718  23234\n",
      "Med1 = 1 and med2 =  74:  26766    924     25842         0   924  23234\n",
      "Med1 = 1 and med2 =  75:  26766   1196     25570         0  1196  23234\n",
      "Med1 = 1 and med2 =  76:  26766    561     26205         0   561  23234\n",
      "Med1 = 1 and med2 =  77:  26766    642     26124         0   642  23234\n",
      "Med1 = 1 and med2 =  78:  26766    689     26077         0   689  23234\n",
      "Med1 = 1 and med2 =  79:  26766    948     25818         0   948  23234\n",
      "Med1 = 1 and med2 =  80:  26766    810     25956         0   810  23234\n",
      "Med1 = 1 and med2 =  81:  26766    839     25927         0   839  23234\n",
      "Med1 = 1 and med2 =  82:  26766    688     26078         0   688  23234\n",
      "Med1 = 1 and med2 =  83:  26766    669     26097         0   669  23234\n",
      "Med1 = 1 and med2 =  84:  26766    646     26120         0   646  23234\n",
      "Med1 = 1 and med2 =  85:  26766    507     26259         0   507  23234\n",
      "Med1 = 1 and med2 =  86:  26766   2985     23781         0  2985  23234\n",
      "Med1 = 1 and med2 =  87:  26766    767     25999         0   767  23234\n",
      "Med1 = 1 and med2 =  88:  26766    757     26009         0   757  23234\n",
      "Med1 = 1 and med2 =  89:  26766    953     25813         0   953  23234\n",
      "Med1 = 1 and med2 =  90:  26766    736     26030         0   736  23234\n",
      "Med1 = 1 and med2 =  91:  26766    743     26023         0   743  23234\n",
      "Med1 = 1 and med2 =  92:  26766   1380     25386         0  1380  23234\n",
      "Med1 = 1 and med2 =  93:  26766    693     26073         0   693  23234\n",
      "Med1 = 1 and med2 =  94:  26766   1058     25708         0  1058  23234\n",
      "Med1 = 1 and med2 =  95:  26766    695     26071         0   695  23234\n",
      "Med1 = 1 and med2 =  96:  26766    955     25811         0   955  23234\n",
      "Med1 = 1 and med2 =  97:  26766    958     25808         0   958  23234\n",
      "Med1 = 1 and med2 =  98:  26766    570     26196         0   570  23234\n",
      "Med1 = 1 and med2 =  99:  26766    705     26061         0   705  23234\n",
      "Med1 = 1 and med2 = 100:  26766   1323     25443         0  1323  23234\n",
      "Med1 = 1 and med2 = 101:  26766    562     26204         0   562  23234\n",
      "Med1 = 1 and med2 = 102:  26766    344     26422         0   344  23234\n",
      "Med1 = 1 and med2 = 103:  26766   1135     25631         0  1135  23234\n",
      "Med1 = 1 and med2 = 104:  26766    652     26114         0   652  23234\n",
      "Med1 = 1 and med2 = 105:  26766    524     26242         0   524  23234\n",
      "Med1 = 1 and med2 = 106:  26766   1100     25666         0  1100  23234\n",
      "Med1 = 1 and med2 = 107:  26766    969     25797         0   969  23234\n",
      "Med1 = 1 and med2 = 108:  26766    361     26405         0   361  23234\n",
      "Med1 = 1 and med2 = 109:  26766    663     26103         0   663  23234\n",
      "Med1 = 1 and med2 = 110:  26766    795     25971         0   795  23234\n",
      "Med1 = 1 and med2 = 111:  26766   1232     25534         0  1232  23234\n",
      "Med1 = 1 and med2 = 112:  26766    714     26052         0   714  23234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Med1 = 1 and med2 = 113:  26766    592     26174         0   592  23234\n",
      "Med1 = 1 and med2 = 114:  26766    836     25930         0   836  23234\n",
      "Med1 = 1 and med2 = 115:  26766   1019     25747         0  1019  23234\n",
      "Med1 = 1 and med2 = 116:  26766    639     26127         0   639  23234\n",
      "Med1 = 1 and med2 = 117:  26766    782     25984         0   782  23234\n",
      "Med1 = 1 and med2 = 118:  26766    718     26048         0   718  23234\n",
      "Med1 = 1 and med2 = 119:  26766    735     26031         0   735  23234\n",
      "Med1 = 1 and med2 = 120:  26766    667     26099         0   667  23234\n",
      "Med1 = 1 and med2 = 121:  26766    240     26526         0   240  23234\n",
      "Med1 = 1 and med2 = 122:  26766    896     25870         0   896  23234\n",
      "Med1 = 1 and med2 = 123:  26766    782     25984         0   782  23234\n",
      "Med1 = 1 and med2 = 124:  26766    625     26141         0   625  23234\n",
      "Med1 = 1 and med2 = 125:  26766    675     26091         0   675  23234\n",
      "Med1 = 1 and med2 = 126:  26766    917     25849         0   917  23234\n",
      "Med1 = 1 and med2 = 127:  26766   4294     22472         0  4294  23234\n",
      "Med1 = 1 and med2 = 128:  26766    787     25979         0   787  23234\n"
     ]
    }
   ],
   "source": [
    "print(\"                          #med1  #med2 #justmed1 #justmed2 #both  #none\")\n",
    "for i in range(129):\n",
    "    compareTwoMedicines(1, i, 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now for a second assume that the gene specific treatments only target a single gene, and more precisely, that treatment 3 correspond to gene 1, treatment 4 correspond to gene 4 and so on. This might be a far fetched assumption, but it's the way we have interpreted the exercise. Then we can conduct a similar calculation as above and look at the proportions of the different genes. That is, for each patient we record wether the treatment was a success or not, and in either case we also record the value of the specific gene. We do this for 10 000 patients. From these calulations we get empirical estimates for the 1) probabilities that a given treatment is a success given the value of the genes, 2) the probabilities for a gene taking on a specific value given that the treatment was a success and 3) general success rates and failure rates. Below you see the code and the final table of the 20 \"best\" treatments, under the assumption that we always recommend it no mater the features and that we can give mutiple treatments to the same people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy2(generator, policy, reward_function, T):\n",
    "    policy.set_reward(reward_function)\n",
    "    # Set seed for reproducibility\n",
    "    seed_number = 333213\n",
    "    # Utility\n",
    "    u = 0\n",
    "    # varaible to count\n",
    "    number_treated_gen0 = 0\n",
    "    number_treated_gen1 = 0\n",
    "    number_failed_gen0  = 0\n",
    "    number_failed_gen1  = 0\n",
    "    \n",
    "    for t in range(T):\n",
    "        # For reproducibility and to analyse the same patients every time the code is called\n",
    "        np.random.seed(seed_number + t)\n",
    "        # We generate 1 new pasient\n",
    "        x = generator.generate_features()\n",
    "        # Fixed model, always give a fixed number\n",
    "        a = policy.recommend(x)\n",
    "        # Generate the outcome based on user_data and action\n",
    "        y = generator.generate_outcome(x, a)\n",
    "        # Add the utility/reward\n",
    "        u += reward_function(a, y)\n",
    "        \n",
    "        # From the feedback after the presentation you said we should look at the proportions of gene0 and gene1 for the \n",
    "        # general treatments. Since they do not correspond to a single gen we assume that your note was reagarding the fact \n",
    "        # that we highlightet treatment 127/gene 125 and hence that we should look at these proportions.\n",
    "        # We can do this by just changing the a value here and use the same code as before:\n",
    "        if (a in [0,1,2]): \n",
    "            a = 127\n",
    "        \n",
    "        # If success or failure count the genes\n",
    "        if(y == 1): \n",
    "            if (x[a] == 0):\n",
    "                number_treated_gen0 += 1\n",
    "            if (x[a] == 1):\n",
    "                number_treated_gen1 += 1\n",
    "        else:\n",
    "            if (x[a] == 0):\n",
    "                number_failed_gen0 += 1\n",
    "            if (x[a] == 1):\n",
    "                number_failed_gen1 += 1\n",
    "                \n",
    "        \n",
    "    return [u/T, number_treated_gen0, number_treated_gen1, number_failed_gen0, number_failed_gen1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment  Utility  Total success: %gen0   %gen1   Total fail: %gen0   %gen1    Successrate given gen0/gen1\n",
      "        2    0.444        5443     0.305   0.695        4557    0.548   0.452    0.400  0.647 (ratios of gene 125)\n",
      "        1    0.434        5341     0.457   0.543        4659    0.368   0.632    0.588  0.496 (ratios of gene 125)\n",
      "        0    0.014         140     0.564   0.436        9860    0.414   0.586    0.019  0.010 (ratios of gene 125)\n",
      "      127   -0.009         906     0.091   0.909        9094    0.448   0.552    0.020  0.141 \n",
      "       86   -0.040         603     0.221   0.779        9397    0.531   0.469    0.026  0.096 \n",
      "       28   -0.062         380     0.463   0.537        9620    0.493   0.507    0.036  0.040 \n",
      "       26   -0.063         368     0.139   0.861        9632    0.517   0.483    0.010  0.064 \n",
      "       11   -0.065         354     0.136   0.864        9646    0.516   0.484    0.010  0.062 \n",
      "        9   -0.067         334     0.266   0.734        9666    0.512   0.488    0.018  0.049 \n",
      "       92   -0.069         315     0.441   0.559        9685    0.503   0.497    0.028  0.035 \n",
      "       64   -0.072         282     0.273   0.727        9718    0.509   0.491    0.015  0.041 \n",
      "      111   -0.072         280     0.357   0.643        9720    0.496   0.504    0.020  0.035 \n",
      "      100   -0.072         279     0.276   0.724        9721    0.508   0.492    0.015  0.040 \n",
      "       21   -0.073         271     0.321   0.679        9729    0.504   0.496    0.017  0.037 \n",
      "       75   -0.074         260     0.512   0.488        9740    0.497   0.503    0.027  0.025 \n",
      "      103   -0.075         253     0.577   0.423        9747    0.501   0.499    0.029  0.022 \n",
      "       53   -0.075         249     0.739   0.261        9751    0.502   0.498    0.036  0.013 \n",
      "      106   -0.076         243     0.403   0.597        9757    0.498   0.502    0.020  0.029 \n",
      "       49   -0.076         237     0.764   0.236        9763    0.497   0.503    0.036  0.011 \n",
      "       94   -0.077         227     0.577   0.423        9773    0.495   0.505    0.026  0.019 \n"
     ]
    }
   ],
   "source": [
    "import FixedTreatmentRecommender\n",
    "\n",
    "# matrix to store the results for the 129 medicines\n",
    "results_fixed_treatment = np.zeros((generator.get_n_actions(), 5))\n",
    "\n",
    "# Number of patients\n",
    "T = 10000\n",
    "\n",
    "# Run each model\n",
    "for i in range(len(results_fixed_treatment)):\n",
    "    policy_temp = FixedTreatmentRecommender.FixedTreatmentRecommender(generator.get_n_actions(), generator.get_n_outcomes(), i)\n",
    "    results_fixed_treatment[i] = test_policy2(generator, policy_temp, reward_function, T)\n",
    "\n",
    "\n",
    "# Let's only look at the k best gene treatments\n",
    "k = 20\n",
    "best_indices = np.argsort(-results_fixed_treatment[:,0])[:k]\n",
    "\n",
    "print(\"Treatment  Utility  Total success: %gen0   %gen1   Total fail: %gen0   %gen1    Successrate given gen0/gen1\")\n",
    "for i in best_indices:\n",
    "    util = results_fixed_treatment[i,0]\n",
    "    suc0 = results_fixed_treatment[i,1]\n",
    "    suc1 = results_fixed_treatment[i,2]\n",
    "    fail0 = results_fixed_treatment[i,3]\n",
    "    fail1 = results_fixed_treatment[i,4]\n",
    "    tot_suc = suc0 + suc1\n",
    "    tot_fail = fail0 + fail1\n",
    "    tot = tot_suc + tot_fail\n",
    "    percentage_suc0 = suc0 / tot_suc\n",
    "    percentage_suc1 = suc1 / tot_suc\n",
    "    percentage_fail0 = fail0 / tot_fail\n",
    "    percentage_fail1 = fail1 / tot_fail\n",
    "    percentage_0_succ = suc0/(suc0+fail0)\n",
    "    percentage_1_succ = suc1/(suc1+fail1)\n",
    "    if (i in [0,1,2]):\n",
    "        print(\"%9d  %7.3f        %4d     %4.3f   %4.3f        %3d  %7.3f  %6.3f   %6.3f %6.3f (ratios of gene 125)\" % (i, util, tot_suc, percentage_suc0, percentage_suc1, tot_fail, percentage_fail0, percentage_fail1,  percentage_0_succ, percentage_1_succ))\n",
    "    else:\n",
    "        print(\"%9d  %7.3f        %4d     %4.3f   %4.3f        %3d  %7.3f  %6.3f   %6.3f %6.3f \" % (i, util, tot_suc, percentage_suc0, percentage_suc1, tot_fail, percentage_fail0, percentage_fail1,  percentage_0_succ, percentage_1_succ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in our presentation we want to highlight treatment 127, corresponding to gene 125. If we know the treatment was a success, then we can with a high probability, more precise $91\\%$, assume that the value of gene 125 was 1. However, this doesn't mean that we should give treatment 127 to a pasient with the value of gene 125 being 1, since the successrate is only $14.1\\%$, while the successrates for the general treatments are much higher. \n",
    "Note that the table display the successrates of the general treatment given gene 125 and they are both better independently of the value of gene 125. These values are only comparable with treatment 127. From them we see that there is a higher successrate for treatment 1 if gene 125 is 0, while the successrate of treatment 2 is higher if the gene has a value of 1.\n",
    "\n",
    "This whole analysis has been a huge digression, but that is something we did after we made some models which became worse when we introduced the new treatments. We had initaially assumed that our results would become better with the new treatments, which we have concluded is wrong. Hence when we do an exploration later on, we are losing potential utility which we are not able to re-earn. Once again, we highlight this, since we have the generator file we can look at it. If we let the $\\texttt{OptimalRecommender}$ recommend between action zero to two or zero to 129, we obtain the same results. Again, this is not possible in the real world, but since we are working in a sandbox scenario we wanted to make a note of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal (129 treatments): \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.632655 0.6624   0.693945]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.70295 0.736   0.77105]\n",
      "Optimal (3 treatments): \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.632655 0.6624   0.693945]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.70295 0.736   0.77105]\n"
     ]
    }
   ],
   "source": [
    "T = 500\n",
    "N = 100\n",
    "\n",
    "print(\"Optimal (129 treatments): \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = generator.get_n_actions())\n",
    "print(\"Optimal (3 treatments): \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's forget this for a moment and rather illustrate how we obtained the results we presentated at the seminar, table 2. That is, where we let the the improved polcies take on values zero, one and two. Let's start by looking at the neural network. Initialy we thought we had to manually force it to explore the second treatment, but after some simulations we figured out that we actually obtained the best results by not forcing the neural network to recommend the second general treatment. Why this is, we are not certain of. Maybe NN are exporationary by nature or we might just been lucky. Either way, the new policy recommend treatments much more often than before and obtain a median utility of 0.622 which is pretty close to the optimal value of 0.666. \n",
    "The NN recommends the action, among the three, that maximizes the estimated reward of the patient.\n",
    "\n",
    "Our results with the logistic model did not work as we had intended. It uses the same idea as above to choose it recommendations, but it ends up always chosing the second treatment. We do not think there is an error in the code, but it is strange that the confidence intervals have zero width. Under the assumption that our code is correct is that the model is too optimistic on the effect of the treatment and that the coefficient corresponding to the action variable is positive, hence it chooses the second action. \n",
    "\n",
    "In the presentation we highlighted this issue and presented a possible solution, which would be to use dummy variables for the action. Your feedback was that that might work, but you recommended us to have a seperate model for each action. We have looked into this and will presentate our findings later in the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not reccommend to run this chunk. It is computationally heavy and takes a long time to run.\n",
    "# We ran it in the terminal, since it is faster.\n",
    "T = 100\n",
    "N = 100\n",
    "\n",
    "# Optimal recommender\n",
    "import OptimalRecommender\n",
    "policy_factory_optimal = OptimalRecommender.OptimalRecommender\n",
    "\n",
    "# Single logistic\n",
    "import LogisticRecommender2Actions\n",
    "policy_factory_logistic = LogisticRecommender2Actions.LogisticRecommender2Actions\n",
    "\n",
    "# Nerural network\n",
    "import NeuralNetworkRecommender2Actions\n",
    "policy_factory_NN = NeuralNetworkRecommender2Actions.NeuralNetworkRecommender2Actions\n",
    "\n",
    "print(\"Optimal: \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = 2)\n",
    "\n",
    "print(\"Single logistic model: \")\n",
    "create_CI(generator, policy_factory_logistic, reward_function, T, N, features, actions, outcome, extra = 1)\n",
    "\n",
    "print(\"NN(5,2): \")\n",
    "create_CI(generator, policy_factory_NN, reward_function, T, N, features, actions, outcome, extra = [1, [5,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Table2.png)\n",
    "![title](Table3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The new version of logistic based on presentation feedback:\n",
    "\n",
    "We start by looking at the version of the logistic model. Here we only look at the three first actions. Note that only action 2 is unknown. Hence we force or model to explore this choice 20 times. This number should propably been decided dynamically by some method, but we lack time to do the analysis. After the first 20 patients it recommends the action with highest estimated utility. Note that the recommender now have 3 models. In the first model all the actions are 0, in the second they are 1 and in the last one we only have action 2. We did not have time to run the $\\texttt{create_CI}$, so we simply ran the code with 2000 patients and looked at the utility. Since we treated so many pasients we hope that the utility has converged. From the printouts that looks to be a reasonable assumption. One should note that the recommender is still too optimistic and prescribe the treatment too often. However, it accheive the best mean utility we have observed this far.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    0 \t Current mean reward:  0.9000\n",
      "Iteration:  100 \t Current mean reward:  0.5931\n",
      "Iteration:  200 \t Current mean reward:  0.6413\n",
      "Iteration:  300 \t Current mean reward:  0.6276\n",
      "Iteration:  400 \t Current mean reward:  0.6357\n",
      "Iteration:  500 \t Current mean reward:  0.6305\n",
      "Iteration:  600 \t Current mean reward:  0.6354\n",
      "Iteration:  700 \t Current mean reward:  0.6389\n",
      "Iteration:  800 \t Current mean reward:  0.6441\n",
      "Iteration:  900 \t Current mean reward:  0.6425\n",
      "Iteration: 1000 \t Current mean reward:  0.6473\n",
      "Iteration: 1100 \t Current mean reward:  0.6493\n",
      "Iteration: 1200 \t Current mean reward:  0.6510\n",
      "Iteration: 1300 \t Current mean reward:  0.6487\n",
      "Iteration: 1400 \t Current mean reward:  0.6545\n",
      "Iteration: 1500 \t Current mean reward:  0.6602\n",
      "Iteration: 1600 \t Current mean reward:  0.6633\n",
      "Iteration: 1700 \t Current mean reward:  0.6590\n",
      "Iteration: 1800 \t Current mean reward:  0.6562\n",
      "Iteration: 1900 \t Current mean reward:  0.6564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6565000000000086, 2000]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import LogisticRecommender2Tips\n",
    "T = 2000\n",
    "\n",
    "policy_factory_tips = LogisticRecommender2Tips.LogisticRecommender2Tips\n",
    "policy_logistic_tips = policy_factory_tips(generator.get_n_actions(), generator.get_n_outcomes(), force_alt_med = 20, force_action=2)\n",
    "policy_logistic_tips.set_reward(reward_function)\n",
    "policy_logistic_tips.fit_treatment_outcome(features, actions, outcome)\n",
    "test_policy(generator, policy_logistic_tips, reward_function, T, 1334, printout = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried to generalize this method to the case with 129 treatments. However, we got stuck. Since we use a logistic model we need a training set which contains instances of both outcomes, for most of the treatments we did not acchieve this even when we forced the recommender to recommend each treatment 20 times. Then we though we could remove the treatments which yielded no sucess after 20 patients. However, we ran into some coding issues and had no time to solve the bugs. We think this could have given some good results. Instead we choose to explore the 129 treatments based on a method we looked at in class, Thompson sampling, which yielded acceptable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thompson sampling\n",
    "In class we devoled the $\\texttt{thompson_bandit}$. It has a beta prior for each of the 129 treatments. The first two treatments we know quite a lot about, we could have found empirical parameters for the beta prior by momentmatching (set the analytic and the historical moments to be identical), but we have chosen parameters which creates the prior we ought to have. The prior for the placebo has the majority of it's weight located close to 0 while the first treatment has a more evenly distributed weight with the mode at 0.5. For the other treatments we do not know anything, hence we chose a uniform dsitribution for them. These priors will be washed away by the data. \n",
    "For each patient we draw a random value from the distributions for each of the treatments and recommend the treatment with the maximum value. From the printout below we see that the recommender first tries out the different treatments and learn from this. After some time it will figure out which treatments are the best and always go for this or these. If there is a treatment superior then it will always chose that one, but in this case both action 1 and action 2 are almost equally good(from earlier analysis), so we will recommend a mixture of them over time. This is because of the randomness by drawing a random point from the distributions.  \n",
    "We see that the utility converges to around 0.443. This is as expected. From earlier analysis we showed that treatment 1 and treatment 2 was effective in about 54% of the cases. If we also include the -0.1 penalty in the utility function we end up with the utility that we see here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thompson 20 000:\n",
      "Iteration:      0 \t Current mean reward: -0.1000\n",
      "Iteration:   1000 \t Current mean reward:  0.0086\n",
      "Iteration:   2000 \t Current mean reward:  0.1594\n",
      "Iteration:   3000 \t Current mean reward:  0.2469\n",
      "Iteration:   4000 \t Current mean reward:  0.2940\n",
      "Iteration:   5000 \t Current mean reward:  0.3192\n",
      "Iteration:   6000 \t Current mean reward:  0.3426\n",
      "Iteration:   7000 \t Current mean reward:  0.3575\n",
      "Iteration:   8000 \t Current mean reward:  0.3695\n",
      "Iteration:   9000 \t Current mean reward:  0.3775\n",
      "Iteration:  10000 \t Current mean reward:  0.3827\n",
      "Iteration:  11000 \t Current mean reward:  0.3863\n",
      "Iteration:  12000 \t Current mean reward:  0.3895\n",
      "Iteration:  13000 \t Current mean reward:  0.3935\n",
      "Iteration:  14000 \t Current mean reward:  0.3968\n",
      "Iteration:  15000 \t Current mean reward:  0.3995\n",
      "Iteration:  16000 \t Current mean reward:  0.4007\n",
      "Iteration:  17000 \t Current mean reward:  0.4034\n",
      "Iteration:  18000 \t Current mean reward:  0.4057\n",
      "Iteration:  19000 \t Current mean reward:  0.4071\n",
      "10 most used treatments:\n",
      "Treatment:      2     1     0    45     4     7    97    65    66    32\n",
      "Times used: 14994  3740    15    15    15    15    15    14    14    14\n",
      "\n",
      "Thompson 200 000:\n",
      "Iteration:      0 \t Current mean reward: -0.1000\n",
      "Iteration:  10000 \t Current mean reward:  0.3827\n",
      "Iteration:  20000 \t Current mean reward:  0.4095\n",
      "Iteration:  30000 \t Current mean reward:  0.4182\n",
      "Iteration:  40000 \t Current mean reward:  0.4241\n",
      "Iteration:  50000 \t Current mean reward:  0.4283\n",
      "Iteration:  60000 \t Current mean reward:  0.4317\n",
      "Iteration:  70000 \t Current mean reward:  0.4347\n",
      "Iteration:  80000 \t Current mean reward:  0.4356\n",
      "Iteration:  90000 \t Current mean reward:  0.4369\n",
      "Iteration: 100000 \t Current mean reward:  0.4388\n",
      "Iteration: 110000 \t Current mean reward:  0.4397\n",
      "Iteration: 120000 \t Current mean reward:  0.4407\n",
      "Iteration: 130000 \t Current mean reward:  0.4411\n",
      "Iteration: 140000 \t Current mean reward:  0.4414\n",
      "Iteration: 150000 \t Current mean reward:  0.4417\n",
      "Iteration: 160000 \t Current mean reward:  0.4416\n",
      "Iteration: 170000 \t Current mean reward:  0.4420\n",
      "Iteration: 180000 \t Current mean reward:  0.4426\n",
      "Iteration: 190000 \t Current mean reward:  0.4430\n",
      "10 most used treatments:\n",
      "Treatment:       2      1     0   119   111    75    66    98    97    92\n",
      "Times used:  14994   3740    15    13    13    14    14    13    15    13\n",
      "\n",
      "Thompson  (20 000): utility = 0.409575\n",
      "Thompson (200 000): utility = 0.443400\n"
     ]
    }
   ],
   "source": [
    "T = 20000\n",
    "import thompson_bandit\n",
    "\n",
    "n_actions = 129\n",
    "n_outcomes = 2\n",
    "prior_a = [2,2] + [1]*127\n",
    "prior_b = [5,2] + [1]*127\n",
    "thompson_policy = thompson_bandit.ThompsonBandit(129, 2, prior_a, prior_b)\n",
    "print(\"Thompson 20 000:\")\n",
    "thompson_result1 = test_policy(generator, thompson_policy, reward_function, T, 100, True, 1000, True)\n",
    "\n",
    "print(\"10 most used treatments:\")\n",
    "b = np.argsort(-thompson_result1[2])[:10]\n",
    "print(\"Treatment:  %5d %5d %5d %5d %5d %5d %5d %5d %5d %5d\" % (b[0], b[1], b[2], b[3], b[4], b[5], b[6], b[7], b[8], b[9]))\n",
    "r = thompson_result1[2][b]\n",
    "print(\"Times used: %5d %5d %5d %5d %5d %5d %5d %5d %5d %5d\" % (r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[7], r[8], r[9]))\n",
    "\n",
    "\n",
    "T = 200000\n",
    "print(\"\\nThompson 200 000:\")\n",
    "thompson_policy = thompson_bandit.ThompsonBandit(129, 2, prior_a, prior_b)\n",
    "thompson_result2 = test_policy(generator, thompson_policy, reward_function, T, 100, True, 10000, True)\n",
    "print(\"10 most used treatments:\")\n",
    "b = np.argsort(-thompson_result2[2])[:10]\n",
    "print(\"Treatment:  %6d %6d %5d %5d %5d %5d %5d %5d %5d %5d\" % (b[0], b[1], b[2], b[3], b[4], b[5], b[6], b[7], b[8], b[9]))\n",
    "r = thompson_result1[2][b]\n",
    "print(\"Times used: %6d %6d %5d %5d %5d %5d %5d %5d %5d %5d\" % (r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[7], r[8], r[9]))\n",
    "\n",
    "\n",
    "print(\"\\nThompson  (20 000): utility = %f\" %thompson_result1[0])\n",
    "print(\"Thompson (200 000): utility = %f\" %thompson_result2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A small discussion on Privacy and Fairness\n",
    "\n",
    "As statisticians we have to remember that data we are working on often origins from human beings and that our conclusions can effect their lives. It is therefor important to adress certain concepts such as privacy and fairness. The former is related to the fact that the data can be e.g. stolen by an adversary. This might be an insurance company which are able to identify you based on database merging and from this they might increase the insurence due to some specefic genes, hypotetically. We do not want this to happen. We might solve this by adding noise to the features. Since we are dealing with binary data this correspond to flip some of the values. However, this might also make it harder for us to give the right treatments. Say that we have a treatment that always work if the pacients have a set of genes, but it is lethal if you don't have the right genes (extremmly hypotetically case). In this scenario we have to be sure about the genes, but if the data has noise we cannot use this medicine on the patient without risking his/hers life. \n",
    "\n",
    "One should also adress fairness. That is that our recommender doesn't discriminate based on gender, ethnectiy, ect. In this dataset the only potential disciminative featuers are the features regarding gender and whether or not the patient smoke. In this project we are in a different setting than in the previous project and it might be a good ting to seperate based on gender. Say that treatment 1 is more effective on female while treatment 2 is more effective on men, then we would like to know the gender on the patient. However, if we are in the first setting were males more often are given placebo then women, then this might be a issue. \n",
    "\n",
    "We have not done any analysis on our models in this project, since we did it in the previous one, but we wanted to adress it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
