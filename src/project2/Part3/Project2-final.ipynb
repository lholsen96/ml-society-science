{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Project\n",
    "\n",
    "### Lars Olsen and Oda Kristensen\n",
    "\n",
    "\n",
    "## Part One - Historical Data\n",
    "In this project we are given we are given a dataset of 10 000 patients. For each patient $\\textit{t}$ we can see their attribute $x_t = \\{x_{t,1},x_{t,2},\\dots, x_{t,130}\\}$, where $x_{t,1}$ represents the gender, $x_{t,2}$ represents the whether or not the pasient smoke, $\\{x_{t,3},\\dots,x_{t,128}\\}$ represents the patient's genes and $\\{x_{t,129},x_{t,130}\\}$ represents the sympotms the patient displays. Note the all the varaibles are binary, that is $x_{t, \\cdot } \\in \\{ 0,1\\}$. We are also given the historical action $a_t \\in \\{ 0,1\\}$ which represents wheter the pasient was given a placebo or a treatment, respectively. Finally, we are given the historical outcome $y_t\\in \\{ 0,1\\}$, whether the passient displayed measurable effects after the treatment. Note that later in the project, part 3, we will expand the action varaible to take on values between 0 and 129, that is, $a_t \\in \\{ 0,1,2,\\dots,129\\}$. Where action 2 represents a new general treatment while the rempaing treatments are gene specific treatments. I.e. they are more effective against only a small porportion of the patients.\n",
    "\n",
    "Throughout this project we want to find a policy that maximizes the utility, given by the mean of the rewards. \n",
    "$$\\text{Utility} = \\frac{1}{T}\\sum_t^T r_t = \\frac{1}{T}\\sum_t^T (-0.1a_t + y_t).$$\n",
    "\n",
    "The reward function implies that there is a small penalty associated with the use of a treatment. Thus, the policy should be somewhat certain that a treatment will yield a positive result before recommending it. If we omit this term, all our models recommend the treatment 100% of the time, since the estimated reward of the treatment is higher than the placebo, as we will come back to soon. This penealty can reflect the cost of a treatment. Say that treatment 1 is cheaper than treatment 2, but the second treatment is better. Then we should use the cheap one when we think that it suffices. When we do not think it is adequate we will use the second treatment.\n",
    "\n",
    "Later, when we introduce the new actions we let the penalty be the same for all treatments. That is, we do not use the value of $a_t$, but apply the penealty of $-0.1$ if we use a treatment. It is not realistic that all the treatments have the same cost, but if we use the action above we get that $a_t = 100$ will yield a reward of $-10$ or $-9$ depending on the outcome. Since we want to maximize the utility we will never end up using the actions correnspong to a high $a_t$. We did not want to make up random cost for each drug, hence we choose a fixed cost for all the treatments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing some packages and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns, numpy as np\n",
    "from scipy.stats import norm\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('historical_X.dat', header=None, sep=\" \").values\n",
    "actions = pd.read_csv('historical_A.dat', header=None, sep=\" \").values\n",
    "outcome = pd.read_csv('historical_Y.dat', header=None, sep=\" \").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the project we are only interested in the features. The first 128 features are what we obsere; sex, smoker and 126 genes. The 2 last attributes are the symptoms and these can be taken to be akin to labels in supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = features[:, :128]\n",
    "labels = features[:,128] + features[:,129]*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the observations of the 1st pacient, sex = 0, and non smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide our data set into a traing set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_train, obs_test, lab_train, lab_test = train_test_split(observations, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of symptoms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3590.,    0.,    0., 3166.,    0.,    0.,  418.,    0.,    0.,\n",
       "         326.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lab_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take a look at the histogram of observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([3762.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3738.]),\n",
       "  array([5436.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         2064.]),\n",
       "  array([3709.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3791.]),\n",
       "  array([3688.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3812.]),\n",
       "  array([3725.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3775.]),\n",
       "  array([3744.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3756.]),\n",
       "  array([3803.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3697.]),\n",
       "  array([3759.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3741.]),\n",
       "  array([3797.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3703.]),\n",
       "  array([3786.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3714.]),\n",
       "  array([3712.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3788.]),\n",
       "  array([3795.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3705.]),\n",
       "  array([3740.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3760.]),\n",
       "  array([3731.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3769.]),\n",
       "  array([3689.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3811.]),\n",
       "  array([3738.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3762.]),\n",
       "  array([3771.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3729.]),\n",
       "  array([3704.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3796.]),\n",
       "  array([3775.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3725.]),\n",
       "  array([3762.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3738.]),\n",
       "  array([3748.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3752.]),\n",
       "  array([3844.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3656.]),\n",
       "  array([3829.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3671.]),\n",
       "  array([3719.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3781.]),\n",
       "  array([3749.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3751.]),\n",
       "  array([3758.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3742.]),\n",
       "  array([3820.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3680.]),\n",
       "  array([3783.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3717.]),\n",
       "  array([3736.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3764.]),\n",
       "  array([3809.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3691.]),\n",
       "  array([3722.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3778.]),\n",
       "  array([3720.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3780.]),\n",
       "  array([3721.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3779.]),\n",
       "  array([3728.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3772.]),\n",
       "  array([3731.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3769.]),\n",
       "  array([3771.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3729.]),\n",
       "  array([3727.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3773.]),\n",
       "  array([3766.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3734.]),\n",
       "  array([3735.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3765.]),\n",
       "  array([3746.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3754.]),\n",
       "  array([3779.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3721.]),\n",
       "  array([3737.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3763.]),\n",
       "  array([3796.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3704.]),\n",
       "  array([3749.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3751.]),\n",
       "  array([3726.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3774.]),\n",
       "  array([3734.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3766.]),\n",
       "  array([3706.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3794.]),\n",
       "  array([3753.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3747.]),\n",
       "  array([3632.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3868.]),\n",
       "  array([3779.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3721.]),\n",
       "  array([3701.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3799.]),\n",
       "  array([3788.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3712.]),\n",
       "  array([3799.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3701.]),\n",
       "  array([3777.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3723.]),\n",
       "  array([3756.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3744.]),\n",
       "  array([3785.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3715.]),\n",
       "  array([3721.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3779.]),\n",
       "  array([3783.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3717.]),\n",
       "  array([3724.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3776.]),\n",
       "  array([3748.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3752.]),\n",
       "  array([3759.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3741.]),\n",
       "  array([3781.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3719.]),\n",
       "  array([3786.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3714.]),\n",
       "  array([3779.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3721.]),\n",
       "  array([3839.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3661.]),\n",
       "  array([3810.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3690.]),\n",
       "  array([3753.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3747.]),\n",
       "  array([3700.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3800.]),\n",
       "  array([3795.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3705.]),\n",
       "  array([3756.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3744.]),\n",
       "  array([3729.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3771.]),\n",
       "  array([3737.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3763.]),\n",
       "  array([3720.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3780.]),\n",
       "  array([3757.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3743.]),\n",
       "  array([3688.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3812.]),\n",
       "  array([3735.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3765.]),\n",
       "  array([3668.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3832.]),\n",
       "  array([3734.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3766.]),\n",
       "  array([3715.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3785.]),\n",
       "  array([3773.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3727.]),\n",
       "  array([3660.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3840.]),\n",
       "  array([3805.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3695.]),\n",
       "  array([3755.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3745.]),\n",
       "  array([3726.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3774.]),\n",
       "  array([3775.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3725.]),\n",
       "  array([3668.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3832.]),\n",
       "  array([3762.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3738.]),\n",
       "  array([3746.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3754.]),\n",
       "  array([3687.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3813.]),\n",
       "  array([3706.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3794.]),\n",
       "  array([3724.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3776.]),\n",
       "  array([3711.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3789.]),\n",
       "  array([3728.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3772.]),\n",
       "  array([3731.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3769.]),\n",
       "  array([3743.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3757.]),\n",
       "  array([3629.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3871.]),\n",
       "  array([3785.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3715.]),\n",
       "  array([3723.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3777.]),\n",
       "  array([3719.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3781.]),\n",
       "  array([3769.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3731.]),\n",
       "  array([3727.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3773.]),\n",
       "  array([3746.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3754.]),\n",
       "  array([3696.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3804.]),\n",
       "  array([3815.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3685.]),\n",
       "  array([3746.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3754.]),\n",
       "  array([3709.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3791.]),\n",
       "  array([3702.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3798.]),\n",
       "  array([3736.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3764.]),\n",
       "  array([3724.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3776.]),\n",
       "  array([3768.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3732.]),\n",
       "  array([3786.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3714.]),\n",
       "  array([3699.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3801.]),\n",
       "  array([3703.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3797.]),\n",
       "  array([3703.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3797.]),\n",
       "  array([3824.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3676.]),\n",
       "  array([3695.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3805.]),\n",
       "  array([3705.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3795.]),\n",
       "  array([3754.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3746.]),\n",
       "  array([3759.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3741.]),\n",
       "  array([3776.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3724.]),\n",
       "  array([3749.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3751.]),\n",
       "  array([3802.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3698.]),\n",
       "  array([3741.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3759.]),\n",
       "  array([3743.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3757.]),\n",
       "  array([3770.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3730.]),\n",
       "  array([3718.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3782.]),\n",
       "  array([3744.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         3756.]),\n",
       "  array([3171.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         4329.])],\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 128 Lists of Patches objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(obs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We talked to Summaya Mumtaz in the lab and she said that from this plot we could se that there are two clusters. We are not sure how she did that. For us it just seems that each attribute takes either the value of zero or one, as we know they do from the definition of the data. If we look at only one attribute at the time we agreee that we have two clusters. Take $x_2$, either they smoke ($x_2=1$) or not ($x_2=0$), so we have to clusters. But when we have more dimensions I feel like we have more clusters. Say we look at the two first attributes. Then a person can be either male or female and the can smoke or not smoke, i.e. we have four potential combinations. Think of a square with a cluster in each corner. obviously it can be that there are no female smokers. Then we have three clusters. Then we can think of the clusters as being on a line. Male smokers are more similar to male non-smokers than female non-smokers, and male non-smokers are equally similar to both (assuming equal weighting of the attributes). So we have \"male smokers\" -- \"male non-smokers\" -- \"female non-smokers\". In a hypercube we would still have clusters in each corner, and this gives us $2^{128}$ potential clusters. This is an astronomical number. So we must assume that there is pattern in the data, which will lower this number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two histograms bellow we see that there are more people of the sex zero and more non-smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lars9\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28141cdcf28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(obs_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lars9\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28141992cc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(obs_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the proportions of smokers among sex 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lars9\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28143e2a710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(obs_train[1][obs_train[0] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the proportions of smokers among sex 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lars9\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x281431d3da0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(obs_train[1][obs_train[0] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a higher percentage of sex=0 that smoke than sex=1 that smoke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now take a look at the scores with Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1: Interia = 239535.284667   Score = -79854.425911   Elbow = 239535.284667\n",
      "k =  2: Interia = 217696.774049   Score = -72646.060011   Elbow = 108848.387024\n",
      "k =  3: Interia = 205758.149279   Score = -68926.579037   Elbow = 68586.049760\n",
      "k =  4: Interia = 197814.025944   Score = -66307.475261   Elbow = 49453.506486\n",
      "k =  5: Interia = 191592.603877   Score = -64231.594262   Elbow = 38318.520775\n",
      "k =  6: Interia = 186423.684485   Score = -62304.008934   Elbow = 31070.614081\n",
      "k =  7: Interia = 181982.207000   Score = -60967.342666   Elbow = 25997.458143\n",
      "k =  8: Interia = 178136.679937   Score = -59713.792270   Elbow = 22267.084992\n",
      "k =  9: Interia = 174866.422370   Score = -58809.068558   Elbow = 19429.602486\n",
      "k = 10: Interia = 172316.123149   Score = -58061.353930   Elbow = 17231.612315\n",
      "k = 11: Interia = 169863.354789   Score = -57229.266099   Elbow = 15442.123163\n",
      "k = 12: Interia = 167763.886097   Score = -56531.099477   Elbow = 13980.323841\n",
      "k = 13: Interia = 165695.515811   Score = -55934.267378   Elbow = 12745.808909\n",
      "k = 14: Interia = 163793.808688   Score = -55453.430997   Elbow = 11699.557763\n",
      "k = 15: Interia = 162157.509972   Score = -54787.140492   Elbow = 10810.500665\n",
      "k = 16: Interia = 160253.505504   Score = -54247.393727   Elbow = 10015.844094\n",
      "k = 17: Interia = 158782.411700   Score = -53885.217443   Elbow = 9340.141865\n",
      "k = 18: Interia = 157292.588374   Score = -53486.700257   Elbow = 8738.477132\n",
      "k = 19: Interia = 156017.978500   Score = -52908.069367   Elbow = 8211.472553\n",
      "k = 20: Interia = 154687.135074   Score = -52242.280611   Elbow = 7734.356754\n"
     ]
    }
   ],
   "source": [
    "elbows_score = np.zeros(21) \n",
    "for k in range(1,21):\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=1).fit(obs_train)\n",
    "    \n",
    "    # Sum of distances of samples to their closest cluster center.\n",
    "    inertia = kmeans_model.inertia_\n",
    "    \n",
    "    elbows_score[k] = interia/k\n",
    "    \n",
    "    print(\"k = %2d: Inertia = %f   Score = %f   Elbow = %f\" % (k,inertia,kmeans_model.score(obs_test), inertia/k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([i for i in range(1,21)])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, elbows_score[1:21])\n",
    "\n",
    "ax.set(xlabel='Index', ylabel='Elbow score',\n",
    "       title='Elbow method')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want this score as high as possible. The k with the best score is the k we should chose, i.e. the optimal number of clusters. The problem is that this score will keep incresing to zero when k increase. This is because score look at the distance from each point to the closest cluster centrum (for the test data, Ineteria does the same for the training data), and train and test set takes the same possible values this is a problem. Since then $2^{128}$ will (potentially) be the best k. Usually this score starts to level of, that the increase in absolute value decrese. So one can usually pick a resoanble K, but we are unsure where such a cap should be choosen here. Interia is much bigger due to the bigger dataset. One need to look at -score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say that K = 6 is a nice treeshold. We take a closer look at K = 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=6, random_state=1).fit(obs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-62687.212628782916"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.score(obs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people in cluster 0: 1274\n",
      "Number of people in cluster 1: 1131\n",
      "Number of people in cluster 2: 1369\n",
      "Number of people in cluster 3: 1385\n",
      "Number of people in cluster 4: 1128\n",
      "Number of people in cluster 5: 1213\n"
     ]
    }
   ],
   "source": [
    "for l in range(6):\n",
    "    print(\"Number of people in cluster %d: %d\" %(l,sum(kmeans_model.labels_ == l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the people are fairly divided between the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1: Score = -32.603439\n",
      "k =  2: Score = -27.188233\n",
      "k =  3: Score = -25.275091\n",
      "k =  4: Score = -24.016455\n",
      "k =  5: Score = -21.425464\n",
      "k =  6: Score = -18.076322\n",
      "k =  7: Score = -20.838692\n",
      "k =  8: Score = -18.565873\n",
      "k =  9: Score = -15.420511\n",
      "k = 10: Score = -18.877297\n",
      "k = 11: Score = -21.430816\n",
      "k = 12: Score = -19.669526\n",
      "k = 13: Score = -19.959870\n",
      "k = 14: Score = -16.383825\n",
      "k = 15: Score = -19.406439\n",
      "k = 16: Score = -19.771687\n",
      "k = 17: Score = -21.365973\n",
      "k = 18: Score = -21.447191\n",
      "k = 19: Score = -19.663103\n",
      "k = 20: Score = -22.821534\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,21):\n",
    "    gm_model = GaussianMixture(n_components=k, max_iter = 200, random_state=1).fit(obs_train)\n",
    "    \n",
    "    print(\"k = %2d: Score = %f\" % (k, gm_model.score(obs_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do the same as before but also take a look at the Bic score to find the optimal value. We have done this because of. http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html#sphx-glr-auto-examples-mixture-plot-gmm-selection-py It was wrong of us to look at BicTest. One should only look at BicTrain. The optimal value is 3. But, 2 is not far of. And since we know that is the truth we go for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1: ScoreTrain = -31.373   ScoreTest = -32.359   Bic = 545399.189   Aic = 487359.622\n",
      "k =  2: ScoreTrain = -24.810   ScoreTest = -26.926   Bic = 521777.915   Aic = 405691.858\n",
      "k =  3: ScoreTrain = -20.511   ScoreTest = -24.019   Bic = 532103.217   Aic = 357970.670\n",
      "k =  4: ScoreTrain = -17.173   ScoreTest = -22.056   Bic = 556844.621   Aic = 324665.584\n",
      "k =  5: ScoreTrain = -13.436   ScoreTest = -19.714   Bic = 575616.057   Aic = 285390.530\n",
      "k =  6: ScoreTrain = -12.238   ScoreTest = -20.020   Bic = 632465.142   Aic = 284193.125\n",
      "k =  7: ScoreTrain = -9.678   ScoreTest = -218.665   Bic = 668870.530   Aic = 262552.023\n",
      "k =  8: ScoreTrain = -7.701   ScoreTest = -217.959   Bic = 714044.179   Aic = 249679.183\n",
      "k =  9: ScoreTrain = -1.213   ScoreTest = -12.901   Bic = 691539.330   Aic = 169127.844\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,10):\n",
    "    gm_model = GaussianMixture(n_components=k, max_iter = 200, random_state=1).fit(obs_train)\n",
    "    bic = gm_model.bic(obs_train)\n",
    "    aic = gm_model.aic(obs_train)\n",
    "    print(\"k = %2d: ScoreTrain = %.3f   ScoreTest = %.3f   Bic = %.3f   Aic = %.3f\" % (k, gm_model.score(obs_train),gm_model.score(obs_test), bic, aic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the values above we see that k=13 is the best choice, but k=6 is not that far off, and since 6 is much lower we conclude that with Gaussian Mixture models the 'optimal' choice is 6 clusters. If we look at the score. But AIC and BIC is betther. Here we see that 2 or 3 is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gm_model = GaussianMixture(n_components=2, max_iter = 200, random_state=1).fit(obs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gm_model.predict(obs_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We look at kmeans_silhouette_analysis\n",
    "\n",
    "Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster. http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.08789046555225062\n",
      "For n_clusters = 3 The average silhouette_score is : 0.07400565765849043\n",
      "For n_clusters = 4 The average silhouette_score is : 0.06795148893837454\n",
      "For n_clusters = 5 The average silhouette_score is : 0.06463853037241843\n",
      "For n_clusters = 6 The average silhouette_score is : 0.06346335792308268\n",
      "For n_clusters = 7 The average silhouette_score is : 0.06442224067814628\n",
      "For n_clusters = 8 The average silhouette_score is : 0.06535853448402974\n",
      "For n_clusters = 9 The average silhouette_score is : 0.06588064103198324\n",
      "For n_clusters = 10 The average silhouette_score is : 0.06493274114857885\n"
     ]
    }
   ],
   "source": [
    "for n_clusters in range(2,11):\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(obs_train)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(obs_train, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the score stabilize after 4 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final choice of clusters and features\n",
    "In the R file OptimalKAndFeatureImportance.R we have calculated the best choice of K and the most important features, based on SilhouetteScore and the importance score from randomforest, respectively. From now on we use the values obtained there. We got that 2 is the optimal number of clusters (see SilhouetteScore.png and SilhouetteScoreAfterFeatureReduction.png) and $x_{6}$, $x_4$, $x_{114}$, $x_{12}$, $x_{84}$, $x_2$ and $x_{56}$ are the most important feautres, in that order. Recall that python counts from 0, so this means columns 5, 3, 113, 11, 83, 1 and 55. \n",
    "\n",
    "Start by dividing the people into 2 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=2, random_state=1).fit(obs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_obs_0 = obs_train[kmeans_model.labels_ == 0]\n",
    "train_obs_1 = obs_train[kmeans_model.labels_ == 1]\n",
    "train_lab_0 = lab_train[kmeans_model.labels_ == 0]\n",
    "train_lab_1 = lab_train[kmeans_model.labels_ == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3609, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_obs_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3609,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lab_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the histogram and see that there are more people with symptoms 1 and 3 in the 0 cluster. \n",
    "And there are more people with symptoms 0 and 2 in cluster 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1269.,    0.,    0., 2071.,    0.,    0.,   95.,    0.,    0.,\n",
       "         174.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_lab_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2338.,    0.,    0., 1086.,    0.,    0.,  327.,    0.,    0.,\n",
       "         140.]),\n",
       " array([0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7, 3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADnlJREFUeJzt3W3M3fVdx/H3ZxSmkUWKvcCmlF1o+kBmHKtNV0NiMBhukxXjSMqDUQimRiFuiU/qHlhlWcIeOBN0srDQrJgJI7ujjk6sdYb4AEYhjBsZcokIl21oRydswcyAXx+cf+WsvW7OdXdOT3/vV3Jy/uf7/53z//2uf3s+1//2SlUhSWrPe0bdAUnSaBgAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEatGnUH5rJmzZqanJwcdTckaaw88cQT36+qifnandIBMDk5ycGDB0fdDUkaK0n+Y5B27gKSpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGndJXAi/V5M6HRrLcl++4diTLlaSFcAtAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkho1bwAkWZ/k20meT/Jcko939XOT7E/yYve8uqsnyZ1JppI8nWRj32dt79q/mGT7yg1LkjSfQbYA3gb+sKp+CdgC3JrkYmAncKCqNgAHutcAVwMbuscO4C7oBQawC/gwsBnYdTw0JEnDN28AVNXhqnqym/4h8DywDtgK7Oma7QGu66a3AvdWz6PAOUnWAlcC+6vqWFX9ANgPXLWso5EkDWxBxwCSTAIfAh4Dzq+qw9ALCeC8rtk64NW+t013tdnqkqQRGDgAkpwNfBX4RFW9OVfTGWo1R/3E5exIcjDJwaNHjw7aPUnSAg0UAEnOpPfl/6Wq+lpXfq3btUP3fKSrTwPr+95+AXBojvpPqKq7q2pTVW2amJhYyFgkSQswyFlAAe4Bnq+qz/bN2gscP5NnO/BgX/3G7mygLcAb3S6ih4ErkqzuDv5e0dUkSSOwaoA2lwIfA55J8lRX+yRwB/BAkluAV4Dru3n7gGuAKeAt4GaAqjqW5FPA412726vq2LKMQpK0YPMGQFX9MzPvvwe4fIb2Bdw6y2ftBnYvpIOSpJXhlcCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKj5g2AJLuTHEnybF/tT5L8Z5Knusc1ffP+KMlUkheSXNlXv6qrTSXZufxDkSQtxCBbAF8Erpqh/udVdUn32AeQ5GJgG/CB7j1/leSMJGcAnwOuBi4GbujaSpJGZNV8DarqkSSTA37eVuD+qvox8O9JpoDN3bypqnoJIMn9Xdt/WXCPJUnLYinHAG5L8nS3i2h1V1sHvNrXZrqrzVaXJI3IYgPgLuAXgUuAw8CfdfXM0LbmqJ8kyY4kB5McPHr06CK7J0maz6ICoKpeq6p3qup/gS/w7m6eaWB9X9MLgENz1Gf67LuralNVbZqYmFhM9yRJA1hUACRZ2/fyt4DjZwjtBbYleW+Si4ANwHeAx4ENSS5Kcha9A8V7F99tSdJSzXsQOMl9wGXAmiTTwC7gsiSX0NuN8zLwuwBV9VySB+gd3H0buLWq3uk+5zbgYeAMYHdVPbfso5EkDWyQs4BumKF8zxztPw18eob6PmDfgnonSVoxXgksSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJatSqUXdAp4fJnQ+NZLkv33HtSJYrnQ7cApCkRhkAktQoA0CSGjVvACTZneRIkmf7aucm2Z/kxe55dVdPkjuTTCV5OsnGvvds79q/mGT7ygxHkjSoQbYAvghcdUJtJ3CgqjYAB7rXAFcDG7rHDuAu6AUGsAv4MLAZ2HU8NCRJozFvAFTVI8CxE8pbgT3d9B7gur76vdXzKHBOkrXAlcD+qjpWVT8A9nNyqEiShmixxwDOr6rDAN3zeV19HfBqX7vprjZb/SRJdiQ5mOTg0aNHF9k9SdJ8lvsgcGao1Rz1k4tVd1fVpqraNDExsaydkyS9a7EB8Fq3a4fu+UhXnwbW97W7ADg0R12SNCKLDYC9wPEzebYDD/bVb+zOBtoCvNHtInoYuCLJ6u7g7xVdTZI0IvPeCiLJfcBlwJok0/TO5rkDeCDJLcArwPVd833ANcAU8BZwM0BVHUvyKeDxrt3tVXXigWVJ0hDNGwBVdcMssy6foW0Bt87yObuB3QvqnSRpxXglsCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1KglBUCSl5M8k+SpJAe72rlJ9id5sXte3dWT5M4kU0meTrJxOQYgSVqc5dgC+I2quqSqNnWvdwIHqmoDcKB7DXA1sKF77ADuWoZlS5IWaSV2AW0F9nTTe4Dr+ur3Vs+jwDlJ1q7A8iVJA1hqABTw90meSLKjq51fVYcBuufzuvo64NW+9053NUnSCKxa4vsvrapDSc4D9if53hxtM0OtTmrUC5IdABdeeOESuydJms2StgCq6lD3fAT4OrAZeO34rp3u+UjXfBpY3/f2C4BDM3zm3VW1qao2TUxMLKV7kqQ5LDoAkvxMkvcdnwauAJ4F9gLbu2bbgQe76b3Ajd3ZQFuAN47vKpIkDd9SdgGdD3w9yfHP+Zuq+rskjwMPJLkFeAW4vmu/D7gGmALeAm5ewrIlSUu06ACoqpeAD85Qfx24fIZ6AbcudnmSpOXllcCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGrXU20FLGrLJnQ+NbNkv33HtyJat5ecWgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY3y7wFI0hxG9fcXhvG3F9wCkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDVq6AGQ5KokLySZSrJz2MuXJPUMNQCSnAF8DrgauBi4IcnFw+yDJKln2FsAm4Gpqnqpqv4HuB/YOuQ+SJIYfgCsA17tez3d1SRJQzbsm8Flhlr9RINkB7Cje/mjJC8sYXlrgO8v4f2Lks8s+0eOZBwrZFnHsgI/64Vobr2M+Oc9iNNmneQzSxrL+wdpNOwAmAbW972+ADjU36Cq7gbuXo6FJTlYVZuW47NG6XQZBziWU9XpMpbTZRwwnLEMexfQ48CGJBclOQvYBuwdch8kSQx5C6Cq3k5yG/AwcAawu6qeG2YfJEk9Q/+DMFW1D9g3pMUty66kU8DpMg5wLKeq02Usp8s4YAhjSVXN30qSdNrxVhCS1KixD4D5bi2R5L1JvtzNfyzJ5PB7OZgBxnJTkqNJnuoevzOKfs4nye4kR5I8O8v8JLmzG+fTSTYOu4+DGmAslyV5o2+d/PGw+ziIJOuTfDvJ80meS/LxGdqMxXoZcCzjsl5+Ksl3kny3G8ufztBm5b7DqmpsH/QOJP8b8AvAWcB3gYtPaPP7wOe76W3Al0fd7yWM5SbgL0fd1wHG8uvARuDZWeZfA3yL3nUhW4DHRt3nJYzlMuCbo+7nAONYC2zspt8H/OsM/77GYr0MOJZxWS8Bzu6mzwQeA7ac0GbFvsPGfQtgkFtLbAX2dNNfAS5PMtMFaaN22twmo6oeAY7N0WQrcG/1PAqck2TtcHq3MAOMZSxU1eGqerKb/iHwPCdfhT8W62XAsYyF7mf9o+7lmd3jxAOzK/YdNu4BMMitJf6/TVW9DbwB/NxQercwg94m47e7zfOvJFk/w/xxcLrdEuTXuk34byX5wKg7M59uF8KH6P222W/s1sscY4ExWS9JzkjyFHAE2F9Vs66X5f4OG/cAmPfWEgO2ORUM0s+/BSar6leAf+Dd3wrGzbisk0E8Cby/qj4I/AXwjRH3Z05Jzga+Cnyiqt48cfYMbzll18s8Yxmb9VJV71TVJfTujLA5yS+f0GTF1su4B8C8t5bob5NkFfCznJqb9IPcJuP1qvpx9/ILwK8OqW/LbZD1Nhaq6s3jm/DVu8blzCRrRtytGSU5k94X5peq6mszNBmb9TLfWMZpvRxXVf8F/BNw1QmzVuw7bNwDYJBbS+wFtnfTHwX+sbqjKaeYecdywv7Yj9Db9zmO9gI3dmedbAHeqKrDo+7UYiT5+eP7Y5Nspvd/6vXR9upkXR/vAZ6vqs/O0mws1ssgYxmj9TKR5Jxu+qeB3wS+d0KzFfsOG/qVwMupZrm1RJLbgYNVtZfeP5S/TjJFLzW3ja7HsxtwLH+Q5CPA2/TGctPIOjyHJPfROwtjTZJpYBe9g1tU1efpXQl+DTAFvAXcPJqezm+AsXwU+L0kbwP/DWw7RX/BuBT4GPBMt78Z4JPAhTB262WQsYzLelkL7Envj2W9B3igqr45rO8wrwSWpEaN+y4gSdIiGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXq/wCzZuGx2054+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_lab_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to observe the effects of two different therapeutic interventions, one of which is placebo, and the other is an experimental drug. First we calculate the success of the two treatments in the whole data set. Here we assume that treatment 0 is placebo and treatment 1 is active treatment, but it could very well be the other way around. We also assume that Y = 1 means that the patient is cured, and Y = 0 means that the patient is not cured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effectiveness of placebo is: 0.008959 \n",
      "The effectiveness of active treatment is: 0.588338 \n"
     ]
    }
   ],
   "source": [
    "#I want pandas\n",
    "features = pd.read_csv('historical_X.dat', header=None, sep=\" \")\n",
    "actions = pd.read_csv('historical_A.dat', header=None, sep=\" \")\n",
    "outcome = pd.read_csv('historical_Y.dat', header=None, sep=\" \")\n",
    "\n",
    "\n",
    "active_treatments = 0\n",
    "success_placebo = 0\n",
    "success_active = 0\n",
    "\n",
    "active_treatments = sum(actions.loc[:,0])\n",
    "\n",
    "\n",
    "for i in range(len(actions)):\n",
    "    if actions.loc[i,0] == 1 and outcome.loc[i,0] == 1:\n",
    "        success_active += 1\n",
    "    elif actions.loc[i,0] == 0 and outcome.loc[i,0] == 1:\n",
    "        success_placebo += 1\n",
    "\n",
    "\n",
    "print(\"The effectiveness of placebo is: %f \" %(success_placebo/(10000-active_treatments)))\n",
    "print(\"The effectiveness of active treatment is: %f \" %(success_active/(active_treatments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the treatment is effective in 58.8% of the cases for treatment 1, and 0.9% effective for treatment 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to investigate whether there are some parameters that effect the outcome of the treatment. I.e. if there are some genes or other parameters that affect the effect of the treatment. From previous parameter selection, we found that the most important features were $X_2$, $X_4$, $X_6$, $X_{12}$, $X_{56}$, $X_{84}$, $X_{114}$. To find out if there is some interaction between some parameters, we choose these features and also include the action feature, and do logistic regression for models with interactions with parameter selection. For code see $\\texttt{LogRegInteract.R}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Call:\n",
    "glm(formula = Y ~ X2 + X4 + X6 + X56 + X84 + X114 + A + X2:X4 + \n",
    "    X4:X6 + X84:A, family = binomial(link = \"logit\"), data = df2)\n",
    "\n",
    "Deviance Residuals: \n",
    "    Min       1Q   Median       3Q      Max  \n",
    "-3.0360  -0.5767  -0.3569  -0.1525   2.8913  \n",
    "\n",
    "Coefficients:\n",
    "            Estimate Std. Error z value Pr(>|z|)    \n",
    "(Intercept) -4.67718    0.16487 -28.369  < 2e-16 ***\n",
    "X2          -0.08487    0.14421  -0.589 0.556160    \n",
    "X4           1.05140    0.20175   5.211 1.87e-07 ***\n",
    "X6           2.15315    0.15559  13.838  < 2e-16 ***\n",
    "X56          0.31314    0.07974   3.927 8.60e-05 ***\n",
    "X84          0.51283    0.08225   6.235 4.52e-10 ***\n",
    "X114         1.09017    0.16115   6.765 1.33e-11 ***\n",
    "A            4.75012    0.14823  32.045  < 2e-16 ***\n",
    "X2:X4        0.57515    0.16910   3.401 0.000671 ***\n",
    "X4:X6       -1.24885    0.17152  -7.281 3.31e-13 ***\n",
    "X84:A        1.85978    0.39793   4.674 2.96e-06 ***\n",
    "---\n",
    "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
    "\n",
    "(Dispersion parameter for binomial family taken to be 1)\n",
    "\n",
    "    Null deviance: 10777.7  on 9998  degrees of freedom\n",
    "Residual deviance:  5832.4  on 9988  degrees of freedom\n",
    "AIC: 5854.4\n",
    "\n",
    "Number of Fisher Scoring iterations: 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text above is the output from R after we have done a parameter selection using BIC, allowing interactions of second order. We see here that the only interaction term including $A$, kept by the feature selection is the interaction between $X_84$ and $A$. The interaction term is positive, meaning that the treatment is more successfull when the $X_84$ feature is present. We repeat this process, but this time using AIC as selection criterion and get the following model. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Call:\n",
    "glm(formula = Y ~ X2 + X4 + X6 + X12 + X56 + X84 + X114 + A + \n",
    "    X2:X4 + X2:X84 + X2:A + X4:X6 + X4:X56 + X4:X84 + X6:X12 + \n",
    "    X6:X56 + X12:X56 + X56:X114 + X84:A, family = binomial(link = \"logit\"), \n",
    "    data = df2)\n",
    "\n",
    "Deviance Residuals: \n",
    "    Min       1Q   Median       3Q      Max  \n",
    "-3.0475  -0.5790  -0.3163  -0.1318   2.9156  \n",
    "\n",
    "Coefficients:\n",
    "            Estimate Std. Error z value Pr(>|z|)    \n",
    "(Intercept) -4.68844    0.24600 -19.058  < 2e-16 ***\n",
    "X2          -0.31497    0.18091  -1.741  0.08169 .  \n",
    "X4           0.89944    0.30607   2.939  0.00330 ** \n",
    "X6           1.88170    0.23232   8.099 5.52e-16 ***\n",
    "X12         -0.09774    0.17791  -0.549  0.58276    \n",
    "X56          0.26167    0.20762   1.260  0.20754    \n",
    "X84          0.65262    0.15372   4.245 2.18e-05 ***\n",
    "X114         1.43465    0.22428   6.397 1.59e-10 ***\n",
    "A            4.68603    0.16591  28.244  < 2e-16 ***\n",
    "X2:X4        0.64661    0.17501   3.695  0.00022 ***\n",
    "X2:X84       0.29707    0.15714   1.891  0.05869 .  \n",
    "X2:A         0.62489    0.36071   1.732  0.08321 .  \n",
    "X4:X6       -1.38088    0.20676  -6.679 2.41e-11 ***\n",
    "X4:X56       0.80771    0.34532   2.339  0.01933 *  \n",
    "X4:X84      -0.33236    0.17645  -1.884  0.05962 .  \n",
    "X6:X12       0.41585    0.18598   2.236  0.02536 *  \n",
    "X6:X56       0.32303    0.19385   1.666  0.09564 .  \n",
    "X12:X56     -0.34621    0.18055  -1.918  0.05517 .  \n",
    "X56:X114    -0.73643    0.33422  -2.203  0.02757 *  \n",
    "X84:A        1.78385    0.40039   4.455 8.38e-06 ***\n",
    "---\n",
    "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
    "\n",
    "(Dispersion parameter for binomial family taken to be 1)\n",
    "\n",
    "    Null deviance: 10777.7  on 9998  degrees of freedom\n",
    "Residual deviance:  5809.1  on 9979  degrees of freedom\n",
    "AIC: 5849.1\n",
    "\n",
    "Number of Fisher Scoring iterations: 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this model, it does not seem like any features have a negative interaction with $A$, meaning that treatment1 will be effective for all features. However we do observe that some features and some feature combinations seems to have a negative effect on the result of the treatment. In both the AIC and the BIC model, the presence of the $X2$ feature influences the result of the treatment in a negative way, meaning that these patients are less likely of being cured. Also, both models indicate that the feature combination of $X_4$ and $X_6$ influence the result of the treatment in a negative way. Based on this, we would always recommend the active treatment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would also like to investigate whether the clusters found by K-means clustering are affected differently by the treatment. We found that two clusters were the optimal number of clusters. We choose to do this on the whole data set, so that all the data are divided into one of the two clusters. We are not sure whether this is the correct approach, or if we should only fit the test data, so please correct us if we are wrong. For this, we repeat the procedure of the first part of Question 2, but this time dividing the data into the two clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effectiveness of placebo in cluster 0 is: 0.001202 \n",
      "The effectiveness of active treatment in cluster 0 is: 0.470206 \n",
      "The effectiveness of placebo in cluster 1 is: 0.018064 \n",
      "The effectiveness of active treatment in cluster 1 is: 0.667636 \n"
     ]
    }
   ],
   "source": [
    "# First fit a K-means\n",
    "kmeans = KMeans(n_clusters = 2, random_state = 1).fit(obs_train)\n",
    "\n",
    "#Divide observations into two clusters. \n",
    "cluster = kmeans.predict(observations)  \n",
    "index_cluster0 = np.where(cluster == 0) \n",
    "index_cluster1 = np.where(cluster == 1)\n",
    "\n",
    "actions_cluster0 = actions.iloc[index_cluster0]\n",
    "outcome_cluster0 = outcome.iloc[index_cluster0]\n",
    "\n",
    "actions_cluster1 = actions.iloc[index_cluster1]\n",
    "outcome_cluster1 = outcome.iloc[index_cluster1]\n",
    "\n",
    "active_treatments0 = sum(actions_cluster0.loc[:,0])\n",
    "active_treatments1 = sum(actions_cluster1.loc[:,0])\n",
    "\n",
    "#First cluster 0:\n",
    "#Successfull and active treatments if both are 1\n",
    "success_active0 = np.sum(np.multiply(actions_cluster0.values, outcome_cluster0.values))\n",
    "#Successfull, active treatments if outcome is 1, but active is 0\n",
    "success_placebo0 = np.sum(outcome_cluster0.values) - success_active0\n",
    "\n",
    "print(\"The effectiveness of placebo in cluster 0 is: %f \" %(success_placebo0/(actions_cluster0.shape[0]-active_treatments0)))\n",
    "print(\"The effectiveness of active treatment in cluster 0 is: %f \" %(success_active0/(active_treatments0)))        \n",
    "\n",
    "#Cluster 1\n",
    "success_active1 = np.sum(np.multiply(actions_cluster1.values, outcome_cluster1.values))\n",
    "success_placebo1 = np.sum(outcome_cluster1.values) - success_active1\n",
    "\n",
    "print(\"The effectiveness of placebo in cluster 1 is: %f \" %(success_placebo1/(actions_cluster1.shape[0]-active_treatments1)))\n",
    "print(\"The effectiveness of active treatment in cluster 1 is: %f \" %(success_active1/(active_treatments1)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the a bigger proportion of patients in cluster 1 are cured than in cluster 0, this apply both to the active treatment and the placebo treatment.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in ![title](SilhouetteScoreAfterFeatureReduction.png)$\\texttt{SilhouetteScoreAfterFeatureReduction.png}$, the clusters were more separated when we only kept the most important features. Maybe the differences in effect of treatment between the two clusters will be even more apparent if we cluster the observations based on only these most important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effectiveness of placebo in cluster 0 is: 0.010493 \n",
      "The effectiveness of active treatment in cluster 0 is: 0.578473 \n",
      "The effectiveness of placebo in cluster 1 is: 0.007727 \n",
      "The effectiveness of active treatment in cluster 1 is: 0.614173 \n"
     ]
    }
   ],
   "source": [
    "important_features = features[[1, 3, 5, 55, 83 , 113]]\n",
    "if_train, if_test = train_test_split(important_features, test_size=0.25)\n",
    "\n",
    "kmeans_if = KMeans(n_clusters=2, random_state=1).fit(if_train)\n",
    "cluster_if = kmeans_if.predict(important_features)\n",
    "\n",
    "\n",
    "index_cluster0_if = np.where(cluster_if == 0) \n",
    "index_cluster1_if = np.where(cluster_if == 1)\n",
    "\n",
    "actions_cluster0_if = actions.iloc[index_cluster0_if]\n",
    "outcome_cluster0_if = outcome.iloc[index_cluster0_if]\n",
    "\n",
    "actions_cluster1_if = actions.iloc[index_cluster1_if]\n",
    "outcome_cluster1_if = outcome.iloc[index_cluster1_if]\n",
    "\n",
    "\n",
    "active_treatments0_if = sum(actions_cluster0_if.loc[:,0])\n",
    "active_treatments1_if = sum(actions_cluster1_if.loc[:,0])\n",
    "\n",
    "\n",
    "#First cluster 0:\n",
    "#Successfull and active treatments if both are 1\n",
    "success_active0_if = np.sum(np.multiply(actions_cluster0_if.values, outcome_cluster0_if.values))\n",
    "#Successfull, active treatments if outcome is 1, but active is 0\n",
    "success_placebo0_if = np.sum(outcome_cluster0_if.values) - success_active0_if\n",
    "\n",
    "\n",
    "print(\"The effectiveness of placebo in cluster 0 is: %f \" %(success_placebo0_if/(actions_cluster0_if.shape[0]-active_treatments0_if)))\n",
    "print(\"The effectiveness of active treatment in cluster 0 is: %f \" %(success_active0_if/(active_treatments0_if)))        \n",
    "\n",
    "\n",
    "#Cluster 1\n",
    "success_active1_if = np.sum(np.multiply(actions_cluster1_if.values, outcome_cluster1_if.values))\n",
    "success_placebo1_if = np.sum(outcome_cluster1_if.values) - success_active1_if\n",
    "\n",
    "print(\"The effectiveness of placebo in cluster 1 is: %f \" %(success_placebo1_if/(actions_cluster1_if.shape[0]-active_treatments1_if)))\n",
    "print(\"The effectiveness of active treatment in cluster 1 is: %f \" %(success_active1_if/(active_treatments1_if)))        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are different from the ones we got previously, when all the features were included. We were hoping to find bigger differences between the clusters using only the most important features, however, the effect of the treatment is more similar between the two clusters when the observations are clustered only by the important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small look at feature selction on the historical data with python-code\n",
    "\n",
    "Since the analysis above was done with $\\texttt{R}$ and it is written that this exercise has to be done in python we include a small section on how we also can look at feature selection in python.\n",
    "\n",
    "Here we use scikit learn's $\\texttt{SelectKBest}$ to scores the features using a the $\\texttt{chi2}$ function. Chi-squared is suited for classification tasks with non-negative features, which fits our scenario. In the cede below we look at both the 10 best scores and all the significant explanatory variables. From the printout we see that 102 of the variables are significant, have a p-value of less than 0.05. \n",
    "\n",
    "We have also created 250 trees from $\\texttt{ExtraTreesClassifier}$ and from this we look at the feature importances of each of the varaibles in this ensamble of trees. Here we see that there is an overlap with the results from the $\\texttt{SelectKBest}$-method. Both methods agree that $x_{130}, x_{128}, x_{129}, x_{102}$ are the 4 most important features, in descending order. That means that the treatment and the sympotms are the most important factors for wether or not the patient displays measuable effects after the treatment. The order of the other variables can be shifted in the two methods due to, e.g. high correlation between the variables, but we have not done any further investigation into that. \n",
    "\n",
    "Note that we now obtained different results than with the methods we used in $\\texttt{R}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 131)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "features2 = pandas.read_csv('historical_X.dat', header=None, sep=\" \")\n",
    "features2['a'] = pandas.read_csv('historical_A.dat', header=None, sep=\" \")\n",
    "\n",
    "X, y = features2.values, outcome\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 variables with best score: \n",
      "[130 128 129 102  55   5 126  44  52 101]\n",
      "[3753.63263455  617.44078638  504.95725172  270.78275622  207.93236283\n",
      "  200.7152214   192.89502425  174.65142505  165.34247839  161.54590066]\n",
      "\n",
      "The 10 most significant vairables\n",
      "[130 128 129 102  55   5 126  44  52 101  69 123  94 125   7  48  84  43\n",
      "  97  50  46   3   2  28  10  72  42  85  11  60  83  93 107 110  23 119\n",
      "  15  49  24 113  90  22  66  73  63  91 120  95  53  16 124  26 105  71\n",
      "  31  20  45 103  58  41  68  78  59  19  89 108  70  27  29  18 117  21\n",
      "  12  62  65  77  61  17 118 114 104  51  30 111  92 109  13  88  34  64\n",
      "  98  35   8  75  14  38  79  82 122  87  54   0  57]\n",
      "[0.00000000e+000 2.69388243e-136 7.93200355e-112 7.66146540e-061\n",
      " 3.88128940e-047 1.45799468e-045 7.42051836e-044 7.13389823e-040\n",
      " 7.70010748e-038 5.19873280e-037 3.77305985e-036 4.47491319e-036\n",
      " 6.35297613e-035 1.35183836e-033 5.10005660e-033 7.50601148e-033\n",
      " 2.95759765e-032 7.90761948e-032 1.66939946e-030 3.56119654e-030\n",
      " 1.45657621e-029 1.74220512e-029 2.92991312e-028 5.18434273e-027\n",
      " 2.08242011e-026 8.85935690e-026 3.46856264e-024 7.90899928e-024\n",
      " 1.65647408e-023 3.25479944e-022 6.01246332e-022 1.71389959e-021\n",
      " 5.31899755e-019 6.82335203e-019 1.67766006e-018 4.80860478e-017\n",
      " 1.72977601e-016 3.38779350e-016 4.39540455e-015 1.07964056e-014\n",
      " 1.12816851e-014 2.06271732e-014 1.02603396e-013 1.17547114e-013\n",
      " 4.47771942e-012 1.12136574e-011 1.53988629e-011 3.13637005e-011\n",
      " 4.50355639e-011 8.18201697e-011 9.16406437e-011 9.27057231e-011\n",
      " 2.40461685e-010 2.62444108e-010 3.79284305e-010 4.43381607e-010\n",
      " 7.29311738e-010 1.01494895e-009 2.03298215e-009 4.30979083e-009\n",
      " 6.19648811e-009 8.14485814e-009 1.07121951e-008 3.77179937e-008\n",
      " 5.75166824e-008 2.34781462e-007 4.30914558e-007 5.79182798e-007\n",
      " 5.80268020e-007 1.31455984e-006 4.01143881e-006 8.19761118e-006\n",
      " 1.22534327e-005 1.41655765e-005 1.50441802e-005 1.65305920e-005\n",
      " 2.93645317e-005 3.01271752e-005 3.58095598e-005 1.88313931e-004\n",
      " 2.54875941e-004 3.57877416e-004 5.77076415e-004 9.57272439e-004\n",
      " 1.20204348e-003 1.88107539e-003 2.25154127e-003 2.70523970e-003\n",
      " 2.92808566e-003 4.25046706e-003 4.82398210e-003 7.09734872e-003\n",
      " 7.52529621e-003 7.60004732e-003 7.72444571e-003 8.12511664e-003\n",
      " 8.39188331e-003 2.23261654e-002 3.31813859e-002 3.51647370e-002\n",
      " 4.29716540e-002 4.58646427e-002 5.08764376e-002]\n"
     ]
    }
   ],
   "source": [
    "k_best = SelectKBest(chi2, k=2).fit(X, y)\n",
    "\n",
    "# Let's look at the 10 best scores\n",
    "# High score is better\n",
    "b = np.argsort(-k_best.scores_)[:10]\n",
    "print(\"The 10 variables with best score: \")\n",
    "print(b)\n",
    "print(k_best.scores_[b])\n",
    "\n",
    "# Let's look at the best p-values. A low p-value indicate that the explanatory variable is significant.\n",
    "# We set the significance limit at 0.05 = 5e-02\n",
    "print(\"\\nThe 10 most significant vairables\")\n",
    "b = np.argsort(k_best.pvalues_)[:103]\n",
    "print(b)\n",
    "print(k_best.pvalues_[b])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the case where create an ensamble of 250 trees and look at the importance of the variables in these trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ten variables with highest scores:\n",
      "[130 128 129 102 101 127  44   7  50  48]\n",
      "[0.33894289 0.04216753 0.03049841 0.02313356 0.01016434 0.01011807\n",
      " 0.00936744 0.00915148 0.0080901  0.00803173]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=250)\n",
    "clf = clf.fit(X, np.ravel(y))\n",
    "b = np.argsort(-clf.feature_importances_)[:10]\n",
    "print(\"The ten variables with highest scores:\")\n",
    "print(b)\n",
    "print(clf.feature_importances_[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part Two - Improved Policies\n",
    "### Exercise 1 (Meassuring utility)\n",
    "#### 1. Measure the utility of $\\pi_0$ on the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Actions is an array of 0's and 1's, representing 'placebo' and 'experimantal drug', respectively.\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Outcome is an array of 0' and 1's, representing 'no effect' and 'measurable effect', respectively.\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility function is given as\n",
    "$$\\sum_t r_t = \\sum_t (-0.1a_t + y_t).$$\n",
    "Here the -0.1 factor implies that the active treatment must be at least 10% more effective than the placebo for the utility to be better for the experimental drug than the placebo. We look at the utility of $\\pi_0$ on the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191.2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = np.sum(-0.1*actions + outcome)\n",
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the utility is 1191.2. We are not confident on wheter or not this is a good result. One should note that $t$ span from 1 to 10 000. So the maximal utility we can achieve is 10 000. However, it that scenario we give placebos to all the patients and we see a measuarble effect in all of them, which is highly unlikely. We see that giving a patient the experimental drug decrease the utility, if not the experimental drug affect the outcome in a postive direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercise asks for the expected utility. We cannot calculate it exactly, but we can estimate it from the data. That is what we have done above. Below we describe it futher.\n",
    "$$\\hat{E[U]} = E_{data}[U] = \\sum_t (-0.1E_{data}[a_t] + E_{data}[y_t])$$ where $E_{data}[a_t] = \\sum(0p(a_t=0) + 1p(a_t=1)) = \\sum (\\frac{\\# a_t = 1}{\\# a_t})$ and $E_{data}[y_t] = \\sum(0p(y_t=0) + 1p(y_t=1)) = \\sum (\\frac{\\# y_t = 1}{\\# y_t})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1421"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc1out = np.sum(outcome==1)/len(outcome)\n",
    "perc1out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2298"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc1act = np.sum(actions==1)/len(actions)\n",
    "perc1act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191.2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10000*(-0.1*perc1act + perc1out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which was the same as we got above, as expected.\n",
    "We have also implemented this in the python file we have delivered.\n",
    "Simply call policy.estimate_utility(features, actions, outcome)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Provide error bounds on the expected utility\n",
    "To provide error bounds on the expected utility we use bootstraping. We create $B$ datasets by sampling from the original data $10 000$ times with replacement. For each of the $B$ dataset we calculate the expected utility. To get, let's say, a 95% error bound we look at the 2.5% and 97.5% quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = 500\n",
    "results = np.zeros(B)\n",
    "\n",
    "for b in range(B):\n",
    "    n = len(outcome)\n",
    "    indices = np.random.choice(n, n)\n",
    "    outcome_bootstrap = outcome[indices]\n",
    "    action_bootstrap = actions[indices]\n",
    "    results[b] = np.sum(-0.1*action_bootstrap + outcome_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1127.9075, 1261.5225])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = np.percentile(results, [2.5, 97.5])\n",
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we see that a 95% CI for the utility is $[1127.9075, 1261.5225]$. So the utility of $\\pi_0$ is well inside these error bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (Improved policies)\n",
    "\n",
    "#### 1.\n",
    "\n",
    "We want to improve the policy, so that we can increase the utility. For the model, we choose a neural network and logistic regression, which we fit by first making an object of the classes $\\texttt{NNRecommender}$ and $\\texttt{LogisticRecommender}$, in the file $\\texttt{TestRecommender.py}$, where we set the reward function to what it is defined as in the project description. We then call the policies' $\\texttt{fit_treatment_outcome}$-function, so that our policies are trained on the historical data. To find the estimated utility of these improved models, we call $\\texttt{policy_NN.estimate_utility(features, None, None, policy.NN)}$ and $\\texttt{policy_logistic.estimate_utility(features, None, None, policy.logistic)}$. Note that when a $\\texttt{policy}$ argument is given to the $\\texttt{estimate_utility}$-function, the $\\texttt{policy}$ will recommend an action, and it is these actions (and the probabilities of the different outomes) that are used to calculate the estimated utility.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "Run $\\texttt{TestRecommender.py}$ to see the results. Below you can see the last printout from $\\texttt{TestRecommender.py}$. From this we see that both logistic regression and neural network are better than the historical policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting treatment outcomes\n",
      "Neural Network estimating utility   1000 of 10000\n",
      "Neural Network estimating utility   2000 of 10000\n",
      "Neural Network estimating utility   3000 of 10000\n",
      "Neural Network estimating utility   4000 of 10000\n",
      "Neural Network estimating utility   5000 of 10000\n",
      "Neural Network estimating utility   6000 of 10000\n",
      "Neural Network estimating utility   7000 of 10000\n",
      "Neural Network estimating utility   8000 of 10000\n",
      "Neural Network estimating utility   9000 of 10000\n",
      "Neural Network estimating utility  10000 of 10000\n",
      "Logistic model estimating utility   1000 of 10000\n",
      "Logistic model estimating utility   2000 of 10000\n",
      "Logistic model estimating utility   3000 of 10000\n",
      "Logistic model estimating utility   4000 of 10000\n",
      "Logistic model estimating utility   5000 of 10000\n",
      "Logistic model estimating utility   6000 of 10000\n",
      "Logistic model estimating utility   7000 of 10000\n",
      "Logistic model estimating utility   8000 of 10000\n",
      "Logistic model estimating utility   9000 of 10000\n",
      "Logistic model estimating utility  10000 of 10000\n",
      "\n",
      "The historical utility was 0.119120\n",
      "The estimated utility of the improved NN policy is: 0.459083 \n",
      "The estimated utility of the improved logistic policy is: 0.427203\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "features = pandas.read_csv('historical_X.dat', header=None, sep=\" \").values\n",
    "actions = pandas.read_csv('historical_A.dat', header=None, sep=\" \").values\n",
    "outcome = pandas.read_csv('historical_Y.dat', header=None, sep=\" \").values\n",
    "n = features.shape[0]\n",
    "\n",
    "import NNRecommender\n",
    "policy_factory_NN = NNRecommender.NNRecommender\n",
    "policy_NN = policy_factory_NN(2, 2)\n",
    "\n",
    "import LogisticRecommender\n",
    "policy_factory_logistic = LogisticRecommender.LogisticRecommender\n",
    "policy_logistic = policy_factory_logistic(2, 2)\n",
    "\n",
    "def reward_function(action, outcome):\n",
    "    return -0.1*action + outcome\n",
    "\n",
    "# First we need to set the reward\n",
    "policy_NN.set_reward(reward_function)\n",
    "policy_logistic.set_reward(reward_function)\n",
    "\n",
    "## Fit the policy on historical data \n",
    "policy_NN.fit_treatment_outcome(features, actions, outcome)\n",
    "policy_logistic.fit_treatment_outcome(features, actions, outcome)\n",
    "\n",
    "# Utility of the historical policy. Deterministic, so no difference if we call with policy_NN or policy_logistic\n",
    "utility_hist = policy_NN.estimate_utility(features, actions, outcome)/n\n",
    "\n",
    "# Utility of new policy\n",
    "utility_new_policy_NN = policy_NN.estimate_utility(features, None, None, policy_NN)/n\n",
    "utility_new_policy_logistic = policy_logistic.estimate_utility(features, None, None, policy_logistic)/n\n",
    "\n",
    "# Utility of improved policy, using a neural network trained on the historical data\n",
    "print(\"\\nThe historical utility was %2f\" %(utility_hist))\n",
    "print(\"The estimated utility of the improved NN policy is: %2f \" % (utility_new_policy_NN))\n",
    "print(\"The estimated utility of the improved logistic policy is: %2f\"  % (utility_new_policy_logistic))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The historical utility was 1191.200000\n",
    "The estimated utility of the improved NN policy is: 4606.017435 \n",
    "The estimated utility of the improved logistic policy is: 4273.185857 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Three - Adaptive Experiment Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part part we are going to test our recommenders on new patients and evaluate the results. We do this by using the $\\texttt{test_policy}$ function. It creates a fixed number of patients, ask the recommenders what treatments each indivdual should recive and then calculate the outcome. At the end it let the recommender obsereve the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy(generator, policy, reward_function, T, seed = None, printout = False, print_index = 100, actions=False):\n",
    "    policy.set_reward(reward_function)\n",
    "    u = 0\n",
    "    \n",
    "    # Variable to count the number of people who were given a treatment\n",
    "    total_given_treatment = 0\n",
    "    \n",
    "    # For reproducibility we allow the user to set the seed\n",
    "    if (seed != None):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    # Record the number of each treatments \n",
    "    if (actions == True):\n",
    "        actions_count = np.zeros(129)\n",
    "    \n",
    "    for t in range(T):\n",
    "        # We generate 1 new pasient\n",
    "        x = generator.generate_features()\n",
    "        \n",
    "        # Find the best action, from our model\n",
    "        a = policy.recommend(x)\n",
    "        \n",
    "        if (actions == True):\n",
    "            actions_count[a] += 1\n",
    "\n",
    "        # If given a treatment, then we record it\n",
    "        if (a != 0): \n",
    "            total_given_treatment += 1\n",
    "            \n",
    "        # Generate the outcome based on user_data and action\n",
    "        y = generator.generate_outcome(x, a)\n",
    "       \n",
    "        # Add the utility/reward\n",
    "        u += reward_function(a, y)\n",
    "        \n",
    "        # Let the policy now about the result/refit the model.\n",
    "        policy.observe(x, a, y)\n",
    "        \n",
    "        # A small printout\n",
    "        if ((printout) & (t % print_index == 0)):\n",
    "            print(\"Iteration: %6d \\t Current mean reward: %7.4f\" %(t, u/(t+1)))\n",
    "    \n",
    "    if (actions):\n",
    "        return [u/T, total_given_treatment, actions_count] \n",
    "    else:\n",
    "        return [u/T, total_given_treatment] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the introduction we use a slightly modified $\\texttt{reward_function}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(action, outcome):\n",
    "    # Here we use the alternative reward_function discussed in the introduction.\n",
    "    # That is, we assume all medicins have the same cost and that they must be 10% more efficient than the placebo.\n",
    "    if (action >= 1): \n",
    "        return -0.1 + outcome\n",
    "    else: \n",
    "        return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the results one should let each recommender run several times. There is a high variability in the results. That means that the results from two consecutive simulations can yield quite different results. Hence it is important to create empiraical confidence intervals for the utility. We have not computed the variance of the empirical data, since this is indirectly visable from the range of the confidence intervals, but the variance is also a good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator generates the data and the outcome\n",
    "# policy_maker is an object that can create policies\n",
    "# reward_function calculate the reward given the action and the outcome\n",
    "# T is the number of patients\n",
    "# N is the number of times we should treat T patients\n",
    "# features are the historical features\n",
    "# actions are the historical actions\n",
    "# outcome are the historical outcome\n",
    "# extra is extra arguments for the policy\n",
    "def create_CI(generator, policy_maker, reward_function, T, N, features, actions, outcome, extra = None):\n",
    "    res = np.zeros((N,2))\n",
    "    for n in range(N):\n",
    "        # Create a policy from the policymaker\n",
    "        if (extra == None):\n",
    "            policy = policy_maker(generator.get_n_actions(), generator.get_n_outcomes())\n",
    "        else:\n",
    "            policy = policy_maker(generator.get_n_actions(), generator.get_n_outcomes(), extra)\n",
    "            \n",
    "        # Set the reward function\n",
    "        policy.set_reward(reward_function)\n",
    "        \n",
    "        # Fit the model\n",
    "        policy.fit_treatment_outcome(features, actions, outcome)\n",
    "        \n",
    "        # Record the results\n",
    "        res[n] = test_policy(generator, policy, reward_function, T, seed = 27183+n)\n",
    "        \n",
    "        if(n % 10 == 0):\n",
    "            print(\"Done with n = %d\" % n)\n",
    "\n",
    "    print(\"Utility percentiles(2.5, 50, 97.5): \", np.percentile(res[:,0], [2.5, 50, 97.5]))\n",
    "    print(\"Percentage of treatments percentiles(2.5, 50, 97.5): \", np.percentile(res[:,1], [2.5, 50, 97.5])/T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - online policy testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "\n",
    "Here we create a $\\texttt{HistoricalRecommender}$ recommender and test it on the testbench. Recall that the $\\texttt{HistoricalRecommender}$ recommends based on the frequency of recommendations in the historical dataset. That is, if the percentage of people given the placebo in the historical data is $30\\%$, then our recommender will also recommend placebo in $30\\%$ of the cases. \n",
    "\n",
    "In hindsight we are uncertain if we mayhaps misinterpreted this model. The idea might have been that we should have used the historical dataset to find the person in this dataset who is most similar to the new patient and give the new patient the same treatment as the historical patient. This could have been done with a KNN with K=1.\n",
    "\n",
    "Whether or not we misinterpreted it, our model yields close to the historical results. Hence we are quite certain that what we have done is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_generation\n",
    "generator = data_generation.DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.08799 0.1064  0.13249]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.202   0.23    0.26305]\n"
     ]
    }
   ],
   "source": [
    "import HistoricalRecommender\n",
    "policy_factory_historical = HistoricalRecommender.HistoricalRecommender\n",
    "\n",
    "T = 500\n",
    "N = 100\n",
    "create_CI(generator, policy_factory_historical, reward_function, T, N, features, actions, outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above we get a bite wider interval than in the previous part, but note that the median is close to the historical utility and that our $95\\%$ empirical confidence interval cover the results from the historical part.\n",
    "Note that the the historical recommender prescibe treatments to about a fifth of the patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "Here we are going to look at the improved recommenders. Note that we \n",
    "\n",
    "\n",
    "We also create some \"stupid\" recommenders to have more recommenders to compare our improved policies with. \n",
    "We have created a $\\texttt{FixedTreatmentRecommender}$ and a $\\texttt{RandomRecommender}$. These should be self explanatory, but they always recommend a fixed treatment(placebo or treatment1, defined in the initializtion) or does a random choice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Always placebo: \n",
      "Utility percentiles(2.5, 50, 97.5):  [0.004   0.012   0.02105]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0. 0. 0.]\n",
      "\n",
      "Always treatment1: \n",
      "Utility percentiles(2.5, 50, 97.5):  [0.39695 0.432   0.476  ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [1. 1. 1.]\n",
      "\n",
      "Random treatment: \n",
      "Utility percentiles(2.5, 50, 97.5):  [0.19066  0.2237   0.257115]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.45495 0.503   0.54105]\n"
     ]
    }
   ],
   "source": [
    "import FixedTreatmentRecommender\n",
    "policy_factory_fixed = FixedTreatmentRecommender.FixedTreatmentRecommender\n",
    "\n",
    "import RandomRecommender\n",
    "policy_factory_random = RandomRecommender.RandomRecommender\n",
    "\n",
    "T = 500\n",
    "N = 100\n",
    "\n",
    "print(\"Always placebo: \")\n",
    "create_CI(generator, policy_factory_fixed, reward_function, T, N, features, actions, outcome, extra = 0)\n",
    "\n",
    "print(\"\\nAlways treatment1: \")\n",
    "create_CI(generator, policy_factory_fixed, reward_function, T, N, features, actions, outcome, extra = 1)\n",
    "\n",
    "print(\"\\nRandom treatment: \")\n",
    "create_CI(generator, policy_factory_random, reward_function, T, N, features, actions, outcome, extra = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we in this case we know how the outcomes are generated, that is, we have access to $\\texttt{big_generating_matrices.mat}$ and the $\\texttt{data_generation}$ we can create an $\\texttt{OptimalRecommender}$ that recommends the optimal treatment. From the two files we see that the outcome is decided based on the the sign of the dot product between the user and the recommended action. If the the dot product is positive then $y_t = 1$ and if the dot product is negative then $y_t = 0$. The optimal policy will then chose the action with highest dot product, given that it is positive, else it will recommend the placebo to maximize the reward (to escape the penatlity of using a treatment).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal: \n",
      "Utility percentiles(2.5, 50, 97.5):  [0.4536 0.486  0.5292]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.504 0.54  0.588]\n"
     ]
    }
   ],
   "source": [
    "import OptimalRecommender\n",
    "policy_factory_optimal = OptimalRecommender.OptimalRecommender\n",
    "\n",
    "T = 500\n",
    "N = 100\n",
    "\n",
    "print(\"Optimal: \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take a look at our improved policies:\n",
    "Single_logistic\n",
    "Bootstrap_logistic\n",
    "NN_(3,2,2)\n",
    "NN_(5,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single logistic model: \n",
      "Done with n = 99\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.429635 0.4667   0.500715]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.63685 0.67    0.71505]\n",
      "Bootstrap logistic model: \n",
      "Done with n = 99\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.425365 0.4663   0.50262 ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.64285 0.68    0.71705]\n"
     ]
    }
   ],
   "source": [
    "# Single logistic\n",
    "import LogisticRecommender\n",
    "policy_factory_logistic = LogisticRecommender.LogisticRecommender\n",
    "\n",
    "import LogisticRecommenderBoot\n",
    "policy_factory_logistic_boot = LogisticRecommenderBoot.LogisticRecommenderBoot\n",
    "\n",
    "print(\"Single logistic model: \")\n",
    "create_CI(generator, policy_factory_logistic, reward_function, T, N, features, actions, outcome, extra = 0)\n",
    "\n",
    "print(\"Bootstrap logistic model: \")\n",
    "create_CI(generator, policy_factory_logistic_boot, reward_function, T, N, features, actions, outcome, extra = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(5,2): \n",
      "Done with n = 9\n",
      "Done with n = 19\n",
      "Done with n = 29\n",
      "Done with n = 39\n",
      "Done with n = 49\n",
      "Done with n = 59\n",
      "Done with n = 69\n",
      "Done with n = 79\n",
      "Done with n = 89\n",
      "Done with n = 99\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.42499 0.4612  0.50504]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.4878 0.536  0.5801]\n",
      "NN(2,2,3): \n",
      "Done with n = 9\n",
      "Done with n = 19\n",
      "Done with n = 29\n",
      "Done with n = 39\n",
      "Done with n = 49\n",
      "Done with n = 59\n",
      "Done with n = 69\n",
      "Done with n = 79\n",
      "Done with n = 89\n",
      "Done with n = 99\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.42616 0.4671  0.51069]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.53495 0.578   0.6241 ]\n"
     ]
    }
   ],
   "source": [
    "import NeuralNetworkRecommender\n",
    "policy_factory_NN = NeuralNetworkRecommender.NeuralNetworkRecommender\n",
    "\n",
    "print(\"NN(5,2): \")\n",
    "create_CI(generator, policy_factory_NN, reward_function, T, N, features, actions, outcome, extra = [0, [5,2]])\n",
    "\n",
    "print(\"NN(2,2,3): \")\n",
    "create_CI(generator, policy_factory_NN, reward_function, T, N, features, actions, outcome, extra = [0, [2,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also created two other improved polcies with utilize the clustert. That is, based on the the historical data it divides the poplulation into two subpopulations and fit a model on each of these. The results for the logistic cluster are nearly identical to those obtained by the non-clustered version. The clustered nerual network actually obtained a lower utility. We think this perhaps might be due to the fact that the trainingset for the individaul neural networks became too small. As we now, it takes a lot of data to fine tune a neural network. Note that the code below takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic cluster: \n",
      "Done with n = 0\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.313625 0.46     0.73975 ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.56125 0.7     0.8775 ]\n",
      "NN cluster(5,2): \n",
      "Done with n = 0\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.320125 0.425    0.675   ]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.41125 0.525   0.75   ]\n"
     ]
    }
   ],
   "source": [
    "import LogisticRecommenderCluster\n",
    "policy_factory_logistic_cluster = LogisticRecommenderCluster.LogisticRecommenderCluster\n",
    "\n",
    "# Old code so is hardcoded to (5,2) layers\n",
    "import NNRecommenderCluster\n",
    "policy_factory_NN_cluster = NNRecommenderCluster.NNRecommenderCluster\n",
    "\n",
    "N = 100\n",
    "T = 500\n",
    "\n",
    "print(\"Logistic cluster: \")\n",
    "create_CI(generator, policy_factory_logistic_cluster, reward_function, T, N, features, actions, outcome)\n",
    "\n",
    "print(\"NN cluster(5,2): \")\n",
    "create_CI(generator, policy_factory_NN_cluster, reward_function, T, N, features, actions, outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize the results from this exercise we have made a table. Note that the numbers might be different than the numbers above. That is becaue we have not fixed a seed so the values change slightly each time you run the code. However, since we run the code 100 times each time the differences are miniscue.\n",
    "\n",
    "![title](Table1.png)\n",
    "\n",
    "From the table we see that the historical recommender and the improved recommenders perform at the same level as in the previous part. When we look at the utility confidence intervals of our improved policies we see that they overlap quite a lot. This means that the models are equally good. However, one should note that the neural network recommends the drug less often but obtain the same utility. That is, the Neural Network is better at detecting patients who will respond positive to the treatment than the logistic. The logistic recommends the treatment more, so they treat more pacients but they also get more patients which doesn't respond to the treatment. Here it would have been interesting to change the penalty and see if this influence the utility. One could also here look at a confusion matrix, to analyze the percentages of false-positve, false-negative, true-positve and true-negative.\n",
    "\n",
    "The clustered versions yield approximately the same results, and hence we have omitted them from the table.\n",
    "\n",
    "One should also note that our improved policies are not far from the the optimal values.\n",
    "\n",
    "The fact that by always recommending the treatment we can obtain an utility which is this close to the optimal utility is quite worring. At least in the setting where the vague terms treatments represent drugs. If we are in the case where the treatment is a sunscreen and the placebo is body lotion this \n",
    "giving the medicin results in a 95% percentile of the optimal value might it scary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - adaptive experiments\n",
    "\n",
    "In this exercise we are going to look at addaptive models. That is, we let our models observe the outcome of their recommendations such that they can learn from them. Since we have used supervised methods this implies that we have to refit our model with the new data. There is probably a better way to do this, since refitting the models take a long time. One should also note that new observations might drown in the old data in the method we have used. Here one might adress issues such as whether one should weight the most resent data higher than the old data. We have not adressed this issue.\n",
    "\n",
    "We will consider two scenarios. In the first scenario we have still only the placebo and the treatment. In the second scenario we introduced the other treatments. That is, we now have 129 treatments: 1 placebo, 2 general treatments and 126 gene specific treatments. Note that we in this scenario we do not have any data for the new treatments. Thus, one have to explore these new treatments and look at the results. This we will do for a fixed number of treatments, and then we are going to use the best treatment for the rest. \n",
    "\n",
    "Here there are two potential goals according to the text: discover the most effective treatment policy at the end of the trial or maximize the expected number of people to be treated. We have gone for the second on, but with the modified $\\texttt{reward_function}$ discussed earlier. \n",
    "\n",
    "We take a look at the first section first.\n",
    "#### 1. \n",
    "We have alredy described what the code does. It adds the new patient to the old dataset and refit the model. We do this with two of the models above. This is due to the long computation time it takes to run these simulations. Since the single logistic and the bootstrap logistic obtained the same results last time we only look at the simple version here. We also only look at the (5,2) neural network. We would have liked to tested (2,2,3) too, but it takes too long time. We allow our models to observe by changing the zeros to ones in the extra, otherwise the code below is identical to the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reduce the number of patients due to the computation time\n",
    "# We do noe recommend to run this block again since it takes hours to run.\n",
    "N = 100\n",
    "T = 100\n",
    "\n",
    "# Optimal recommender\n",
    "import OptimalRecommender\n",
    "policy_factory_optimal = OptimalRecommender.OptimalRecommender\n",
    "\n",
    "# Single logistic\n",
    "import LogisticRecommender\n",
    "policy_factory_logistic = LogisticRecommender.LogisticRecommender\n",
    "\n",
    "# Nerural network\n",
    "import NeuralNetworkRecommender\n",
    "policy_factory_NN = NeuralNetworkRecommender.NeuralNetworkRecommender\n",
    "\n",
    "print(\"Optimal: \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = 2)\n",
    "\n",
    "print(\"Single logistic model: \")\n",
    "create_CI(generator, policy_factory_logistic, reward_function, T, N, features, actions, outcome, extra = 1)\n",
    "\n",
    "print(\"NN(5,2): \")\n",
    "create_CI(generator, policy_factory_NN, reward_function, T, N, features, actions, outcome, extra = [1, [5,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the results of the code above in the left part of the table below. Note that there is not much improvments compared to the previous table. This might be because the new information drowns in the old data or there is some underlying noise that cannot be reduced. Note that each model now only treats 100 persons, due to the computational time, hence the wider intervals. So if you want to compare the results in this table with the previous table you should look at the medians.\n",
    "\n",
    "\n",
    "![title](Table2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. \n",
    "In this setting we are able to choose among the 129 treatments. We initialy had some difficulites so we will first adress what we had done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are informed that treatment 2 is a general treatment. So we want to compare it to the other genereal treatment; treatment 1. In some scenarios it it possible to test two treatments on a single individual, and in other cases it's impossible. E.g. you cannot donclude which of two painkillers relived you of the pain, under the assumption that both were taken by oral administration. However, you can can apply two different body lotions for dry skin on either arm and check which worked or not. In the code below we simulate the the latter scenario. \n",
    "\n",
    "Note that the analyis above in rooted in the real world. Since we are given the code we can treat the same patient with different treatments no mather the scenario. We also want to note that the analysis we are doing here is perhaps not applicable in the real world, since we just give them treatments and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose medicine 1 and 2 which we want to compare. \n",
    "# Can take values between 0 and 129, inclusive. \n",
    "# N is the number of individuals we want to compare.\n",
    "\n",
    "def compareTwoMedicines(med1, med2, N, seed = 10):\n",
    "    # Number of times medicine 1 worked \n",
    "    num1 = 0\n",
    "\n",
    "    # Number of times medicine 2 worked\n",
    "    num2 = 0\n",
    "\n",
    "    # Number of times only medicine 2 worked\n",
    "    numjust1 = 0\n",
    "\n",
    "    # Number of times only medicine 1 worked\n",
    "    numjust2 = 0\n",
    "\n",
    "    # Number of times both medecines worked\n",
    "    numboth = 0\n",
    "\n",
    "    # Number of times neither medicine worked\n",
    "    numnone = 0\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "    for _ in range(N):\n",
    "            # We generate 1 new pasient\n",
    "            x = generator.generate_features()\n",
    "\n",
    "            # Generate the outcome based on user_data and action\n",
    "            y_1 = generator.generate_outcome(x, med1)\n",
    "            y_2 = generator.generate_outcome(x, med2)\n",
    "\n",
    "            if (y_1 == 1): num1 += 1\n",
    "            if (y_2 == 1): num2 += 1\n",
    "            if ((y_1 == 1) & (y_2 == 1)): numboth += 1\n",
    "            if ((y_1 == 0) & (y_2 == 0)): numnone += 1\n",
    "            if ((y_1 == 1) & (y_2 == 0)): numjust1 += 1\n",
    "            if ((y_1 == 0) & (y_2 == 1)): numjust2 += 1\n",
    "    print(\"Med1 = %d and med2 = %3d: %6d %6d %9d %9d %5d %6d\" % (med1, med2, num1, num2, numjust1, numjust2, numboth, numnone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Med1 = 1 and med2 = 2:  53553  54690  19312  20449  34241  25998\n"
     ]
    }
   ],
   "source": [
    "compareTwoMedicines(1, 2, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this printout we see that there is some overlap between the two general treatments. That is, there is about $34.2\\%$ of the patients who display measurable effects to both treatments. Some patients react positively to only one of the treatments while other pasients, about $26\\%$ don't react positively to either treatment. This information is summeraized by the following venn diagram. \n",
    "![Venn](Venn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do the same analysis that we did above with treatment 1 and the gene specific treatments we get some interesting results. From the printout below we see that we never observe an instance where only the gene specific treatment works. If it worked, then the general treatment 1 also worked. So, we are always better of by only recommending the placebo, treatment1 or treatment2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          #med1  #med2 #justmed1 #justmed2 #both  #none\n",
      "Med1 = 1 and med2 =   0:  26766    579     26187         0   579  23234\n",
      "Med1 = 1 and med2 =   1:  26766  26766         0         0 26766  23234\n",
      "Med1 = 1 and med2 =   2:  26766  27305      9677     10216 17089  13018\n",
      "Med1 = 1 and med2 =   3:  26766    365     26401         0   365  23234\n",
      "Med1 = 1 and med2 =   4:  26766    774     25992         0   774  23234\n",
      "Med1 = 1 and med2 =   5:  26766    458     26308         0   458  23234\n",
      "Med1 = 1 and med2 =   6:  26766    889     25877         0   889  23234\n",
      "Med1 = 1 and med2 =   7:  26766    832     25934         0   832  23234\n",
      "Med1 = 1 and med2 =   8:  26766    597     26169         0   597  23234\n",
      "Med1 = 1 and med2 =   9:  26766   1570     25196         0  1570  23234\n",
      "Med1 = 1 and med2 =  10:  26766    737     26029         0   737  23234\n",
      "Med1 = 1 and med2 =  11:  26766   1631     25135         0  1631  23234\n",
      "Med1 = 1 and med2 =  12:  26766    847     25919         0   847  23234\n",
      "Med1 = 1 and med2 =  13:  26766    724     26042         0   724  23234\n",
      "Med1 = 1 and med2 =  14:  26766    906     25860         0   906  23234\n",
      "Med1 = 1 and med2 =  15:  26766    772     25994         0   772  23234\n",
      "Med1 = 1 and med2 =  16:  26766    955     25811         0   955  23234\n",
      "Med1 = 1 and med2 =  17:  26766    655     26111         0   655  23234\n",
      "Med1 = 1 and med2 =  18:  26766    899     25867         0   899  23234\n",
      "Med1 = 1 and med2 =  19:  26766    747     26019         0   747  23234\n",
      "Med1 = 1 and med2 =  20:  26766    357     26409         0   357  23234\n",
      "Med1 = 1 and med2 =  21:  26766   1237     25529         0  1237  23234\n",
      "Med1 = 1 and med2 =  22:  26766    873     25893         0   873  23234\n",
      "Med1 = 1 and med2 =  23:  26766    566     26200         0   566  23234\n",
      "Med1 = 1 and med2 =  24:  26766    828     25938         0   828  23234\n",
      "Med1 = 1 and med2 =  25:  26766    783     25983         0   783  23234\n",
      "Med1 = 1 and med2 =  26:  26766   1761     25005         0  1761  23234\n",
      "Med1 = 1 and med2 =  27:  26766    475     26291         0   475  23234\n",
      "Med1 = 1 and med2 =  28:  26766   1629     25137         0  1629  23234\n",
      "Med1 = 1 and med2 =  29:  26766    446     26320         0   446  23234\n",
      "Med1 = 1 and med2 =  30:  26766    884     25882         0   884  23234\n",
      "Med1 = 1 and med2 =  31:  26766    843     25923         0   843  23234\n",
      "Med1 = 1 and med2 =  32:  26766    875     25891         0   875  23234\n",
      "Med1 = 1 and med2 =  33:  26766    817     25949         0   817  23234\n",
      "Med1 = 1 and med2 =  34:  26766    756     26010         0   756  23234\n",
      "Med1 = 1 and med2 =  35:  26766    738     26028         0   738  23234\n",
      "Med1 = 1 and med2 =  36:  26766    684     26082         0   684  23234\n",
      "Med1 = 1 and med2 =  37:  26766    769     25997         0   769  23234\n",
      "Med1 = 1 and med2 =  38:  26766    683     26083         0   683  23234\n",
      "Med1 = 1 and med2 =  39:  26766    520     26246         0   520  23234\n",
      "Med1 = 1 and med2 =  40:  26766    790     25976         0   790  23234\n",
      "Med1 = 1 and med2 =  41:  26766    814     25952         0   814  23234\n",
      "Med1 = 1 and med2 =  42:  26766    589     26177         0   589  23234\n",
      "Med1 = 1 and med2 =  43:  26766    627     26139         0   627  23234\n",
      "Med1 = 1 and med2 =  44:  26766    676     26090         0   676  23234\n",
      "Med1 = 1 and med2 =  45:  26766    856     25910         0   856  23234\n",
      "Med1 = 1 and med2 =  46:  26766    851     25915         0   851  23234\n",
      "Med1 = 1 and med2 =  47:  26766    616     26150         0   616  23234\n",
      "Med1 = 1 and med2 =  48:  26766    473     26293         0   473  23234\n",
      "Med1 = 1 and med2 =  49:  26766   1091     25675         0  1091  23234\n",
      "Med1 = 1 and med2 =  50:  26766    775     25991         0   775  23234\n",
      "Med1 = 1 and med2 =  51:  26766    874     25892         0   874  23234\n",
      "Med1 = 1 and med2 =  52:  26766    255     26511         0   255  23234\n",
      "Med1 = 1 and med2 =  53:  26766   1135     25631         0  1135  23234\n",
      "Med1 = 1 and med2 =  54:  26766    712     26054         0   712  23234\n",
      "Med1 = 1 and med2 =  55:  26766    719     26047         0   719  23234\n",
      "Med1 = 1 and med2 =  56:  26766    549     26217         0   549  23234\n",
      "Med1 = 1 and med2 =  57:  26766    602     26164         0   602  23234\n",
      "Med1 = 1 and med2 =  58:  26766    726     26040         0   726  23234\n",
      "Med1 = 1 and med2 =  59:  26766    619     26147         0   619  23234\n",
      "Med1 = 1 and med2 =  60:  26766    682     26084         0   682  23234\n",
      "Med1 = 1 and med2 =  61:  26766    819     25947         0   819  23234\n",
      "Med1 = 1 and med2 =  62:  26766    745     26021         0   745  23234\n",
      "Med1 = 1 and med2 =  63:  26766    863     25903         0   863  23234\n",
      "Med1 = 1 and med2 =  64:  26766   1238     25528         0  1238  23234\n",
      "Med1 = 1 and med2 =  65:  26766    823     25943         0   823  23234\n",
      "Med1 = 1 and med2 =  66:  26766    818     25948         0   818  23234\n",
      "Med1 = 1 and med2 =  67:  26766    542     26224         0   542  23234\n",
      "Med1 = 1 and med2 =  68:  26766    905     25861         0   905  23234\n",
      "Med1 = 1 and med2 =  69:  26766    642     26124         0   642  23234\n",
      "Med1 = 1 and med2 =  70:  26766    659     26107         0   659  23234\n",
      "Med1 = 1 and med2 =  71:  26766    628     26138         0   628  23234\n",
      "Med1 = 1 and med2 =  72:  26766    733     26033         0   733  23234\n",
      "Med1 = 1 and med2 =  73:  26766    718     26048         0   718  23234\n",
      "Med1 = 1 and med2 =  74:  26766    924     25842         0   924  23234\n",
      "Med1 = 1 and med2 =  75:  26766   1196     25570         0  1196  23234\n",
      "Med1 = 1 and med2 =  76:  26766    561     26205         0   561  23234\n",
      "Med1 = 1 and med2 =  77:  26766    642     26124         0   642  23234\n",
      "Med1 = 1 and med2 =  78:  26766    689     26077         0   689  23234\n",
      "Med1 = 1 and med2 =  79:  26766    948     25818         0   948  23234\n",
      "Med1 = 1 and med2 =  80:  26766    810     25956         0   810  23234\n",
      "Med1 = 1 and med2 =  81:  26766    839     25927         0   839  23234\n",
      "Med1 = 1 and med2 =  82:  26766    688     26078         0   688  23234\n",
      "Med1 = 1 and med2 =  83:  26766    669     26097         0   669  23234\n",
      "Med1 = 1 and med2 =  84:  26766    646     26120         0   646  23234\n",
      "Med1 = 1 and med2 =  85:  26766    507     26259         0   507  23234\n",
      "Med1 = 1 and med2 =  86:  26766   2985     23781         0  2985  23234\n",
      "Med1 = 1 and med2 =  87:  26766    767     25999         0   767  23234\n",
      "Med1 = 1 and med2 =  88:  26766    757     26009         0   757  23234\n",
      "Med1 = 1 and med2 =  89:  26766    953     25813         0   953  23234\n",
      "Med1 = 1 and med2 =  90:  26766    736     26030         0   736  23234\n",
      "Med1 = 1 and med2 =  91:  26766    743     26023         0   743  23234\n",
      "Med1 = 1 and med2 =  92:  26766   1380     25386         0  1380  23234\n",
      "Med1 = 1 and med2 =  93:  26766    693     26073         0   693  23234\n",
      "Med1 = 1 and med2 =  94:  26766   1058     25708         0  1058  23234\n",
      "Med1 = 1 and med2 =  95:  26766    695     26071         0   695  23234\n",
      "Med1 = 1 and med2 =  96:  26766    955     25811         0   955  23234\n",
      "Med1 = 1 and med2 =  97:  26766    958     25808         0   958  23234\n",
      "Med1 = 1 and med2 =  98:  26766    570     26196         0   570  23234\n",
      "Med1 = 1 and med2 =  99:  26766    705     26061         0   705  23234\n",
      "Med1 = 1 and med2 = 100:  26766   1323     25443         0  1323  23234\n",
      "Med1 = 1 and med2 = 101:  26766    562     26204         0   562  23234\n",
      "Med1 = 1 and med2 = 102:  26766    344     26422         0   344  23234\n",
      "Med1 = 1 and med2 = 103:  26766   1135     25631         0  1135  23234\n",
      "Med1 = 1 and med2 = 104:  26766    652     26114         0   652  23234\n",
      "Med1 = 1 and med2 = 105:  26766    524     26242         0   524  23234\n",
      "Med1 = 1 and med2 = 106:  26766   1100     25666         0  1100  23234\n",
      "Med1 = 1 and med2 = 107:  26766    969     25797         0   969  23234\n",
      "Med1 = 1 and med2 = 108:  26766    361     26405         0   361  23234\n",
      "Med1 = 1 and med2 = 109:  26766    663     26103         0   663  23234\n",
      "Med1 = 1 and med2 = 110:  26766    795     25971         0   795  23234\n",
      "Med1 = 1 and med2 = 111:  26766   1232     25534         0  1232  23234\n",
      "Med1 = 1 and med2 = 112:  26766    714     26052         0   714  23234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Med1 = 1 and med2 = 113:  26766    592     26174         0   592  23234\n",
      "Med1 = 1 and med2 = 114:  26766    836     25930         0   836  23234\n",
      "Med1 = 1 and med2 = 115:  26766   1019     25747         0  1019  23234\n",
      "Med1 = 1 and med2 = 116:  26766    639     26127         0   639  23234\n",
      "Med1 = 1 and med2 = 117:  26766    782     25984         0   782  23234\n",
      "Med1 = 1 and med2 = 118:  26766    718     26048         0   718  23234\n",
      "Med1 = 1 and med2 = 119:  26766    735     26031         0   735  23234\n",
      "Med1 = 1 and med2 = 120:  26766    667     26099         0   667  23234\n",
      "Med1 = 1 and med2 = 121:  26766    240     26526         0   240  23234\n",
      "Med1 = 1 and med2 = 122:  26766    896     25870         0   896  23234\n",
      "Med1 = 1 and med2 = 123:  26766    782     25984         0   782  23234\n",
      "Med1 = 1 and med2 = 124:  26766    625     26141         0   625  23234\n",
      "Med1 = 1 and med2 = 125:  26766    675     26091         0   675  23234\n",
      "Med1 = 1 and med2 = 126:  26766    917     25849         0   917  23234\n",
      "Med1 = 1 and med2 = 127:  26766   4294     22472         0  4294  23234\n",
      "Med1 = 1 and med2 = 128:  26766    787     25979         0   787  23234\n"
     ]
    }
   ],
   "source": [
    "print(\"                          #med1  #med2 #justmed1 #justmed2 #both  #none\")\n",
    "for i in range(129):\n",
    "    compareTwoMedicines(1, i, 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now for a second assume that the gene specific treatments only target a single gene, and more precisely, that treatment 3 correspond to gene 1, treatment 4 correspond to gene 4 and so on. This might be a far fetched assumption, but it's the way we have interpreted the exercise. Then we can conduct a similar calculation as above and look at the proportions of the different genes. That is, for each patient we record wether the treatment was a success or not, and in either case we also record the value of the specific gene. We do this for 10 000 patients. From these calulations we get empirical estimates for the 1) probabilities that a given treatment is a success given the value of the genes, 2) the probabilities for a gene taking on a specific value given that the treatment was a success and 3) general success rates and failure rates. Below you see the code and the final table of the 20 \"best\" treatments, under the assumption that we always recommend it no mater the features and that we can give mutiple treatments to the same people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_policy2(generator, policy, reward_function, T):\n",
    "    policy.set_reward(reward_function)\n",
    "    # Set seed for reproducibility\n",
    "    seed_number = 333213\n",
    "    # Utility\n",
    "    u = 0\n",
    "    # varaible to count\n",
    "    number_treated_gen0 = 0\n",
    "    number_treated_gen1 = 0\n",
    "    number_failed_gen0  = 0\n",
    "    number_failed_gen1  = 0\n",
    "    \n",
    "    for t in range(T):\n",
    "        # For reproducibility and to analyse the same patients every time the code is called\n",
    "        np.random.seed(seed_number + t)\n",
    "        # We generate 1 new pasient\n",
    "        x = generator.generate_features()\n",
    "        # Fixed model, always give a fixed number\n",
    "        a = policy.recommend(x)\n",
    "        # Generate the outcome based on user_data and action\n",
    "        y = generator.generate_outcome(x, a)\n",
    "        # Add the utility/reward\n",
    "        u += reward_function(a, y)\n",
    "        \n",
    "        # From the feedback after the presentation you said we should look at the proportions of gene0 and gene1 for the \n",
    "        # general treatments. Since they do not correspond to a single gen we assume that your note was reagarding the fact \n",
    "        # that we highlightet treatment 127/gene 125 and hence that we should look at these proportions.\n",
    "        # We can do this by just changing the a value here and use the same code as before:\n",
    "        if (a in [0,1,2]): \n",
    "            a = 127\n",
    "        \n",
    "        # If success or failure count the genes\n",
    "        if(y == 1): \n",
    "            if (x[a] == 0):\n",
    "                number_treated_gen0 += 1\n",
    "            if (x[a] == 1):\n",
    "                number_treated_gen1 += 1\n",
    "        else:\n",
    "            if (x[a] == 0):\n",
    "                number_failed_gen0 += 1\n",
    "            if (x[a] == 1):\n",
    "                number_failed_gen1 += 1\n",
    "                \n",
    "        \n",
    "    return [u/T, number_treated_gen0, number_treated_gen1, number_failed_gen0, number_failed_gen1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment  Utility  Total success: %gen0   %gen1   Total fail: %gen0   %gen1    Successrate given gen0/gen1\n",
      "        2    0.444        5443     0.305   0.695        4557    0.548   0.452    0.400  0.647 (ratios of gene 125)\n",
      "        1    0.434        5341     0.457   0.543        4659    0.368   0.632    0.588  0.496 (ratios of gene 125)\n",
      "        0    0.014         140     0.564   0.436        9860    0.414   0.586    0.019  0.010 (ratios of gene 125)\n",
      "      127   -0.009         906     0.091   0.909        9094    0.448   0.552    0.020  0.141 \n",
      "       86   -0.040         603     0.221   0.779        9397    0.531   0.469    0.026  0.096 \n",
      "       28   -0.062         380     0.463   0.537        9620    0.493   0.507    0.036  0.040 \n",
      "       26   -0.063         368     0.139   0.861        9632    0.517   0.483    0.010  0.064 \n",
      "       11   -0.065         354     0.136   0.864        9646    0.516   0.484    0.010  0.062 \n",
      "        9   -0.067         334     0.266   0.734        9666    0.512   0.488    0.018  0.049 \n",
      "       92   -0.069         315     0.441   0.559        9685    0.503   0.497    0.028  0.035 \n",
      "       64   -0.072         282     0.273   0.727        9718    0.509   0.491    0.015  0.041 \n",
      "      111   -0.072         280     0.357   0.643        9720    0.496   0.504    0.020  0.035 \n",
      "      100   -0.072         279     0.276   0.724        9721    0.508   0.492    0.015  0.040 \n",
      "       21   -0.073         271     0.321   0.679        9729    0.504   0.496    0.017  0.037 \n",
      "       75   -0.074         260     0.512   0.488        9740    0.497   0.503    0.027  0.025 \n",
      "      103   -0.075         253     0.577   0.423        9747    0.501   0.499    0.029  0.022 \n",
      "       53   -0.075         249     0.739   0.261        9751    0.502   0.498    0.036  0.013 \n",
      "      106   -0.076         243     0.403   0.597        9757    0.498   0.502    0.020  0.029 \n",
      "       49   -0.076         237     0.764   0.236        9763    0.497   0.503    0.036  0.011 \n",
      "       94   -0.077         227     0.577   0.423        9773    0.495   0.505    0.026  0.019 \n"
     ]
    }
   ],
   "source": [
    "import FixedTreatmentRecommender\n",
    "\n",
    "# matrix to store the results for the 129 medicines\n",
    "results_fixed_treatment = np.zeros((generator.get_n_actions(), 5))\n",
    "\n",
    "# Number of patients\n",
    "T = 10000\n",
    "\n",
    "# Run each model\n",
    "for i in range(len(results_fixed_treatment)):\n",
    "    policy_temp = FixedTreatmentRecommender.FixedTreatmentRecommender(generator.get_n_actions(), generator.get_n_outcomes(), i)\n",
    "    results_fixed_treatment[i] = test_policy2(generator, policy_temp, reward_function, T)\n",
    "\n",
    "\n",
    "# Let's only look at the k best gene treatments\n",
    "k = 20\n",
    "best_indices = np.argsort(-results_fixed_treatment[:,0])[:k]\n",
    "\n",
    "print(\"Treatment  Utility  Total success: %gen0   %gen1   Total fail: %gen0   %gen1    Successrate given gen0/gen1\")\n",
    "for i in best_indices:\n",
    "    util = results_fixed_treatment[i,0]\n",
    "    suc0 = results_fixed_treatment[i,1]\n",
    "    suc1 = results_fixed_treatment[i,2]\n",
    "    fail0 = results_fixed_treatment[i,3]\n",
    "    fail1 = results_fixed_treatment[i,4]\n",
    "    tot_suc = suc0 + suc1\n",
    "    tot_fail = fail0 + fail1\n",
    "    tot = tot_suc + tot_fail\n",
    "    percentage_suc0 = suc0 / tot_suc\n",
    "    percentage_suc1 = suc1 / tot_suc\n",
    "    percentage_fail0 = fail0 / tot_fail\n",
    "    percentage_fail1 = fail1 / tot_fail\n",
    "    percentage_0_succ = suc0/(suc0+fail0)\n",
    "    percentage_1_succ = suc1/(suc1+fail1)\n",
    "    if (i in [0,1,2]):\n",
    "        print(\"%9d  %7.3f        %4d     %4.3f   %4.3f        %3d  %7.3f  %6.3f   %6.3f %6.3f (ratios of gene 125)\" % (i, util, tot_suc, percentage_suc0, percentage_suc1, tot_fail, percentage_fail0, percentage_fail1,  percentage_0_succ, percentage_1_succ))\n",
    "    else:\n",
    "        print(\"%9d  %7.3f        %4d     %4.3f   %4.3f        %3d  %7.3f  %6.3f   %6.3f %6.3f \" % (i, util, tot_suc, percentage_suc0, percentage_suc1, tot_fail, percentage_fail0, percentage_fail1,  percentage_0_succ, percentage_1_succ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in our presentation we want to highlight treatment 127, corresponding to gene 125. If we know the treatment was a success, then we can with a high probability, more precise $91\\%$, assume that the value of gene 125 was 1. However, this doesn't mean that we should give treatment 127 to a pasient with the value of gene 125 being 1, since the successrate is only $14.1\\%$, while the successrates for the general treatments are much higher. \n",
    "Note that the table display the successrates of the general treatment given gene 125 and they are both better independently of the value of gene 125. These values are only comparable with treatment 127. From them we see that there is a higher successrate for treatment 1 if gene 125 is 0, while the successrate of treatment 2 is higher if the gene has a value of 1.\n",
    "\n",
    "This whole analysis has been a huge digression, but that is something we did after we made some models which became worse when we introduced the new treatments. We had initaially assumed that our results would become better with the new treatments, which we have concluded is wrong. Hence when we do an exploration later on, we are losing potential utility which we are not able to re-earn. Once again, we highlight this, since we have the generator file we can look at it. If we let the $\\texttt{OptimalRecommender}$ recommend between action zero to two or zero to 129, we obtain the same results. Again, this is not possible in the real world, but since we are working in a sandbox scenario we wanted to make a note of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal (129 treatments): \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.632655 0.6624   0.693945]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.70295 0.736   0.77105]\n",
      "Optimal (3 treatments): \n",
      "Done with n = 0\n",
      "Done with n = 10\n",
      "Done with n = 20\n",
      "Done with n = 30\n",
      "Done with n = 40\n",
      "Done with n = 50\n",
      "Done with n = 60\n",
      "Done with n = 70\n",
      "Done with n = 80\n",
      "Done with n = 90\n",
      "Utility percentiles(2.5, 50, 97.5):  [0.632655 0.6624   0.693945]\n",
      "Percentage of treatments percentiles(2.5, 50, 97.5):  [0.70295 0.736   0.77105]\n"
     ]
    }
   ],
   "source": [
    "T = 500\n",
    "N = 100\n",
    "\n",
    "print(\"Optimal (129 treatments): \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = generator.get_n_actions())\n",
    "print(\"Optimal (3 treatments): \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's forget this for a moment and rather illustrate how we obtained the results we presentated at the seminar, table 2. That is, where we let the the improved polcies take on values zero, one and two. Let's start by looking at the neural network. Initialy we thought we had to manually force it to explore the second treatment, but after some simulations we figured out that we actually obtained the best results by not forcing the neural network to recommend the second general treatment. Why this is, we are not certain of. Maybe NN are exporationary by nature or we might just been lucky. Either way, the new policy recommend treatments much more often than before and obtain a median utility of 0.622 which is pretty close to the optimal value of 0.666. \n",
    "The NN recommends the action, among the three, that maximizes the estimated reward of the patient.\n",
    "\n",
    "Our results with the logistic model did not work as we had intended. It uses the same idea as above to choose it recommendations, but it ends up always chosing the second treatment. We do not think there is an error in the code, but it is strange that the confidence intervals have zero width. Under the assumption that our code is correct is that the model is too optimistic on the effect of the treatment and that the coefficient corresponding to the action variable is positive, hence it chooses the second action. \n",
    "\n",
    "In the presentation we highlighted this issue and presented a possible solution, which would be to use dummy variables for the action. Your feedback was that that might work, but you recommended us to have a seperate model for each action. We have looked into this and will presentate our findings later in the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not reccommend to run this chunk. It is computationally heavy and takes a long time to run.\n",
    "# We ran it in the terminal, since it is faster.\n",
    "T = 100\n",
    "N = 100\n",
    "\n",
    "# Optimal recommender\n",
    "import OptimalRecommender\n",
    "policy_factory_optimal = OptimalRecommender.OptimalRecommender\n",
    "\n",
    "# Single logistic\n",
    "import LogisticRecommender2Actions\n",
    "policy_factory_logistic = LogisticRecommender2Actions.LogisticRecommender2Actions\n",
    "\n",
    "# Nerural network\n",
    "import NeuralNetworkRecommender2Actions\n",
    "policy_factory_NN = NeuralNetworkRecommender2Actions.NeuralNetworkRecommender2Actions\n",
    "\n",
    "print(\"Optimal: \")\n",
    "create_CI(generator, policy_factory_optimal, reward_function, T, N, features, actions, outcome, extra = 2)\n",
    "\n",
    "print(\"Single logistic model: \")\n",
    "create_CI(generator, policy_factory_logistic, reward_function, T, N, features, actions, outcome, extra = 1)\n",
    "\n",
    "print(\"NN(5,2): \")\n",
    "create_CI(generator, policy_factory_NN, reward_function, T, N, features, actions, outcome, extra = [1, [5,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Table2.png)\n",
    "![title](Table3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The new version of logistic based on presentation feedback:\n",
    "\n",
    "We start by looking at the version of the logistic model. Here we only look at the three first actions. Note that only action 2 is unknown. Hence we force or model to explore this choice 20 times. This number should propably been decided dynamically by some method, but we lack time to do the analysis. After the first 20 patients it recommends the action with highest estimated utility. Note that the recommender now have 3 models. In the first model all the actions are 0, in the second they are 1 and in the last one we only have action 2. We did not have time to run the $\\texttt{create_CI}$, so we simply ran the code with 2000 patients and looked at the utility. Since we treated so many pasients we hope that the utility has converged. From the printouts that looks to be a reasonable assumption. One should note that the recommender is still too optimistic and prescribe the treatment too often. However, it accheive the best mean utility we have observed this far.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    0 \t Current mean reward:  0.9000\n",
      "Iteration:  100 \t Current mean reward:  0.5931\n",
      "Iteration:  200 \t Current mean reward:  0.6413\n",
      "Iteration:  300 \t Current mean reward:  0.6276\n",
      "Iteration:  400 \t Current mean reward:  0.6357\n",
      "Iteration:  500 \t Current mean reward:  0.6305\n",
      "Iteration:  600 \t Current mean reward:  0.6354\n",
      "Iteration:  700 \t Current mean reward:  0.6389\n",
      "Iteration:  800 \t Current mean reward:  0.6441\n",
      "Iteration:  900 \t Current mean reward:  0.6425\n",
      "Iteration: 1000 \t Current mean reward:  0.6473\n",
      "Iteration: 1100 \t Current mean reward:  0.6493\n",
      "Iteration: 1200 \t Current mean reward:  0.6510\n",
      "Iteration: 1300 \t Current mean reward:  0.6487\n",
      "Iteration: 1400 \t Current mean reward:  0.6545\n",
      "Iteration: 1500 \t Current mean reward:  0.6602\n",
      "Iteration: 1600 \t Current mean reward:  0.6633\n",
      "Iteration: 1700 \t Current mean reward:  0.6590\n",
      "Iteration: 1800 \t Current mean reward:  0.6562\n",
      "Iteration: 1900 \t Current mean reward:  0.6564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6565000000000086, 2000]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import LogisticRecommender2Tips\n",
    "T = 2000\n",
    "\n",
    "policy_factory_tips = LogisticRecommender2Tips.LogisticRecommender2Tips\n",
    "policy_logistic_tips = policy_factory_tips(generator.get_n_actions(), generator.get_n_outcomes(), force_alt_med = 20, force_action=2)\n",
    "policy_logistic_tips.set_reward(reward_function)\n",
    "policy_logistic_tips.fit_treatment_outcome(features, actions, outcome)\n",
    "test_policy(generator, policy_logistic_tips, reward_function, T, 1334, printout = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried to generalize this method to the case with 129 treatments. However, we got stuck. Since we use a logistic model we need a training set which contains instances of both outcomes, for most of the treatments we did not acchieve this even when we forced the recommender to recommend each treatment 20 times. Then we though we could remove the treatments which yielded no sucess after 20 patients. However, we ran into some coding issues and had no time to solve the bugs. We think this could have given some good results. Instead we choose to explore the 129 treatments based on a method we looked at in class, Thompson sampling, which yielded acceptable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thompson sampling\n",
    "In class we devoled the $\\texttt{thompson_bandit}$. It has a beta prior for each of the 129 treatments. The first two treatments we know quite a lot about, we could have found empirical parameters for the beta prior by momentmatching (set the analytic and the historical moments to be identical), but we have chosen parameters which creates the prior we ought to have. The prior for the placebo has the majority of it's weight located close to 0 while the first treatment has a more evenly distributed weight with the mode at 0.5. For the other treatments we do not know anything, hence we chose a uniform dsitribution for them. These priors will be washed away by the data. \n",
    "For each patient we draw a random value from the distributions for each of the treatments and recommend the treatment with the maximum value. From the printout below we see that the recommender first tries out the different treatments and learn from this. After some time it will figure out which treatments are the best and always go for this or these. If there is a treatment superior then it will always chose that one, but in this case both action 1 and action 2 are almost equally good(from earlier analysis), so we will recommend a mixture of them over time. This is because of the randomness by drawing a random point from the distributions.  \n",
    "We see that the utility converges to around 0.443. This is as expected. From earlier analysis we showed that treatment 1 and treatment 2 was effective in about 54% of the cases. If we also include the -0.1 penalty in the utility function we end up with the utility that we see here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thompson 20 000:\n",
      "Iteration:    0 \t Current mean reward: -0.1000\n",
      "Iteration: 1000 \t Current mean reward:  0.0086\n",
      "Iteration: 2000 \t Current mean reward:  0.1594\n",
      "Iteration: 3000 \t Current mean reward:  0.2469\n",
      "Iteration: 4000 \t Current mean reward:  0.2940\n",
      "Iteration: 5000 \t Current mean reward:  0.3192\n",
      "Iteration: 6000 \t Current mean reward:  0.3426\n",
      "Iteration: 7000 \t Current mean reward:  0.3575\n",
      "Iteration: 8000 \t Current mean reward:  0.3695\n",
      "Iteration: 9000 \t Current mean reward:  0.3775\n",
      "Iteration: 10000 \t Current mean reward:  0.3827\n",
      "Iteration: 11000 \t Current mean reward:  0.3863\n",
      "Iteration: 12000 \t Current mean reward:  0.3895\n",
      "Iteration: 13000 \t Current mean reward:  0.3935\n",
      "Iteration: 14000 \t Current mean reward:  0.3968\n",
      "Iteration: 15000 \t Current mean reward:  0.3995\n",
      "Iteration: 16000 \t Current mean reward:  0.4007\n",
      "Iteration: 17000 \t Current mean reward:  0.4034\n",
      "Iteration: 18000 \t Current mean reward:  0.4057\n",
      "Iteration: 19000 \t Current mean reward:  0.4071\n",
      "10 most used treatments:\n",
      "Treatment:      2     1     0    45     4     7    97    65    66    32\n",
      "Times used: 14994  3740    15    15    15    15    15    14    14    14\n",
      "\n",
      "Thompson 200 000:\n",
      "Iteration:    0 \t Current mean reward: -0.1000\n",
      "Iteration: 10000 \t Current mean reward:  0.3827\n",
      "Iteration: 20000 \t Current mean reward:  0.4095\n",
      "Iteration: 30000 \t Current mean reward:  0.4182\n",
      "Iteration: 40000 \t Current mean reward:  0.4241\n",
      "Iteration: 50000 \t Current mean reward:  0.4283\n",
      "Iteration: 60000 \t Current mean reward:  0.4317\n",
      "Iteration: 70000 \t Current mean reward:  0.4347\n",
      "Iteration: 80000 \t Current mean reward:  0.4356\n",
      "Iteration: 90000 \t Current mean reward:  0.4369\n",
      "Iteration: 100000 \t Current mean reward:  0.4388\n",
      "Iteration: 110000 \t Current mean reward:  0.4397\n",
      "Iteration: 120000 \t Current mean reward:  0.4407\n",
      "Iteration: 130000 \t Current mean reward:  0.4411\n",
      "Iteration: 140000 \t Current mean reward:  0.4414\n",
      "Iteration: 150000 \t Current mean reward:  0.4417\n",
      "Iteration: 160000 \t Current mean reward:  0.4416\n",
      "Iteration: 170000 \t Current mean reward:  0.4420\n",
      "Iteration: 180000 \t Current mean reward:  0.4426\n",
      "Iteration: 190000 \t Current mean reward:  0.4430\n",
      "10 most used treatments:\n",
      "Treatment:       2      1     0   119   111    75    66    98    97    92\n",
      "Times used:  14994   3740    15    15    15    15    15    14    14    14\n",
      "\n",
      "Thompson  (20 000): utility = 0.409575\n",
      "Thompson (200 000): utility = 0.443400\n"
     ]
    }
   ],
   "source": [
    "T = 20000\n",
    "import thompson_bandit\n",
    "\n",
    "n_actions = 129\n",
    "n_outcomes = 2\n",
    "prior_a = [2,2] + [1]*127\n",
    "prior_b = [5,2] + [1]*127\n",
    "thompson_policy = thompson_bandit.ThompsonBandit(129, 2, prior_a, prior_b)\n",
    "print(\"Thompson 20 000:\")\n",
    "thompson_result1 = test_policy(generator, thompson_policy, reward_function, T, 100, True, 1000, True)\n",
    "\n",
    "print(\"10 most used treatments:\")\n",
    "b = np.argsort(-thompson_result1[2])[:10]\n",
    "print(\"Treatment:  %5d %5d %5d %5d %5d %5d %5d %5d %5d %5d\" % (b[0], b[1], b[2], b[3], b[4], b[5], b[6], b[7], b[8], b[9]))\n",
    "r = thompson_result1[2][best_indices]\n",
    "print(\"Times used: %5d %5d %5d %5d %5d %5d %5d %5d %5d %5d\" % (r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[7], r[8], r[9]))\n",
    "\n",
    "T = 200000\n",
    "print(\"\\nThompson 200 000:\")\n",
    "thompson_policy = thompson_bandit.ThompsonBandit(129, 2, prior_a, prior_b)\n",
    "thompson_result2 = test_policy(generator, thompson_policy, reward_function, T, 100, True, 10000, True)\n",
    "print(\"10 most used treatments:\")\n",
    "b = np.argsort(-thompson_result2[2])[:10]\n",
    "print(\"Treatment:  %6d %6d %5d %5d %5d %5d %5d %5d %5d %5d\" % (b[0], b[1], b[2], b[3], b[4], b[5], b[6], b[7], b[8], b[9]))\n",
    "r = thompson_result1[2][best_indices]\n",
    "print(\"Times used: %6d %6d %5d %5d %5d %5d %5d %5d %5d %5d\" % (r[0], r[1], r[2], r[3], r[4], r[5], r[6], r[7], r[8], r[9]))\n",
    "\n",
    "\n",
    "print(\"\\nThompson  (20 000): utility = %f\" %thompson_result1[0])\n",
    "print(\"Thompson (200 000): utility = %f\" %thompson_result2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A small discussion on Privacy and Fairness\n",
    "\n",
    "As statisticians we have to remember that data we are working on often origins from human beings and that our conclusions can effect their lives. It is therefor important to adress certain concepts such as privacy and fairness. The former is related to the fact that the data can be e.g. stolen by an adversary. This might be an insurance company which are able to identify you based on database merging and from this they might increase the insurence due to some specefic genes, hypotetically. We do not want this to happen. We might solve this by adding noise to the features. Since we are dealing with binary data this correspond to flip some of the values. However, this might also make it harder for us to give the right treatments. Say that we have a treatment that always work if the pacients have a set of genes, but it is lethal if you don't have the right genes (extremmly hypotetically case). In this scenario we have to be sure about the genes, but if the data has noise we cannot use this medicine on the patient without risking his/hers life. \n",
    "\n",
    "One should also adress fairness. That is that our recommender doesn't discriminate based on gender, ethnectiy, ect. In this dataset the only potential disciminative featuers are the features regarding gender and whether or not the patient smoke. In this project we are in a different setting than in the previous project and it might be a good ting to seperate based on gender. Say that treatment 1 is more effective on female while treatment 2 is more effective on men, then we would like to know the gender on the patient. However, if we are in the first setting were males more often are given placebo then women, then this might be a issue. \n",
    "\n",
    "We have not done any analysis on our models in this project, since we did it in the previous one, but we wanted to adress it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
